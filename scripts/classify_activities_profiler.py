#!/usr/bin/env python3
"""
classify_activities í•¨ìˆ˜ ìƒì„¸ í”„ë¡œíŒŒì¼ë§
ê° ì£¼ìš” ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì •ìœ¼ë¡œ ì •í™•í•œ ë³‘ëª© íŒŒì•…
"""

import time
import logging
from datetime import date
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.database import get_database_manager
from src.data_processing import PickleManager
from src.ui.components.individual_dashboard import IndividualDashboard
from src.analysis.individual_analyzer import IndividualAnalyzer

class ClassifyActivitiesProfiler:
    """classify_activities í•¨ìˆ˜ ìƒì„¸ í”„ë¡œíŒŒì¼ëŸ¬"""
    
    def __init__(self):
        self.db_manager = get_database_manager()
        self.pickle_manager = PickleManager()
        
        # ë¡œê¹… ë ˆë²¨ ì„ì‹œ ë³€ê²½ìœ¼ë¡œ ë¡œê¹… ì˜¤ë²„í—¤ë“œ ì¸¡ì •
        self.original_log_level = logging.root.level
        
    def profile_classify_activities(self, employee_id="20170124", test_date=None):
        """classify_activities í•¨ìˆ˜ ìƒì„¸ í”„ë¡œíŒŒì¼ë§"""
        print("ğŸ”¬ classify_activities ìƒì„¸ í”„ë¡œíŒŒì¼ë§")
        print("="*60)
        
        if not test_date:
            test_date = date(2025, 6, 4)
            
        # IndividualAnalyzerì™€ IndividualDashboard ìƒì„±
        individual_analyzer = IndividualAnalyzer(self.db_manager, None)
        individual_analyzer.pickle_manager = self.pickle_manager
        individual_dashboard = IndividualDashboard(individual_analyzer)
        
        # íƒœê·¸ ë°ì´í„° ì¤€ë¹„
        daily_data = individual_dashboard.get_daily_tag_data(employee_id, test_date)
        if daily_data is None or daily_data.empty:
            print("âŒ íƒœê·¸ ë°ì´í„° ì—†ìŒ")
            return {}
            
        print(f"ğŸ“Š ì…ë ¥ ë°ì´í„°: {len(daily_data)}ê±´")
        
        # 1. ë¡œê¹… ë ˆë²¨ë³„ ì„±ëŠ¥ ë¹„êµ
        logging_performance = self.compare_logging_levels(individual_dashboard, daily_data, employee_id, test_date)
        
        # 2. ì£¼ìš” í•¨ìˆ˜ í˜¸ì¶œë³„ ì‹œê°„ ì¸¡ì •
        function_performance = self.profile_internal_functions(individual_dashboard, daily_data, employee_id, test_date)
        
        return {
            'logging_performance': logging_performance,
            'function_performance': function_performance
        }
    
    def compare_logging_levels(self, dashboard, daily_data, employee_id, test_date):
        """ë¡œê¹… ë ˆë²¨ë³„ ì„±ëŠ¥ ë¹„êµ"""
        print("\nğŸ” ë¡œê¹… ë ˆë²¨ë³„ ì„±ëŠ¥ ë¹„êµ")
        print("-" * 40)
        
        results = {}
        
        # ë¡œê¹… ë ˆë²¨ë³„ í…ŒìŠ¤íŠ¸
        levels = [
            (logging.CRITICAL, "CRITICAL (ë¡œê¹… ê±°ì˜ ì—†ìŒ)"),
            (logging.ERROR, "ERROR"),
            (logging.WARNING, "WARNING"),  
            (logging.INFO, "INFO (ê¸°ë³¸ê°’)"),
            (logging.DEBUG, "DEBUG (ìµœëŒ€ ë¡œê¹…)")
        ]
        
        for level, name in levels:
            # ë¡œê¹… ë ˆë²¨ ë³€ê²½
            logging.root.setLevel(level)
            dashboard.logger.setLevel(level)
            
            # 5íšŒ ì¸¡ì • í›„ í‰ê· 
            times = []
            for i in range(3):
                data_copy = daily_data.copy()
                
                start_time = time.time()
                dashboard.classify_activities(data_copy, employee_id, test_date)
                elapsed = time.time() - start_time
                times.append(elapsed)
            
            avg_time = sum(times) / len(times)
            results[level] = {
                'name': name,
                'avg_time': avg_time,
                'times': times
            }
            
            print(f"  {name}: {avg_time:.3f}ì´ˆ (í‰ê· )")
        
        # ì›ë˜ ë¡œê¹… ë ˆë²¨ ë³µì›
        logging.root.setLevel(self.original_log_level)
        dashboard.logger.setLevel(self.original_log_level)
        
        return results
    
    def profile_internal_functions(self, dashboard, daily_data, employee_id, test_date):
        """ë‚´ë¶€ í•¨ìˆ˜ í˜¸ì¶œë³„ ì‹œê°„ ì¸¡ì •"""
        print("\nğŸ¯ ë‚´ë¶€ í•¨ìˆ˜ë³„ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§")
        print("-" * 40)
        
        times = {}
        
        # 1. get_tag_location_master ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        tag_location_master = dashboard.get_tag_location_master()
        times['get_tag_location_master'] = time.time() - start_time
        print(f"  get_tag_location_master: {times['get_tag_location_master']:.3f}ì´ˆ")
        
        # 2. get_employee_work_type ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        work_type = dashboard.get_employee_work_type(employee_id, test_date)
        times['get_employee_work_type'] = time.time() - start_time
        print(f"  get_employee_work_type: {times['get_employee_work_type']:.3f}ì´ˆ")
        
        # 3. ì£¼ìš” DataFrame ì—°ì‚°ë“¤ ì¶”ì •
        data_copy = daily_data.copy()
        
        # ê¸°ë³¸ ì»¬ëŸ¼ ì„¤ì • ì‹œê°„
        start_time = time.time()
        if 'activity_code' not in data_copy.columns:
            data_copy['activity_code'] = 'WORK'
        if 'confidence' not in data_copy.columns:
            data_copy['confidence'] = 80
        times['basic_column_setup'] = time.time() - start_time
        print(f"  ê¸°ë³¸ ì»¬ëŸ¼ ì„¤ì •: {times['basic_column_setup']:.3f}ì´ˆ")
        
        # merge ì—°ì‚° ì‹œê°„ (ê°€ì¥ ë¹„ìš©ì´ í´ ê²ƒìœ¼ë¡œ ì˜ˆìƒ)
        if tag_location_master is not None and not tag_location_master.empty:
            start_time = time.time()
            # DR_NO ë¬¸ìì—´ ë³€í™˜ 
            data_copy['DR_NO_str'] = data_copy['DR_NO'].astype(str).str.strip()
            tag_location_master['DR_NO_str'] = tag_location_master['DR_NO'].astype(str).str.strip()
            
            # ì‹¤ì œ merge ì—°ì‚°
            merged = data_copy.merge(
                tag_location_master[['DR_NO_str', 'Tag_Code']],
                on='DR_NO_str',
                how='left',
                suffixes=('', '_master')
            )
            times['dataframe_merge'] = time.time() - start_time
            print(f"  DataFrame merge: {times['dataframe_merge']:.3f}ì´ˆ")
        
        return times
    
    def analyze_function_complexity(self):
        """í•¨ìˆ˜ ë³µì¡ë„ ë¶„ì„"""
        print("\nğŸ“Š classify_activities í•¨ìˆ˜ ë³µì¡ë„ ë¶„ì„")
        print("-" * 50)
        
        # íŒŒì¼ ì½ê¸°
        with open("/Users/hanskim/Projects/SambioHR3/src/ui/components/individual_dashboard.py", 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # classify_activities í•¨ìˆ˜ ë²”ìœ„ ì°¾ê¸°
        start_line = None
        end_line = None
        
        for i, line in enumerate(lines):
            if 'def classify_activities(' in line:
                start_line = i
            elif start_line is not None and line.startswith('    def ') and not line.startswith('        def'):
                end_line = i
                break
        
        if start_line is not None:
            if end_line is None:
                end_line = len(lines)
                
            func_lines = lines[start_line:end_line]
            
            # ë³µì¡ë„ ì§€í‘œë“¤ ê³„ì‚°
            total_lines = len(func_lines)
            
            # ë¡œê¹… ëª…ë ¹ì–´ ìˆ˜
            log_count = sum(1 for line in func_lines 
                           if any(log_type in line for log_type in ['logger.info', 'logger.warning', 'logger.error', 'logger.debug']))
            
            # ì¡°ê±´ë¬¸ ìˆ˜
            condition_count = sum(1 for line in func_lines 
                                 if any(keyword in line.strip() for keyword in ['if ', 'elif ', 'for ', 'while ']))
            
            # merge/join ì—°ì‚° ìˆ˜  
            merge_count = sum(1 for line in func_lines if 'merge(' in line or 'join(' in line)
            
            # ë°˜ë³µë¬¸ ë‚´ DataFrame ì—°ì‚° (ì„±ëŠ¥ ìœ„í—˜)
            loop_df_ops = sum(1 for line in func_lines 
                             if any(op in line for op in ['.loc[', '.iloc[', '.at[', '.iat[']) and 
                                any(indent in line[:20] for indent in ['        ', '            ']))
            
            print(f"  ğŸ“ ì´ ë¼ì¸ ìˆ˜: {total_lines:,}ì¤„")
            print(f"  ğŸ” ë¡œê¹… ëª…ë ¹ì–´: {log_count}ê°œ")
            print(f"  âš¡ ì¡°ê±´ë¬¸/ë°˜ë³µë¬¸: {condition_count}ê°œ")
            print(f"  ğŸ”— DataFrame merge: {merge_count}ê°œ")
            print(f"  ğŸš¨ ë°˜ë³µë¬¸ ë‚´ DataFrame ì—°ì‚°: {loop_df_ops}ê°œ")
            print()
            print(f"  ğŸ’¡ ë³µì¡ë„ ì ìˆ˜: {(log_count * 0.1 + condition_count * 0.2 + merge_count * 2 + loop_df_ops * 5):.1f}")
            print(f"     (ë¡œê¹…Ã—0.1 + ì¡°ê±´ë¬¸Ã—0.2 + mergeÃ—2 + ë°˜ë³µë¬¸DFì—°ì‚°Ã—5)")
    
    def generate_optimization_report(self, results):
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ë³´ê³ ì„œ"""
        print("\n" + "="*80)
        print("ğŸ“ˆ classify_activities ìµœì í™” ë¶„ì„ ë³´ê³ ì„œ")
        print("="*80)
        
        logging_results = results.get('logging_performance', {})
        function_results = results.get('function_performance', {})
        
        # ë¡œê¹… ì˜¤ë²„í—¤ë“œ ë¶„ì„
        if logging_results:
            critical_time = logging_results.get(logging.CRITICAL, {}).get('avg_time', 0)
            info_time = logging_results.get(logging.INFO, {}).get('avg_time', 0)
            
            if critical_time > 0:
                logging_overhead = ((info_time - critical_time) / info_time) * 100
                print(f"ğŸ” ë¡œê¹… ì˜¤ë²„í—¤ë“œ ë¶„ì„:")
                print(f"  â€¢ ë¡œê¹… ì—†ìŒ: {critical_time:.3f}ì´ˆ")
                print(f"  â€¢ ê¸°ë³¸ ë¡œê¹…: {info_time:.3f}ì´ˆ")
                print(f"  â€¢ ë¡œê¹… ì˜¤ë²„í—¤ë“œ: {logging_overhead:.1f}%")
                print()
        
        # í•¨ìˆ˜ë³„ ì„±ëŠ¥ ë¶„ì„
        if function_results:
            print("ğŸ¯ ë³‘ëª© í•¨ìˆ˜ ë¶„ì„:")
            sorted_functions = sorted(function_results.items(), key=lambda x: x[1], reverse=True)
            for func_name, time_taken in sorted_functions:
                print(f"  â€¢ {func_name}: {time_taken:.3f}ì´ˆ")
            print()
        
        # ìµœì í™” ê¶Œì¥ì‚¬í•­
        print("ğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        print("  1. ğŸš¨ ë¡œê¹… ë ˆë²¨ ìµœì í™”")
        print("     - ìš´ì˜ í™˜ê²½ì—ì„œëŠ” WARNING ì´ìƒìœ¼ë¡œ ì„¤ì •")
        print("     - ë””ë²„ê·¸ ë¡œê¹… 373ê°œ ì¤‘ í•µì‹¬ë§Œ ìœ ì§€")
        print()
        print("  2. ğŸ”„ ë°ì´í„° ë¡œë“œ ìºì‹±")
        print("     - get_employee_work_typeì˜ claim_data ìºì‹±")
        print("     - PerformanceCacheì— ì¶”ê°€")
        print()
        print("  3. ğŸ—ï¸ í•¨ìˆ˜ ë¶„í• ")
        print("     - 1,558ì¤„ ê±°ëŒ€ í•¨ìˆ˜ë¥¼ ì‘ì€ í•¨ìˆ˜ë“¤ë¡œ ë¶„í• ")
        print("     - ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì ìš©")
        print()
        print("  4. âš¡ DataFrame ì—°ì‚° ìµœì í™”")
        print("     - ë°˜ë³µì ì¸ merge ì—°ì‚°ì„ í•œ ë²ˆìœ¼ë¡œ í†µí•©")
        print("     - ë²¡í„°í™” ì—°ì‚° í™œìš©")
        print()
        print("  5. ğŸ¯ ì¡°ê±´ë¶€ ì‹¤í–‰")
        print("     - ë¶ˆí•„ìš”í•œ ì—°ì‚°ë“¤ì„ ì¡°ê±´ë¶€ë¡œ ì‹¤í–‰")
        print("     - Early return íŒ¨í„´ í™œìš©")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ classify_activities ìƒì„¸ í”„ë¡œíŒŒì¼ë§ ì‹œì‘")
    print("="*60)
    
    profiler = ClassifyActivitiesProfiler()
    
    # 1. í•¨ìˆ˜ ë³µì¡ë„ ë¶„ì„
    profiler.analyze_function_complexity()
    
    # 2. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
    results = profiler.profile_classify_activities()
    
    # 3. ìµœì í™” ê¶Œì¥ì‚¬í•­ ë³´ê³ ì„œ
    profiler.generate_optimization_report(results)

if __name__ == "__main__":
    main()