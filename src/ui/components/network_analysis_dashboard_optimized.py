"""
ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸ - ì„±ëŠ¥ ìµœì í™” ë²„ì „
ì¡°ì§ ì „ì²´ì˜ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ë° ì‹œê°í™”
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta, date
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
import matplotlib.pyplot as plt
import networkx as nx
import sqlite3
from functools import lru_cache
import concurrent.futures
from collections import defaultdict

from ...analysis.network_analyzer import NetworkAnalyzer
from ...database import DatabaseManager
from .common.organization_selector import OrganizationSelector

class NetworkAnalysisDashboard:
    """ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸ - ì„±ëŠ¥ ìµœì í™”"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db_manager = db_manager
        self.logger = logging.getLogger(__name__)
        self.network_analyzer = NetworkAnalyzer("data/sambio_human.db")
        self._tag_data_cache = None
        self._cache_date = None
        self._date_range_cache = None
        self.org_selector = OrganizationSelector()
        
    @property
    def tag_data(self):
        """íƒœê·¸ ë°ì´í„° ìºì‹±"""
        if self._tag_data_cache is None:
            from ...data_processing import PickleManager
            pickle_manager = PickleManager()
            self._tag_data_cache = pickle_manager.load_dataframe(name='tag_data')
            
            if self._tag_data_cache is not None:
                # ë‚ ì§œì™€ ì‹œê°„ ì»¬ëŸ¼ ì‚¬ì „ ì²˜ë¦¬
                self._tag_data_cache['ENTE_DT'] = pd.to_numeric(self._tag_data_cache['ENTE_DT'], errors='coerce')
                self._tag_data_cache['time_str'] = self._tag_data_cache['ì¶œì…ì‹œê°'].astype(str).str.zfill(6)
                # timestampë¥¼ ë¯¸ë¦¬ ìƒì„±
                self._tag_data_cache['timestamp'] = pd.to_datetime(
                    self._tag_data_cache['ENTE_DT'].astype(str) + ' ' + self._tag_data_cache['time_str'],
                    format='%Y%m%d %H%M%S',
                    errors='coerce'
                )
                # ì¸ë±ìŠ¤ ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ ê²€ìƒ‰
                self._tag_data_cache.set_index('timestamp', inplace=True, drop=False)
                
        return self._tag_data_cache
    
    def get_data_date_range(self):
        """ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ë‚ ì§œ ë²”ìœ„ ë°˜í™˜"""
        if self._date_range_cache is not None:
            return self._date_range_cache
            
        if self.tag_data is None or self.tag_data.empty:
            return None, None
            
        try:
            # íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
            dates = self.tag_data['timestamp'].dt.date
            min_date = dates.min()
            max_date = dates.max()
            
            # ë‚ ì§œë³„ ë°ì´í„° ê°œìˆ˜ ê³„ì‚°
            date_counts = dates.value_counts().sort_index()
            
            self._date_range_cache = (min_date, max_date, date_counts)
            return min_date, max_date, date_counts
            
        except Exception as e:
            self.logger.error(f"ë‚ ì§œ ë²”ìœ„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return None, None, pd.Series()
    
    def render(self):
        """ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        st.markdown("### ğŸŒ ì¡°ì§ ë„¤íŠ¸ì›Œí¬ ë¶„ì„")
        
        # ë°ì´í„° ë¡œë“œ ìƒíƒœ í‘œì‹œ
        if self.tag_data is None:
            st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„° ë‚ ì§œ ë²”ìœ„ í™•ì¸
        min_date, max_date, date_counts = self.get_data_date_range()
        
        if min_date is None or max_date is None:
            st.error("ë°ì´í„°ì˜ ë‚ ì§œ ë²”ìœ„ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„° ê¸°ê°„ ì •ë³´ í‘œì‹œ
        st.info(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {min_date.strftime('%Y-%m-%d')} ~ {max_date.strftime('%Y-%m-%d')} (ì´ {len(date_counts)}ì¼)")
        
        # íƒ­ ì„¤ì • - ë¶„ì„ ì„¤ì •/ê²°ê³¼ì™€ ë¶„ì„ ì´ë ¥
        tab1, tab2 = st.tabs(["ğŸ“‹ ë„¤íŠ¸ì›Œí¬ ë¶„ì„", "ğŸ“ ë¶„ì„ ì´ë ¥"])
        
        with tab1:
            st.markdown("#### ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •")
            
            # ë¶„ì„ ìœ í˜• ì„ íƒ
            analysis_type = st.selectbox(
                "ë¶„ì„ ìœ í˜• ì„ íƒ",
                ["ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬", "ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬", "ì‹œê³„ì—´ ë™ì  ë„¤íŠ¸ì›Œí¬", "í™œë™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬"],
                help="ë¶„ì„í•˜ê³ ì í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”."
            )
            
            # ê¸°ê°„ ì„¤ì • ì„¹ì…˜
            st.markdown("##### ğŸ“… ë¶„ì„ ê¸°ê°„ ì„¤ì •")
            col1, col2 = st.columns(2)
            
            # ê¸°ë³¸ ë‚ ì§œ ì„¤ì • (ì „ì²´ ê¸°ê°„)
            default_end = max_date
            default_start = min_date
            
            with col1:
                start_date = st.date_input(
                    "ì‹œì‘ ë‚ ì§œ",
                    value=default_start,
                    min_value=min_date,
                    max_value=max_date,
                    key="network_start_date",
                    help=f"ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ: {min_date} ~ {max_date}"
                )
            with col2:
                end_date = st.date_input(
                    "ì¢…ë£Œ ë‚ ì§œ",
                    value=default_end,
                    min_value=min_date,
                    max_value=max_date,
                    key="network_end_date",
                    help=f"ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ: {min_date} ~ {max_date}"
                )
            
            # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
            if start_date > end_date:
                st.error("ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
                return
            
            # ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            selected_dates = pd.date_range(start_date, end_date).date
            data_exists = any(d in date_counts.index for d in selected_dates)
            
            if not data_exists:
                st.warning(f"ì„ íƒí•œ ê¸°ê°„({start_date} ~ {end_date})ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                
                # ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ í‘œì‹œ
                with st.expander("ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ í™•ì¸"):
                    # ì›”ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
                    monthly_data = date_counts.groupby(pd.Grouper(freq='M')).sum()
                    if not monthly_data.empty:
                        fig = px.bar(
                            x=monthly_data.index,
                            y=monthly_data.values,
                            labels={'x': 'ì›”', 'y': 'ë°ì´í„° ê°œìˆ˜'},
                            title='ì›”ë³„ ë°ì´í„° ë¶„í¬'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                return
            
            # ë¶„ì„ ë²”ìœ„ ì„¤ì •
            st.markdown("##### ğŸ¯ ë¶„ì„ ë²”ìœ„ ì„¤ì •")
            
            col1, col2 = st.columns(2)
            with col1:
                analysis_scope = st.radio(
                    "ë¶„ì„ ë²”ìœ„",
                    ["ì „ì²´ ì¡°ì§", "íŠ¹ì • ì¡°ì§", "íŠ¹ì • ê°œì¸"],
                    help="ë¶„ì„í•  ëŒ€ìƒì˜ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”."
                )
            
            with col2:
                selected_targets = []
                org_selection = {}
                
                if analysis_scope == "íŠ¹ì • ì¡°ì§":
                    # ê³„ì¸µì  ì¡°ì§ ì„ íƒ
                    st.markdown("##### ğŸ¢ ì¡°ì§ ì„ íƒ")
                    org_selection = self.org_selector.render_selection(
                        key_prefix="network_org",
                        allow_multiple=False,
                        show_employee_count=True
                    )
                    
                    # ì„ íƒëœ ì¡°ì§ í‘œì‹œ ì´ë¦„
                    selected_targets = [self.org_selector.get_selection_display_name(org_selection)]
                    
                elif analysis_scope == "íŠ¹ì • ê°œì¸":
                    # ê°œì¸ ì„ íƒ
                    employees = self.get_employees_cached()
                    
                    # ê²€ìƒ‰ ê¸°ëŠ¥
                    search_term = st.text_input(
                        "ì§ì› ê²€ìƒ‰",
                        placeholder="ì´ë¦„ ë˜ëŠ” ì‚¬ë²ˆìœ¼ë¡œ ê²€ìƒ‰",
                        help="ì§ì› ì´ë¦„ì´ë‚˜ ì‚¬ë²ˆì„ ì…ë ¥í•˜ì—¬ ê²€ìƒ‰í•˜ì„¸ìš”."
                    )
                    
                    # ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§
                    if search_term:
                        filtered_employees = [
                            emp for emp in employees 
                            if search_term.lower() in emp.lower()
                        ]
                    else:
                        filtered_employees = employees[:20]  # ì²˜ìŒ 20ëª…ë§Œ í‘œì‹œ
                    
                    selected_employees = st.multiselect(
                        "ì§ì› ì„ íƒ",
                        filtered_employees,
                        help="ë¶„ì„í•  ì§ì›ì„ ì„ íƒí•˜ì„¸ìš”. ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                    )
                    selected_targets = selected_employees
            
            # ì„ íƒëœ ë²”ìœ„ í™•ì¸
            if analysis_scope == "íŠ¹ì • ì¡°ì§" and org_selection.get('center') == "ì „ì²´":
                st.warning("íŠ¹ì • ì¡°ì§ì„ ì„ íƒí•´ì£¼ì„¸ìš”. 'ì „ì²´' ì„ íƒ ì‹œ ì „ì²´ ì¡°ì§ ë¶„ì„ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                return
            elif analysis_scope == "íŠ¹ì • ê°œì¸" and not selected_targets:
                st.warning("ë¶„ì„í•  ì§ì›ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            # ë¶„ì„ ìœ í˜•ë³„ ì¶”ê°€ ì„¤ì •
            st.markdown("##### âš™ï¸ ì„¸ë¶€ ì„¤ì •")
            
            if analysis_type == "ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬":
                col1, col2, col3 = st.columns(3)
                with col1:
                    interaction_threshold = st.slider(
                        "ì‹œê°„ ë‹¨ìœ„ (ë¶„)",
                        min_value=15,
                        max_value=60,
                        value=30,
                        step=15,
                        help="ê°™ì€ ìœ„ì¹˜ì—ì„œ ì´ ì‹œê°„ ë‚´ì— ìˆìœ¼ë©´ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ê°„ì£¼"
                    )
                with col2:
                    department_filter = st.selectbox(
                        "ë¶€ì„œ í•„í„°",
                        ["ì „ì²´"] + self.get_departments_cached()
                    )
                with col3:
                    visualization_type = st.selectbox(
                        "ì‹œê°í™” ìœ í˜•",
                        ["Force-directed", "Circular", "Hierarchical"]
                    )
            
            elif analysis_type == "ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬":
                col1, col2 = st.columns(2)
                with col1:
                    # ê¸°ì¡´ analysis_levelì„ ì‚­ì œí•˜ê³  ìœ„ì˜ analysis_scopeë¡œ ëŒ€ì²´
                    pass
                with col2:
                    time_window = st.selectbox(
                        "ì‹œê°„ëŒ€",
                        ["ì „ì²´", "ì£¼ê°„(08:00-20:00)", "ì•¼ê°„(20:00-08:00)"]
                    )
            
            elif analysis_type == "ì‹œê³„ì—´ ë™ì  ë„¤íŠ¸ì›Œí¬":
                col1, col2, col3 = st.columns(3)
                with col1:
                    time_granularity = st.selectbox(
                        "ì‹œê°„ ë‹¨ìœ„",
                        ["ì‹œê°„ë³„", "ì¼ë³„", "ì£¼ë³„"]
                    )
                with col2:
                    network_type = st.selectbox(
                        "ë„¤íŠ¸ì›Œí¬ ìœ í˜•",
                        ["ìƒí˜¸ì‘ìš©", "ì´ë™", "í˜‘ì—…"]
                    )
                with col3:
                    animation_speed = st.slider(
                        "ì• ë‹ˆë©”ì´ì…˜ ì†ë„",
                        min_value=100,
                        max_value=2000,
                        value=500,
                        step=100
                    )
            
            elif analysis_type == "í™œë™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬":
                activity_types = st.multiselect(
                    "ë¶„ì„í•  í™œë™ ìœ í˜•",
                    ["ì—…ë¬´", "íšŒì˜", "ì‹ì‚¬", "íœ´ì‹", "ì´ë™"],
                    default=["ì—…ë¬´", "íšŒì˜"]
                )
                network_method = st.selectbox(
                    "ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ë°©ë²•",
                    ["ë™ì‹œ í™œë™", "ìˆœì°¨ í™œë™", "í™œë™ ì „í™˜"]
                )
            
            # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
            st.markdown("---")
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                analyze_button = st.button(
                    "ğŸš€ ë¶„ì„ ì‹œì‘",
                    type="primary",
                    use_container_width=True,
                    help="ì„¤ì •í•œ íŒŒë¼ë¯¸í„°ë¡œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤."
                )
            
            # ë¶„ì„ ì‹¤í–‰
            if analyze_button or st.session_state.get('rerun_analysis', False):
                # ë¶„ì„ íŒŒë¼ë¯¸í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['network_analysis_params'] = {
                    'analysis_type': analysis_type,
                    'start_date': start_date,
                    'end_date': end_date,
                    'timestamp': datetime.now(),
                    'analysis_scope': analysis_scope,
                    'selected_targets': selected_targets,
                    'org_selection': org_selection if analysis_scope == "íŠ¹ì • ì¡°ì§" else None
                }
                
                # ë¶„ì„ ìœ í˜•ë³„ ì¶”ê°€ íŒŒë¼ë¯¸í„° ì €ì¥
                if analysis_type == "ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬":
                    st.session_state['network_analysis_params'].update({
                        'interaction_threshold': interaction_threshold,
                        'department_filter': department_filter,
                        'visualization_type': visualization_type
                    })
                elif analysis_type == "ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬":
                    st.session_state['network_analysis_params'].update({
                        'time_window': time_window
                    })
                elif analysis_type == "ì‹œê³„ì—´ ë™ì  ë„¤íŠ¸ì›Œí¬":
                    st.session_state['network_analysis_params'].update({
                        'time_granularity': time_granularity,
                        'network_type': network_type,
                        'animation_speed': animation_speed
                    })
                elif analysis_type == "í™œë™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬":
                    st.session_state['network_analysis_params'].update({
                        'activity_types': activity_types,
                        'network_method': network_method
                    })
                
                # ë¶„ì„ ì¦‰ì‹œ ì‹¤í–‰
                st.session_state['network_analysis_running'] = True
            
            # ë¶„ì„ ì‹œì‘ ë²„íŠ¼ì´ ëˆŒë ¸ê±°ë‚˜ ì§„í–‰ ì¤‘ì¸ ê²½ìš° ê²°ê³¼ í‘œì‹œ
            if st.session_state.get('network_analysis_running', False):
                params = st.session_state.get('network_analysis_params', {})
                
                # ë¶„ì„ ì •ë³´ í‘œì‹œ
                st.markdown("#### ğŸ“Š ë¶„ì„ ì§„í–‰ ì¤‘...")
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                progress_container = st.container()
                with progress_container:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™©
                    steps = [
                        "ë°ì´í„° ë¡œë”© ì¤‘...",
                        "ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...",
                        "ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ì¤‘...",
                        "ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘...",
                        "ì‹œê°í™” ìƒì„± ì¤‘..."
                    ]
                    
                    for i, step in enumerate(steps):
                        progress = (i + 1) / len(steps)
                        progress_bar.progress(progress)
                        status_text.text(f"ğŸ”„ {step} ({int(progress * 100)}%)")
                        
                        # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰ (ë‹¨ê³„ë³„ë¡œ)
                        if i == len(steps) - 1:
                            # ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
                            try:
                                if params['analysis_type'] == "ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬":
                                    self.render_interaction_network_with_params(params)
                                elif params['analysis_type'] == "ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬":
                                    self.render_movement_network_with_params(params)
                                elif params['analysis_type'] == "ì‹œê³„ì—´ ë™ì  ë„¤íŠ¸ì›Œí¬":
                                    self.render_temporal_network_with_params(params)
                                elif params['analysis_type'] == "í™œë™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬":
                                    self.render_activity_network_with_params(params)
                                
                                # ì™„ë£Œ ìƒíƒœ
                                progress_bar.progress(1.0)
                                status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
                                
                                # ë¶„ì„ ì™„ë£Œ
                                st.session_state['network_analysis_running'] = False
                                
                                # ë¶„ì„ ì´ë ¥ ì €ì¥
                                if 'network_analysis_history' not in st.session_state:
                                    st.session_state['network_analysis_history'] = []
                                
                                # í˜„ì¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì´ë ¥ì— ì¶”ê°€
                                history_entry = {
                                    **params,
                                    'completed_at': datetime.now(),
                                    'id': len(st.session_state['network_analysis_history'])
                                }
                                st.session_state['network_analysis_history'].append(history_entry)
                                
                            except Exception as e:
                                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                                st.session_state['network_analysis_running'] = False
        
        with tab2:
            # ë¶„ì„ ì´ë ¥ íƒ­
            st.markdown("#### ğŸ“ ë¶„ì„ ì´ë ¥")
            
            if 'network_analysis_history' in st.session_state and st.session_state['network_analysis_history']:
                # ì´ë ¥ì„ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
                history = sorted(st.session_state['network_analysis_history'], 
                               key=lambda x: x['completed_at'], reverse=True)
                
                # ì´ë ¥ í•„í„°ë§ ì˜µì…˜
                col1, col2 = st.columns([2, 1])
                with col1:
                    filter_type = st.selectbox(
                        "ë¶„ì„ ìœ í˜• í•„í„°",
                        ["ì „ì²´"] + ["ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬", "ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬", 
                         "ì‹œê³„ì—´ ë™ì  ë„¤íŠ¸ì›Œí¬", "í™œë™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬"]
                    )
                
                # í•„í„°ë§ëœ ì´ë ¥
                if filter_type != "ì „ì²´":
                    filtered_history = [h for h in history if h['analysis_type'] == filter_type]
                else:
                    filtered_history = history
                
                # ì´ë ¥ í‘œì‹œ
                for idx, entry in enumerate(filtered_history[:10]):  # ìµœê·¼ 10ê±´ë§Œ í‘œì‹œ
                    with st.expander(
                        f"{entry['analysis_type']} - "
                        f"{entry['completed_at'].strftime('%Y-%m-%d %H:%M:%S')}",
                        expanded=False
                    ):
                        # ë¶„ì„ ìƒì„¸ ì •ë³´
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.write(f"**ê¸°ê°„**: {entry['start_date']} ~ {entry['end_date']}")
                        with col2:
                            st.write(f"**ë¶„ì„ ë²”ìœ„**: {entry.get('analysis_scope', 'ì „ì²´ ì¡°ì§')}")
                        with col3:
                            if entry.get('analysis_scope') == "íŠ¹ì • ì¡°ì§" and entry.get('org_selection'):
                                org_name = self.org_selector.get_selection_display_name(entry['org_selection'])
                                st.write(f"**ëŒ€ìƒ**: {org_name}")
                            elif entry.get('selected_targets'):
                                st.write(f"**ëŒ€ìƒ**: {', '.join(entry['selected_targets'][:3])}...")
                        
                        # ì„¤ì • ìƒì„¸
                        if entry['analysis_type'] == "ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬":
                            st.write(f"- ìƒí˜¸ì‘ìš© ì‹œê°„: {entry.get('interaction_threshold', 30)}ë¶„")
                            st.write(f"- ë¶€ì„œ í•„í„°: {entry.get('department_filter', 'ì „ì²´')}")
                            st.write(f"- ì‹œê°í™”: {entry.get('visualization_type', 'Force-directed')}")
                        
                        # ë‹¤ì‹œ ì‹¤í–‰ ë²„íŠ¼
                        if st.button(f"ğŸ”„ ì´ ì„¤ì •ìœ¼ë¡œ ë‹¤ì‹œ ë¶„ì„", key=f"rerun_{entry['id']}_{idx}"):
                            # ì´ì „ ì„¤ì •ì„ í˜„ì¬ ì„¤ì •ìœ¼ë¡œ ë³µì‚¬
                            st.session_state['network_analysis_params'] = entry.copy()
                            st.session_state['network_analysis_params']['timestamp'] = datetime.now()
                            st.session_state['rerun_analysis'] = True
                            st.rerun()
                
                # ì´ë ¥ ì‚­ì œ ë²„íŠ¼
                if st.button("ğŸ—‘ï¸ ì „ì²´ ì´ë ¥ ì‚­ì œ", type="secondary"):
                    if st.checkbox("ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
                        st.session_state['network_analysis_history'] = []
                        st.success("ë¶„ì„ ì´ë ¥ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
            else:
                st.info("ì•„ì§ ë¶„ì„ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ì´ê³³ì— ê¸°ë¡ë©ë‹ˆë‹¤.")
        
        # ì´ì „ ë¶„ì„ ì„¤ì •ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        if st.session_state.get('rerun_analysis', False):
            st.session_state['rerun_analysis'] = False
            # ì²« ë²ˆì§¸ íƒ­ìœ¼ë¡œ ì „í™˜í•˜ê³  ë¶„ì„ ì‹¤í–‰
            st.session_state['network_analysis_running'] = True
    
    def get_filtered_data(self, start_date: date, end_date: date, department: str = None,
                         analysis_scope: str = None, selected_targets: List[str] = None,
                         org_selection: Dict = None) -> pd.DataFrame:
        """ë‚ ì§œì™€ ë²”ìœ„ë¡œ í•„í„°ë§ëœ ë°ì´í„° ë°˜í™˜ - ìµœì í™”"""
        if self.tag_data is None:
            return pd.DataFrame()
            
        # ë‚ ì§œë¥¼ timestampë¡œ ë³€í™˜
        start_timestamp = pd.Timestamp(start_date)
        end_timestamp = pd.Timestamp(end_date) + pd.Timedelta(days=1)
        
        # ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•œ ë¹ ë¥¸ í•„í„°ë§
        filtered = self.tag_data.loc[start_timestamp:end_timestamp].copy()
        
        # ë¶„ì„ ë²”ìœ„ì— ë”°ë¥¸ í•„í„°ë§
        if analysis_scope == "íŠ¹ì • ì¡°ì§" and org_selection:
            # ì¡°ì§ ì„ íƒì— ë”°ë¥¸ ì§ì› ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            employees = self.org_selector.get_employees_by_selection(org_selection)
            employee_ids = [emp['id'] for emp in employees]
            filtered = filtered[filtered['ì‚¬ë²ˆ'].astype(str).isin(employee_ids)]
        elif analysis_scope == "íŠ¹ì • ê°œì¸" and selected_targets:
            # ì‚¬ë²ˆë§Œ ì¶”ì¶œ ("ì‚¬ë²ˆ - ì´ë¦„" í˜•ì‹ì—ì„œ)
            employee_ids = []
            for target in selected_targets:
                if ' - ' in target:
                    employee_ids.append(target.split(' - ')[0])
                else:
                    employee_ids.append(target)
            filtered = filtered[filtered['ì‚¬ë²ˆ'].astype(str).isin(employee_ids)]
        
        # ë¶€ì„œ í•„í„°ë§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if department and department != "ì „ì²´":
            filtered = filtered[filtered['TEAM'] == department]
            
        return filtered
    
    def analyze_interactions_optimized(self, start_date: date, end_date: date, 
                                     threshold: int, department: str,
                                     analysis_scope: str = None, selected_targets: List[str] = None,
                                     org_selection: Dict = None) -> Optional[Dict]:
        """ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë¶„ì„ - ìµœì í™” ë²„ì „"""
        try:
            # í•„í„°ë§ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            filtered_data = self.get_filtered_data(start_date, end_date, department, analysis_scope, selected_targets, org_selection)
            
            if filtered_data.empty:
                return None
            
            # ìœ„ì¹˜ë³„, ì‹œê°„ëŒ€ë³„ë¡œ ê·¸ë£¹í™” (30ë¶„ ë‹¨ìœ„)
            filtered_data['time_slot'] = filtered_data['timestamp'].dt.floor('30min')
            
            # ë²¡í„°í™”ëœ ì—°ì‚°ìœ¼ë¡œ ìƒí˜¸ì‘ìš© ì°¾ê¸°
            interactions = []
            
            # ìœ„ì¹˜ì™€ ì‹œê°„ëŒ€ë³„ë¡œ ê·¸ë£¹í™”
            grouped = filtered_data.groupby(['DR_NM', 'time_slot'])
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìƒí˜¸ì‘ìš© ê³„ì‚°
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                futures = []
                
                for (location, time_slot), group in grouped:
                    if len(group) < 2:
                        continue
                    futures.append(
                        executor.submit(self._process_interaction_group, group, location, threshold)
                    )
                
                # ê²°ê³¼ ìˆ˜ì§‘
                for future in concurrent.futures.as_completed(futures):
                    result = future.result()
                    if result:
                        interactions.extend(result)
            
            if not interactions:
                return None
            
            # DataFrame ìƒì„± ë° ì§‘ê³„
            df_interactions = pd.DataFrame(interactions)
            
            # ìƒí˜¸ì‘ìš© íšŸìˆ˜ ì§‘ê³„
            interaction_counts = df_interactions.groupby(['employee1', 'employee2']).size().reset_index(name='interaction_count')
            
            # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
            G = nx.Graph()
            
            for _, row in interaction_counts.iterrows():
                G.add_edge(
                    str(row['employee1']), 
                    str(row['employee2']), 
                    weight=row['interaction_count']
                )
            
            # ì‚¬ë²ˆ-ì´ë¦„ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
            name_mapping = self.get_employee_name_mapping()
            
            # ì¤‘ì‹¬ì„± ê³„ì‚° (ë…¸ë“œê°€ ì¶©ë¶„í•  ë•Œë§Œ)
            if G.number_of_nodes() > 0:
                degree_centrality = nx.degree_centrality(G)
                betweenness_centrality = nx.betweenness_centrality(G) if G.number_of_nodes() > 2 else {}
                closeness_centrality = nx.closeness_centrality(G) if nx.is_connected(G) else {}
            else:
                degree_centrality = {}
                betweenness_centrality = {}
                closeness_centrality = {}
            
            return {
                'graph': G,
                'interactions': df_interactions,
                'interaction_counts': interaction_counts,
                'degree_centrality': degree_centrality,
                'betweenness_centrality': betweenness_centrality,
                'closeness_centrality': closeness_centrality,
                'num_nodes': G.number_of_nodes(),
                'num_edges': G.number_of_edges(),
                'density': nx.density(G) if G.number_of_nodes() > 0 else 0,
                'name_mapping': name_mapping
            }
            
        except Exception as e:
            self.logger.error(f"ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _process_interaction_group(self, group: pd.DataFrame, location: str, threshold: int) -> List[Dict]:
        """ê·¸ë£¹ ë‚´ ìƒí˜¸ì‘ìš© ì²˜ë¦¬ - í—¬í¼ í•¨ìˆ˜"""
        interactions = []
        employees = group['ì‚¬ë²ˆ'].unique()
        
        # ì§ì› ìŒ ìƒì„± (ì¤‘ë³µ ì œê±°)
        for i, emp1 in enumerate(employees):
            for emp2 in employees[i+1:]:
                interactions.append({
                    'employee1': str(emp1),
                    'employee2': str(emp2),
                    'location': location,
                    'timestamp': group['timestamp'].iloc[0]
                })
        
        return interactions
    
    def render_interaction_network_with_params(self, params: dict):
        """íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬ ë Œë”ë§"""
        self.render_interaction_network(
            params['start_date'],
            params['end_date'],
            params.get('interaction_threshold', 30),
            params.get('department_filter', "ì „ì²´"),
            params.get('visualization_type', "Force-directed"),
            params.get('analysis_scope', "ì „ì²´ ì¡°ì§"),
            params.get('selected_targets', []),
            params.get('org_selection', {})
        )
    
    def render_movement_network_with_params(self, params: dict):
        """íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ì´ë™ ë„¤íŠ¸ì›Œí¬ ë Œë”ë§"""
        self.render_movement_network(
            params['start_date'],
            params['end_date'],
            params.get('analysis_level', "ì „ì²´"),
            params.get('time_window', "ì „ì²´"),
            params.get('analysis_scope', "ì „ì²´ ì¡°ì§"),
            params.get('selected_targets', []),
            params.get('org_selection', {})
        )
    
    def render_temporal_network_with_params(self, params: dict):
        """íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ì‹œê³„ì—´ ë„¤íŠ¸ì›Œí¬ ë Œë”ë§"""
        self.render_temporal_network(
            params['start_date'],
            params['end_date']
        )
    
    def render_activity_network_with_params(self, params: dict):
        """íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ í™œë™ ë„¤íŠ¸ì›Œí¬ ë Œë”ë§"""
        self.render_activity_network(
            params['start_date'],
            params['end_date']
        )
    
    def render_interaction_network(self, start_date: date, end_date: date,
                                 interaction_threshold: int = None,
                                 department_filter: str = None,
                                 visualization_type: str = None,
                                 analysis_scope: str = None,
                                 selected_targets: List[str] = None,
                                 org_selection: Dict = None):
        """ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬ ë¶„ì„"""
        st.subheader("ğŸ‘¥ ì§ì› ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬")
        
        # íŒŒë¼ë¯¸í„°ê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        if interaction_threshold is None:
            interaction_threshold = 30
        if department_filter is None:
            department_filter = "ì „ì²´"
        if visualization_type is None:
            visualization_type = "Force-directed"
        if analysis_scope is None:
            analysis_scope = "ì „ì²´ ì¡°ì§"
        if selected_targets is None:
            selected_targets = []
        
        # ë¶„ì„ ë²”ìœ„ í‘œì‹œ
        if analysis_scope == "íŠ¹ì • ì¡°ì§":
            st.info(f"ğŸ¢ ë¶„ì„ ëŒ€ìƒ ë¶€ì„œ: {', '.join(selected_targets)}")
        elif analysis_scope == "íŠ¹ì • ê°œì¸":
            st.info(f"ğŸ‘¤ ë¶„ì„ ëŒ€ìƒ ì§ì›: {', '.join(selected_targets)}")
        
        # ìƒí˜¸ì‘ìš© ë°ì´í„° ë¶„ì„
        interaction_data = self.analyze_interactions_optimized(
            start_date, end_date, interaction_threshold, department_filter,
            analysis_scope, selected_targets, org_selection
        )
        
        if interaction_data and interaction_data['num_nodes'] > 0:
            # ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ í‘œì‹œ
            self.display_network_metrics(interaction_data)
            
            # ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
            self.visualize_interaction_network(interaction_data, visualization_type)
            
            # ì¤‘ì‹¬ì„± ë¶„ì„
            if interaction_data['degree_centrality']:
                self.display_centrality_analysis(interaction_data)
            
            # ì»¤ë®¤ë‹ˆí‹° íƒì§€
            if interaction_data['num_nodes'] > 3:
                self.display_community_detection(interaction_data)
        else:
            st.info("ì„ íƒí•œ ê¸°ê°„ì— ë¶„ì„í•  ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def analyze_movement_patterns_optimized(self, start_date: date, end_date: date,
                                          level: str, time_window: str,
                                          analysis_scope: str = None, selected_targets: List[str] = None,
                                          org_selection: Dict = None) -> Optional[Dict]:
        """ê³µê°„ ì´ë™ íŒ¨í„´ ë¶„ì„ - ìµœì í™” ë²„ì „"""
        try:
            # í•„í„°ë§ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            filtered_data = self.get_filtered_data(start_date, end_date, None, analysis_scope, selected_targets, org_selection)
            
            if filtered_data.empty:
                return None
            
            # ì‹œê°„ëŒ€ í•„í„°ë§ (ë²¡í„°í™”)
            if time_window != "ì „ì²´":
                hour = filtered_data['timestamp'].dt.hour
                if time_window == "ì£¼ê°„(08:00-20:00)":
                    filtered_data = filtered_data[(hour >= 8) & (hour < 20)]
                elif time_window == "ì•¼ê°„(20:00-08:00)":
                    filtered_data = filtered_data[(hour >= 20) | (hour < 8)]
                # ... ê¸°íƒ€ ì‹œê°„ëŒ€ ì²˜ë¦¬
            
            # ì´ë™ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
            df = filtered_data.reset_index(drop=True)
            df = df.sort_values(['ì‚¬ë²ˆ', 'timestamp'])
            
            # ë²¡í„°í™”ëœ ì´ì „ ìœ„ì¹˜ ê³„ì‚°
            df['prev_location'] = df.groupby('ì‚¬ë²ˆ')['DR_NM'].shift(1)
            df['location'] = df['DR_NM']
            
            # ì´ë™ë§Œ í•„í„°ë§ (ìœ„ì¹˜ê°€ ë³€ê²½ëœ ê²½ìš°)
            movements = df[df['prev_location'].notna() & (df['location'] != df['prev_location'])].copy()
            
            if movements.empty:
                return None
            
            # ê±´ë¬¼ ë§¤í•‘ (ë²¡í„°í™”)
            movements['from_building'] = movements['prev_location'].apply(
                self.network_analyzer.mapper.get_building_from_location
            )
            movements['to_building'] = movements['location'].apply(
                self.network_analyzer.mapper.get_building_from_location
            )
            
            # ìœ íš¨í•œ ì´ë™ë§Œ í•„í„°ë§
            valid_movements = movements[
                movements['from_building'].notna() & 
                movements['to_building'].notna()
            ]
            
            # ì´ë™ í†µê³„ ê³„ì‚°
            movement_counts = valid_movements.groupby(
                ['from_building', 'to_building']
            ).size().reset_index(name='count')
            
            # ê±´ë¬¼ë³„ ë°©ë¬¸ í†µê³„
            building_visits = valid_movements['to_building'].value_counts()
            
            return {
                'movements': valid_movements,
                'movement_counts': movement_counts,
                'building_visits': building_visits,
                'total_movements': len(valid_movements),
                'unique_paths': len(movement_counts)
            }
            
        except Exception as e:
            self.logger.error(f"ì´ë™ íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def render_movement_network(self, start_date: date, end_date: date,
                              analysis_level: str = None, time_window: str = None,
                              analysis_scope: str = None, selected_targets: List[str] = None,
                              org_selection: Dict = None):
        """ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬ ë¶„ì„"""
        st.subheader("ğŸ¢ ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬")
        
        # íŒŒë¼ë¯¸í„°ê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        if analysis_level is None:
            analysis_level = "ì „ì²´"
        if time_window is None:
            time_window = "ì „ì²´"
        if analysis_scope is None:
            analysis_scope = "ì „ì²´ ì¡°ì§"
        if selected_targets is None:
            selected_targets = []
        
        # ë¶„ì„ ë²”ìœ„ í‘œì‹œ
        if analysis_scope == "íŠ¹ì • ì¡°ì§":
            st.info(f"ğŸ¢ ë¶„ì„ ëŒ€ìƒ ë¶€ì„œ: {', '.join(selected_targets)}")
        elif analysis_scope == "íŠ¹ì • ê°œì¸":
            st.info(f"ğŸ‘¤ ë¶„ì„ ëŒ€ìƒ ì§ì›: {', '.join(selected_targets)}")
        
        # ì´ë™ ë°ì´í„° ë¶„ì„
        movement_data = self.analyze_movement_patterns_optimized(
            start_date, end_date, analysis_level, time_window,
            analysis_scope, selected_targets, org_selection
        )
        
        if movement_data and movement_data['total_movements'] > 0:
            # ì „ì²´ ì´ë™ í†µê³„
            self.display_movement_statistics(movement_data)
            
            # ê³µê°„ ì´ë™ ë§µ ì‹œê°í™”
            self.visualize_movement_map(movement_data)
            
            # ì´ë™ íŒ¨í„´ ë¶„ì„
            self.display_movement_patterns(movement_data)
        else:
            st.info("ì„ íƒí•œ ê¸°ê°„ì— ë¶„ì„í•  ì´ë™ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    @lru_cache(maxsize=1)
    def get_departments_cached(self) -> List[str]:
        """ë¶€ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° - ìºì‹±"""
        try:
            if self.tag_data is not None and 'TEAM' in self.tag_data.columns:
                departments = self.tag_data['TEAM'].dropna().unique().tolist()
                return sorted(departments)
            return []
        except Exception as e:
            self.logger.error(f"ë¶€ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return []
    
    @lru_cache(maxsize=1)
    def get_employees_cached(self) -> List[str]:
        """ì§ì› ëª©ë¡ ê°€ì ¸ì˜¤ê¸° - ìºì‹±"""
        try:
            if self.tag_data is not None:
                # ì‚¬ë²ˆê³¼ ì´ë¦„ì´ ìˆë‹¤ë©´ ê²°í•©í•˜ì—¬ í‘œì‹œ
                if 'ì‚¬ë²ˆ' in self.tag_data.columns:
                    employees = self.tag_data['ì‚¬ë²ˆ'].dropna().unique()
                    # ì´ë¦„ ì •ë³´ê°€ ìˆë‹¤ë©´ ì¶”ê°€
                    if 'ì„±ëª…' in self.tag_data.columns:
                        emp_info = self.tag_data[['ì‚¬ë²ˆ', 'ì„±ëª…']].drop_duplicates()
                        emp_list = []
                        for _, row in emp_info.iterrows():
                            if pd.notna(row['ì‚¬ë²ˆ']) and pd.notna(row['ì„±ëª…']):
                                emp_list.append(f"{row['ì‚¬ë²ˆ']} - {row['ì„±ëª…']}")
                            elif pd.notna(row['ì‚¬ë²ˆ']):
                                emp_list.append(str(row['ì‚¬ë²ˆ']))
                        return sorted(emp_list)
                    else:
                        return sorted([str(emp) for emp in employees])
            return []
        except Exception as e:
            self.logger.error(f"ì§ì› ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return []
    
    @lru_cache(maxsize=1)
    def get_employee_name_mapping(self) -> Dict[str, str]:
        """ì‚¬ë²ˆ-ì´ë¦„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
        try:
            mapping = {}
            
            # íƒœê·¸ ë°ì´í„°ì—ì„œ ë§¤í•‘ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if self.tag_data is not None and 'ì‚¬ë²ˆ' in self.tag_data.columns:
                if 'ì„±ëª…' in self.tag_data.columns:
                    emp_info = self.tag_data[['ì‚¬ë²ˆ', 'ì„±ëª…']].drop_duplicates()
                    for _, row in emp_info.iterrows():
                        if pd.notna(row['ì‚¬ë²ˆ']) and pd.notna(row['ì„±ëª…']):
                            mapping[str(row['ì‚¬ë²ˆ'])] = row['ì„±ëª…']
                    return mapping
            
            # ì¡°ì§ ë°ì´í„°ì—ì„œ ë§¤í•‘ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (íƒœê·¸ ë°ì´í„°ì— ì—†ëŠ” ê²½ìš°)
            if not mapping:
                from ...data_processing import PickleManager
                pickle_manager = PickleManager()
                org_data = pickle_manager.load_dataframe(name='organization_data')
                
                if org_data is not None and 'ì‚¬ë²ˆ' in org_data.columns and 'ì„±ëª…' in org_data.columns:
                    for _, row in org_data.iterrows():
                        if pd.notna(row['ì‚¬ë²ˆ']) and pd.notna(row['ì„±ëª…']):
                            mapping[str(row['ì‚¬ë²ˆ'])] = row['ì„±ëª…']
            
            return mapping
            
        except Exception as e:
            self.logger.error(f"ì‚¬ë²ˆ-ì´ë¦„ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return {}
    
    def display_network_metrics(self, interaction_data: Dict):
        """ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ í‘œì‹œ"""
        st.markdown("#### ğŸ“Š ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ë…¸ë“œ ìˆ˜", interaction_data['num_nodes'])
        with col2:
            st.metric("ì—£ì§€ ìˆ˜", interaction_data['num_edges'])
        with col3:
            st.metric("ë„¤íŠ¸ì›Œí¬ ë°€ë„", f"{interaction_data['density']:.3f}")
        with col4:
            avg_degree = (2 * interaction_data['num_edges']) / interaction_data['num_nodes'] if interaction_data['num_nodes'] > 0 else 0
            st.metric("í‰ê·  ì—°ê²°ë„", f"{avg_degree:.2f}")
    
    def visualize_interaction_network(self, interaction_data: Dict, viz_type: str):
        """ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”"""
        st.markdown("#### ğŸŒ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”")
        
        G = interaction_data['graph']
        
        # ë…¸ë“œê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒ˜í”Œë§
        if G.number_of_nodes() > 100:
            st.warning(f"ë…¸ë“œê°€ {G.number_of_nodes()}ê°œë¡œ ë§ì•„ ìƒìœ„ 100ê°œë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
            # ì—°ê²°ì´ ë§ì€ ìƒìœ„ 100ê°œ ë…¸ë“œë§Œ ì„ íƒ
            degree_dict = dict(G.degree())
            top_nodes = sorted(degree_dict.keys(), key=lambda x: degree_dict[x], reverse=True)[:100]
            G = G.subgraph(top_nodes)
        
        # ë ˆì´ì•„ì›ƒ ì„ íƒ
        if viz_type == "Force-directed":
            pos = nx.spring_layout(G, k=1/np.sqrt(G.number_of_nodes()), iterations=50)
        elif viz_type == "Circular":
            pos = nx.circular_layout(G)
        else:  # Hierarchical
            pos = nx.kamada_kawai_layout(G)
        
        # Plotly ê·¸ë˜í”„ ìƒì„±
        edge_trace = []
        for edge in G.edges(data=True):
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_trace.append(go.Scatter(
                x=[x0, x1, None],
                y=[y0, y1, None],
                mode='lines',
                line=dict(width=0.5 + edge[2]['weight']/10, color='#888'),
                hoverinfo='none'
            ))
        
        # ë…¸ë“œ í¬ê¸° ê³„ì‚°
        node_sizes = []
        for node in G.nodes():
            degree = G.degree(node)
            size = 10 + min(degree * 2, 50)  # ìµœëŒ€ í¬ê¸° ì œí•œ
            node_sizes.append(size)
        
        # ì‚¬ë²ˆ-ì´ë¦„ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
        name_mapping = interaction_data.get('name_mapping', {})
        
        # ë…¸ë“œ ë¼ë²¨ ìƒì„± (ì´ë¦„ ìš°ì„ , ì—†ìœ¼ë©´ ì‚¬ë²ˆ)
        node_labels = []
        hover_texts = []
        for node in G.nodes():
            name = name_mapping.get(str(node), str(node))
            node_labels.append(name)
            # í˜¸ë²„ í…ìŠ¤íŠ¸ì—ëŠ” ì‚¬ë²ˆê³¼ ì´ë¦„ ëª¨ë‘ í‘œì‹œ
            hover_texts.append(f"ì‚¬ë²ˆ: {node}<br>ì´ë¦„: {name}<br>ì—°ê²°ë„: {G.degree(node)}")
        
        node_trace = go.Scatter(
            x=[pos[node][0] for node in G.nodes()],
            y=[pos[node][1] for node in G.nodes()],
            mode='markers+text',
            text=node_labels,
            textposition="top center",
            hoverinfo='text',
            hovertext=hover_texts,
            marker=dict(
                size=node_sizes,
                color=[interaction_data['degree_centrality'].get(node, 0) for node in G.nodes()],
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(
                    thickness=15,
                    title='Degree<br>Centrality',
                    xanchor='left',
                    titleside='right'
                )
            )
        )
        
        fig = go.Figure(data=edge_trace + [node_trace])
        fig.update_layout(
            showlegend=False,
            hovermode='closest',
            margin=dict(b=0, l=0, r=0, t=0),
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=600
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def display_centrality_analysis(self, interaction_data: Dict):
        """ì¤‘ì‹¬ì„± ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        st.markdown("#### ğŸ¯ ì¤‘ì‹¬ì„± ë¶„ì„")
        
        # ì‚¬ë²ˆ-ì´ë¦„ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
        name_mapping = interaction_data.get('name_mapping', {})
        
        # ìƒìœ„ 10ëª…ì˜ ì¤‘ì‹¬ ì¸ë¬¼
        centrality_data = []
        for emp_id in interaction_data['degree_centrality'].keys():
            name = name_mapping.get(str(emp_id), str(emp_id))
            centrality_data.append({
                'Employee': f"{name} ({emp_id})",
                'Degree Centrality': interaction_data['degree_centrality'][emp_id],
                'Betweenness Centrality': interaction_data['betweenness_centrality'].get(emp_id, 0),
                'Closeness Centrality': interaction_data['closeness_centrality'].get(emp_id, 0)
            })
        
        centrality_df = pd.DataFrame(centrality_data)
        
        # ìƒìœ„ 10ëª…ë§Œ í‘œì‹œ
        top_central = centrality_df.nlargest(10, 'Degree Centrality')
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig1 = px.bar(top_central, x='Employee', y='Degree Centrality',
                         title='ì—°ê²° ì¤‘ì‹¬ì„± ìƒìœ„ 10ëª…')
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            fig2 = px.bar(top_central, x='Employee', y='Betweenness Centrality',
                         title='ë§¤ê°œ ì¤‘ì‹¬ì„± ìƒìœ„ 10ëª…')
            st.plotly_chart(fig2, use_container_width=True)
    
    def visualize_movement_map(self, movement_data: Dict):
        """ê³µê°„ ì´ë™ ë§µ ì‹œê°í™”"""
        facility_image_path = Path(__file__).parent.parent.parent.parent / 'data' / 'Sambio.png'
        
        if not facility_image_path.exists():
            st.warning("ì‹œì„¤ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì´ë™ ë„¤íŠ¸ì›Œí¬ ìƒì„±
        G = nx.DiGraph()
        
        movement_counts = movement_data['movement_counts']
        for _, row in movement_counts.iterrows():
            G.add_edge(row['from_building'], row['to_building'], weight=row['count'])
        
        # matplotlib ì‹œê°í™”
        from PIL import Image
        img = Image.open(facility_image_path)
        
        fig, ax = plt.subplots(figsize=(20, 12))
        ax.imshow(img, alpha=0.7)
        
        # ë…¸ë“œ ìœ„ì¹˜ ì„¤ì •
        img_width, img_height = img.size
        pos = {}
        for node in G.nodes():
            coords = self.network_analyzer.mapper.get_coordinates(node, img_width, img_height)
            if coords:
                pos[node] = coords
        
        # ë…¸ë“œ í¬ê¸° (ë°©ë¬¸ íšŸìˆ˜ ê¸°ë°˜)
        node_sizes = []
        for node in G.nodes():
            if node in movement_data['building_visits']:
                size = 500 + movement_data['building_visits'][node] * 10
            else:
                size = 500
            node_sizes.append(size)
        
        # ë„¤íŠ¸ì›Œí¬ ê·¸ë¦¬ê¸°
        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, 
                             node_color='lightblue', alpha=0.8, ax=ax)
        
        # ì—£ì§€ ê·¸ë¦¬ê¸°
        edges = G.edges()
        weights = [G[u][v]['weight'] for u, v in edges]
        max_weight = max(weights) if weights else 1
        
        nx.draw_networkx_edges(G, pos, width=[1 + (w/max_weight)*5 for w in weights],
                             edge_color='blue', alpha=0.6, arrows=True,
                             arrowsize=20, ax=ax)
        
        # ë ˆì´ë¸”
        labels = {}
        for node in G.nodes():
            count = movement_data['building_visits'].get(node, 0)
            labels[node] = f"{node}\n({count})"
        
        nx.draw_networkx_labels(G, pos, labels, font_size=12, font_weight='bold', ax=ax)
        
        ax.set_title("ê³µê°„ ì´ë™ ë„¤íŠ¸ì›Œí¬", fontsize=16)
        ax.axis('off')
        
        st.pyplot(fig, use_container_width=True)
        plt.close()
    
    def display_movement_statistics(self, movement_data: Dict):
        """ì´ë™ í†µê³„ í‘œì‹œ"""
        st.markdown("#### ğŸ“Š ì´ë™ í†µê³„")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì´ ì´ë™ íšŸìˆ˜", movement_data['total_movements'])
        with col2:
            st.metric("ê³ ìœ  ì´ë™ ê²½ë¡œ", movement_data['unique_paths'])
        with col3:
            st.metric("ë°©ë¬¸ ê±´ë¬¼ ìˆ˜", len(movement_data['building_visits']))
        
        # ìƒìœ„ ì´ë™ ê²½ë¡œ
        st.markdown("##### ğŸ” ìƒìœ„ ì´ë™ ê²½ë¡œ")
        top_paths = movement_data['movement_counts'].nlargest(10, 'count')
        
        fig = px.bar(top_paths, 
                    x='count', 
                    y=top_paths['from_building'] + ' â†’ ' + top_paths['to_building'],
                    orientation='h',
                    title='ê°€ì¥ ë¹ˆë²ˆí•œ ì´ë™ ê²½ë¡œ Top 10')
        st.plotly_chart(fig, use_container_width=True)
    
    def display_movement_patterns(self, movement_data: Dict):
        """ì´ë™ íŒ¨í„´ ë¶„ì„ í‘œì‹œ"""
        st.markdown("#### ğŸ”„ ì´ë™ íŒ¨í„´")
        
        # ì‹œê°„ëŒ€ë³„ ì´ë™ íŒ¨í„´
        movements = movement_data['movements']
        movements['hour'] = movements['timestamp'].dt.hour
        
        hourly_movements = movements.groupby('hour').size()
        
        fig = px.line(x=hourly_movements.index, y=hourly_movements.values,
                     labels={'x': 'ì‹œê°„', 'y': 'ì´ë™ íšŸìˆ˜'},
                     title='ì‹œê°„ëŒ€ë³„ ì´ë™ íŒ¨í„´')
        st.plotly_chart(fig, use_container_width=True)
    
    def render_temporal_network(self, start_date: date, end_date: date):
        """ì‹œê³„ì—´ ë™ì  ë„¤íŠ¸ì›Œí¬ ë¶„ì„ - ê°„ì†Œí™”"""
        st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ë™ì  ë„¤íŠ¸ì›Œí¬")
        
        st.info("ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•´ ê°„ì†Œí™”ëœ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")
        
        # ê¸°ê°„ë³„ ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ ë³€í™” í‘œì‹œ
        filtered_data = self.get_filtered_data(start_date, end_date)
        
        if not filtered_data.empty:
            # ì¼ë³„ í™œë™ëŸ‰ ì¶”ì´
            daily_activity = filtered_data.groupby(filtered_data['timestamp'].dt.date).size()
            
            fig = px.line(x=daily_activity.index, y=daily_activity.values,
                         labels={'x': 'ë‚ ì§œ', 'y': 'í™œë™ ìˆ˜'},
                         title='ì¼ë³„ í™œë™ëŸ‰ ì¶”ì´')
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def render_activity_network(self, start_date: date, end_date: date):
        """í™œë™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ - ê°„ì†Œí™”"""
        st.subheader("âš¡ í™œë™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬")
        
        filtered_data = self.get_filtered_data(start_date, end_date)
        
        if not filtered_data.empty:
            # ìœ„ì¹˜ ê¸°ë°˜ í™œë™ ë¶„ë¥˜
            activity_counts = filtered_data['DR_NM'].value_counts().head(20)
            
            fig = px.bar(x=activity_counts.values, y=activity_counts.index,
                        orientation='h',
                        labels={'x': 'ë°©ë¬¸ íšŸìˆ˜', 'y': 'ìœ„ì¹˜'},
                        title='ì£¼ìš” í™œë™ ìœ„ì¹˜')
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def display_community_detection(self, interaction_data: Dict):
        """ì»¤ë®¤ë‹ˆí‹° íƒì§€ ê²°ê³¼ í‘œì‹œ"""
        st.markdown("#### ğŸ‘¥ ì»¤ë®¤ë‹ˆí‹° íƒì§€")
        
        G = interaction_data['graph']
        
        try:
            # Greedy modularity communities (networkx ë‚´ì¥)
            from networkx.algorithms.community import greedy_modularity_communities
            
            communities = list(greedy_modularity_communities(G))
            
            # ì»¤ë®¤ë‹ˆí‹°ë³„ ë©¤ë²„ ìˆ˜
            community_sizes = [len(c) for c in communities]
            
            st.write(f"ë°œê²¬ëœ ì»¤ë®¤ë‹ˆí‹° ìˆ˜: {len(communities)}")
            
            # ì»¤ë®¤ë‹ˆí‹° í¬ê¸° ë¶„í¬
            fig = px.bar(x=list(range(len(community_sizes))), 
                        y=community_sizes,
                        labels={'x': 'ì»¤ë®¤ë‹ˆí‹° ID', 'y': 'ë©¤ë²„ ìˆ˜'},
                        title='ì»¤ë®¤ë‹ˆí‹°ë³„ í¬ê¸° ë¶„í¬')
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.info("ì»¤ë®¤ë‹ˆí‹° íƒì§€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")