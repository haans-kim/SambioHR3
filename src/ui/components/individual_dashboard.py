"""
ê°œì¸ë³„ ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸
UI ì°¸ì¡°ìë£Œë¥¼ ë°˜ì˜í•œ ê°œì¸ í™œë™ ìš”ì•½ ë° íƒ€ì„ë¼ì¸ ì‹œê°í™”
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta, date
import logging
from pathlib import Path
from typing import List, Dict, Any
from .improved_gantt_chart import render_improved_gantt_chart
from .hmm_classifier import HMMActivityClassifier

from ...analysis import IndividualAnalyzer
from ...config.activity_types import (
    ACTIVITY_TYPES, get_activity_color, get_activity_name,
    get_activity_type, ActivityType
)

class IndividualDashboard:
    """ê°œì¸ë³„ ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, individual_analyzer: IndividualAnalyzer):
        self.analyzer = individual_analyzer
        self.logger = logging.getLogger(__name__)
        
        # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (activity_types.pyì—ì„œ ê°€ì ¸ì˜´)
        self.colors = {}
        for code, activity in ACTIVITY_TYPES.items():
            self.colors[code] = activity.color
        
        # ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë§¤í•‘
        self.colors.update({
            'work': '#2E86AB',
            'meeting': '#A23B72',
            'movement': '#F18F01',
            'meal': '#C73E1D',
            'breakfast': '#FF6B6B',
            'lunch': '#4ECDC4',
            'dinner': '#45B7D1',
            'midnight_meal': '#96CEB4',
            'rest': '#4CAF50',
            'low_confidence': '#E0E0E0'
        })
    
    def get_available_employees(self):
        """ë¡œë“œëœ ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì§ì› ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # pickle íŒŒì¼ì—ì„œ ì§ì› ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            from ...data_processing import PickleManager
            pickle_manager = PickleManager()
            
            # íƒœê¹… ë°ì´í„°ì—ì„œ ì§ì› ëª©ë¡ ì¶”ì¶œ
            tag_data = pickle_manager.load_dataframe(name='tag_data')
            if tag_data is not None and 'ì‚¬ë²ˆ' in tag_data.columns:
                employees = sorted(tag_data['ì‚¬ë²ˆ'].unique().tolist())
                return employees[:100]  # ìµœëŒ€ 100ëª…ê¹Œì§€ë§Œ í‘œì‹œ
            
            # ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„
            claim_data = pickle_manager.load_dataframe(name='claim_data')
            if claim_data is not None and 'ì‚¬ë²ˆ' in claim_data.columns:
                employees = sorted(claim_data['ì‚¬ë²ˆ'].unique().tolist())
                return employees[:100]
            
            return []
        except Exception as e:
            self.logger.warning(f"ì§ì› ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def get_available_date_range(self):
        """ë¡œë“œëœ ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°"""
        try:
            from ...data_processing import PickleManager
            pickle_manager = PickleManager()
            
            # íƒœê¹… ë°ì´í„°ì—ì„œ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ
            tag_data = pickle_manager.load_dataframe(name='tag_data')
            if tag_data is not None and 'ENTE_DT' in tag_data.columns:
                # YYYYMMDD í˜•ì‹ì„ date ê°ì²´ë¡œ ë³€í™˜
                tag_data['date'] = pd.to_datetime(tag_data['ENTE_DT'], format='%Y%m%d')
                min_date = tag_data['date'].min().date()
                max_date = tag_data['date'].max().date()
                return {'min_date': min_date, 'max_date': max_date}
            
            # ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„
            claim_data = pickle_manager.load_dataframe(name='claim_data')
            if claim_data is not None and 'ê·¼ë¬´ì¼' in claim_data.columns:
                claim_data['date'] = pd.to_datetime(claim_data['ê·¼ë¬´ì¼'], format='%Y%m%d')
                min_date = claim_data['date'].min().date()
                max_date = claim_data['date'].max().date()
                return {'min_date': min_date, 'max_date': max_date}
            
            return None
        except Exception as e:
            self.logger.warning(f"ë‚ ì§œ ë²”ìœ„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_daily_claim_data(self, employee_id: str, selected_date: date):
        """íŠ¹ì • ì§ì›ì˜ íŠ¹ì • ë‚ ì§œ Claim ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            from ...data_processing import PickleManager
            pickle_manager = PickleManager()
            
            # Claim ë°ì´í„° ë¡œë“œ
            claim_data = pickle_manager.load_dataframe(name='claim_data')
            if claim_data is None:
                return None
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYYMMDD)
            date_str = selected_date.strftime('%Y%m%d')
            date_int = int(date_str)
            
            # í•´ë‹¹ ì§ì›ê³¼ ë‚ ì§œì˜ ë°ì´í„° í•„í„°ë§
            daily_claim = claim_data[
                (claim_data['ì‚¬ë²ˆ'] == employee_id) & 
                (claim_data['ê·¼ë¬´ì¼'] == date_int)
            ]
            
            if daily_claim.empty:
                return None
            
            # í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
            claim_info = {
                'exists': True,
                'claim_start': daily_claim.iloc[0].get('ì‹œì‘', 'N/A'),
                'claim_end': daily_claim.iloc[0].get('ì¢…ë£Œ', 'N/A'),
                'claim_hours': daily_claim.iloc[0].get('ê·¼ë¬´ì‹œê°„', 0),
                'claim_type': daily_claim.iloc[0].get('ê·¼ë¬´ìœ í˜•', 'N/A'),
                'overtime': daily_claim.iloc[0].get('ì´ˆê³¼ê·¼ë¬´', 0),
                'raw_claim': daily_claim.iloc[0].to_dict()
            }
            
            return claim_info
            
        except Exception as e:
            self.logger.warning(f"Claim ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_tag_location_master(self):
        """íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            from ...data_processing import PickleManager
            import gzip
            pickle_manager = PickleManager()
            
            # ì§ì ‘ íŒŒì¼ ê²½ë¡œë¡œ ë¡œë“œ ì‹œë„
            import glob
            pattern = str(pickle_manager.base_path / "tag_location_master_v*.pkl.gz")
            files = glob.glob(pattern)
            
            if files:
                # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
                latest_file = sorted(files)[-1]
                self.logger.info(f"íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° íŒŒì¼ ì§ì ‘ ë¡œë“œ: {latest_file}")
                
                with gzip.open(latest_file, 'rb') as f:
                    tag_location_master = pd.read_pickle(f)
            else:
                self.logger.warning("íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            if tag_location_master is not None:
                self.logger.info(f"íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(tag_location_master)}ê±´")
                self.logger.info(f"ë§ˆìŠ¤í„° ë°ì´í„° ì»¬ëŸ¼: {tag_location_master.columns.tolist()}")
                
                # ì»¬ëŸ¼ëª… í™•ì¸ ë° í‘œì¤€í™”
                # ê°€ëŠ¥í•œ ì»¬ëŸ¼ëª… ë³€í˜•ë“¤
                dr_no_variations = ['DR_NO', 'dr_no', 'Dr_No', 'DRNO', 'drë²ˆí˜¸', 'DRë²ˆí˜¸', 'ê¸°ê¸°ë²ˆí˜¸']
                work_area_variations = ['ê·¼ë¬´êµ¬ì—­ì—¬ë¶€', 'ê·¼ë¬´êµ¬ì—­', 'work_area', 'WORK_AREA']
                work_status_variations = ['ê·¼ë¬´', 'ê·¼ë¬´ìƒíƒœ', 'work_status', 'WORK_STATUS']
                label_variations = ['ë¼ë²¨ë§', 'ë¼ë²¨', 'label', 'LABEL', 'ë ˆì´ë¸”']
                
                # ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸°
                for col in dr_no_variations:
                    if col in tag_location_master.columns:
                        tag_location_master['DR_NO'] = tag_location_master[col]
                        break
                
                # ê·¼ë¬´êµ¬ì—­ì—¬ë¶€, ê·¼ë¬´, ë¼ë²¨ë§ ì»¬ëŸ¼ì€ ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì²˜ë¦¬ ë¶ˆí•„ìš”
                
                return tag_location_master
            else:
                self.logger.warning("íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
        except Exception as e:
            self.logger.warning(f"íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_daily_tag_data(self, employee_id: str, selected_date: date):
        """íŠ¹ì • ì§ì›ì˜ íŠ¹ì • ë‚ ì§œ íƒœê¹… ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            from ...data_processing import PickleManager
            pickle_manager = PickleManager()
            
            # íƒœê¹… ë°ì´í„° ë¡œë“œ
            tag_data = pickle_manager.load_dataframe(name='tag_data')
            if tag_data is None:
                return None
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYYMMDD)
            date_str = selected_date.strftime('%Y%m%d')
            date_int = int(date_str)
            
            # í•´ë‹¹ ì§ì›ê³¼ ë‚ ì§œì˜ ë°ì´í„° í•„í„°ë§
            daily_data = tag_data[
                (tag_data['ì‚¬ë²ˆ'] == employee_id) & 
                (tag_data['ENTE_DT'] == date_int)
            ].copy()
            
            if daily_data.empty:
                return None
            
            # ì‹œê°„ìˆœ ì •ë ¬
            daily_data['time'] = daily_data['ì¶œì…ì‹œê°'].astype(str).str.zfill(6)
            daily_data['datetime'] = pd.to_datetime(
                daily_data['ENTE_DT'].astype(str) + ' ' + daily_data['time'],
                format='%Y%m%d %H%M%S'
            )
            daily_data = daily_data.sort_values('datetime')
            
            return daily_data
            
        except Exception as e:
            self.logger.error(f"ì¼ì¼ íƒœê·¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def classify_activities(self, daily_data: pd.DataFrame):
        """í™œë™ ë¶„ë¥˜ ìˆ˜í–‰ (HMM ê¸°ë°˜)"""
        try:
            # íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ
            tag_location_master = self.get_tag_location_master()
            
            # ê¸°ë³¸ í™œë™ ë¶„ë¥˜
            daily_data['activity_code'] = 'WORK'  # ê¸°ë³¸ê°’
            daily_data['work_area_type'] = 'Y'  # ê¸°ë³¸ê°’ (ê·¼ë¬´êµ¬ì—­)
            daily_data['work_status'] = 'W'  # ê¸°ë³¸ê°’ (ê·¼ë¬´ìƒíƒœ)
            daily_data['activity_label'] = 'YW'  # ê¸°ë³¸ê°’ (ê·¼ë¬´êµ¬ì—­ì—ì„œ ê·¼ë¬´ì¤‘)
            daily_data['confidence'] = 80  # ê¸°ë³¸ ì‹ ë¢°ë„
            
            # íƒœê¹…ì§€ì  ë§ˆìŠ¤í„° ë°ì´í„°ì™€ ì¡°ì¸
            if tag_location_master is not None and 'DR_NO' in tag_location_master.columns:
                # DR_NO ë°ì´í„° íƒ€ì… ë§ì¶”ê¸°
                daily_data['DR_NO_str'] = daily_data['DR_NO'].astype(str).str.strip()
                
                # ë§ˆìŠ¤í„° ë°ì´í„°ì˜ DR_NOê°€ ìˆ«ìí˜•ì´ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
                if tag_location_master['DR_NO'].dtype in ['int64', 'float64']:
                    tag_location_master['DR_NO_str'] = tag_location_master['DR_NO'].astype(int).astype(str)
                else:
                    tag_location_master['DR_NO_str'] = tag_location_master['DR_NO'].astype(str).str.strip()
                
                # ì¡°ì¸ ì „ ë°ì´í„° í™•ì¸
                self.logger.info(f"ì¡°ì¸ ì „ - daily_data DR_NO ìƒ˜í”Œ: {daily_data['DR_NO_str'].head().tolist()}")
                self.logger.info(f"ì¡°ì¸ ì „ - master DR_NO ìƒ˜í”Œ: {tag_location_master['DR_NO_str'].head().tolist()}")
                
                # ì¡°ì¸í•  ì»¬ëŸ¼ í™•ì¸ (ìƒˆë¡œìš´ íƒœê·¸ ì½”ë“œ ì²´ê³„ ì ìš©)
                join_columns = ['DR_NO_str']
                if 'Tag_Code' in tag_location_master.columns:
                    join_columns.append('Tag_Code')
                if 'ê³µê°„êµ¬ë¶„_NM' in tag_location_master.columns:
                    join_columns.append('ê³µê°„êµ¬ë¶„_NM')
                if 'ì„¸ë¶€ìœ í˜•_NM' in tag_location_master.columns:
                    join_columns.append('ì„¸ë¶€ìœ í˜•_NM')
                if 'ë¼ë²¨ë§_í™œë™' in tag_location_master.columns:
                    join_columns.append('ë¼ë²¨ë§_í™œë™')
                # ê¸°ì¡´ ì»¬ëŸ¼ë“¤ë„ ì²´í¬ (í˜¸í™˜ì„±)
                if 'ê·¼ë¬´êµ¬ì—­ì—¬ë¶€' in tag_location_master.columns:
                    join_columns.append('ê·¼ë¬´êµ¬ì—­ì—¬ë¶€')
                if 'ê·¼ë¬´' in tag_location_master.columns:
                    join_columns.append('ê·¼ë¬´')
                if 'ë¼ë²¨ë§' in tag_location_master.columns:
                    join_columns.append('ë¼ë²¨ë§')
                
                # DR_NO_strë¡œ ì¡°ì¸
                daily_data = daily_data.merge(
                    tag_location_master[join_columns],
                    on='DR_NO_str',
                    how='left',
                    suffixes=('', '_master')
                )
                
                # ì¡°ì¸ í›„ ê²°ê³¼ í™•ì¸
                if 'Tag_Code' in daily_data.columns:
                    matched_count = daily_data['Tag_Code'].notna().sum()
                elif 'ê·¼ë¬´êµ¬ì—­ì—¬ë¶€' in daily_data.columns:
                    matched_count = daily_data['ê·¼ë¬´êµ¬ì—­ì—¬ë¶€'].notna().sum()
                else:
                    matched_count = 0
                self.logger.info(f"ì¡°ì¸ ê²°ê³¼: {matched_count}/{len(daily_data)} ë§¤ì¹­ë¨")
                
                # ìƒˆë¡œìš´ íƒœê·¸ ì½”ë“œ ì²´ê³„ ì ìš©
                if 'Tag_Code' in daily_data.columns:
                    # Tag_Code ê¸°ë°˜ í™œë™ ë¶„ë¥˜
                    # G1~G4: ê·¼ë¬´ì˜ì—­, N1~N2: ë¹„ê·¼ë¬´ì˜ì—­, T1~T3: ì´ë™êµ¬ê°„
                    daily_data['tag_code'] = daily_data['Tag_Code'].fillna('G1')  # ê¸°ë³¸ê°’
                    daily_data['space_type'] = daily_data['ê³µê°„êµ¬ë¶„_NM'].fillna('ê·¼ë¬´ì˜ì—­')  # ê¸°ë³¸ê°’
                    daily_data['detail_type'] = daily_data['ì„¸ë¶€ìœ í˜•_NM'].fillna('ì£¼ì—…ë¬´ê³µê°„')  # ê¸°ë³¸ê°’
                    daily_data['allowed_activities'] = daily_data['ë¼ë²¨ë§_í™œë™'].fillna('ì—…ë¬´, ì‹ì‚¬, íœ´ê²Œ')  # ê¸°ë³¸ê°’
                    
                    # ê¸°ì¡´ ì»¬ëŸ¼ê³¼ì˜ í˜¸í™˜ì„± ìœ ì§€
                    # Tag_Codeë¥¼ ê¸°ë°˜ìœ¼ë¡œ work_area_type ì„¤ì •
                    daily_data.loc[daily_data['tag_code'].str.startswith('G'), 'work_area_type'] = 'Y'  # ê·¼ë¬´ì˜ì—­
                    daily_data.loc[daily_data['tag_code'].str.startswith('N'), 'work_area_type'] = 'N'  # ë¹„ê·¼ë¬´ì˜ì—­
                    daily_data.loc[daily_data['tag_code'].str.startswith('T'), 'work_area_type'] = 'T'  # ì´ë™êµ¬ê°„
                else:
                    # ê¸°ì¡´ ë°©ì‹ ìœ ì§€ (í˜¸í™˜ì„±)
                    daily_data['work_area_type'] = daily_data['ê·¼ë¬´êµ¬ì—­ì—¬ë¶€'].fillna('Y')
                    daily_data['work_status'] = daily_data['ê·¼ë¬´'].fillna('W')
                    daily_data['activity_label'] = daily_data['ë¼ë²¨ë§'].fillna('YW')
                
                # Tag_Code ê¸°ë°˜ ê¸°ë³¸ í™œë™ ë¶„ë¥˜
                if 'tag_code' in daily_data.columns:
                    # G1: ì£¼ì—…ë¬´ê³µê°„ -> ì—…ë¬´
                    daily_data.loc[daily_data['tag_code'] == 'G1', 'activity_code'] = 'WORK'
                    
                    # G2: ë³´ì¡°ì—…ë¬´ê³µê°„ -> ì¤€ë¹„
                    daily_data.loc[daily_data['tag_code'] == 'G2', 'activity_code'] = 'WORK_PREPARATION'
                    
                    # G3: í˜‘ì—…ê³µê°„ -> íšŒì˜
                    daily_data.loc[daily_data['tag_code'] == 'G3', 'activity_code'] = 'MEETING'
                    
                    # G4: êµìœ¡ê³µê°„ -> êµìœ¡
                    daily_data.loc[daily_data['tag_code'] == 'G4', 'activity_code'] = 'TRAINING'
                    
                    # N1: íœ´ê²Œê³µê°„ -> íœ´ê²Œ
                    daily_data.loc[daily_data['tag_code'] == 'N1', 'activity_code'] = 'REST'
                    
                    # N2: ë³µì§€ê³µê°„ -> íœ´ê²Œ
                    daily_data.loc[daily_data['tag_code'] == 'N2', 'activity_code'] = 'REST'
                    
                    # T1: ê±´ë¬¼/êµ¬ì—­ ì—°ê²° -> ë‚´ë¶€ì´ë™
                    daily_data.loc[daily_data['tag_code'] == 'T1', 'activity_code'] = 'MOVEMENT'
                    
                    # T2: ì¶œì…í¬ì¸íŠ¸(IN) -> ì¶œê·¼
                    daily_data.loc[daily_data['tag_code'] == 'T2', 'activity_code'] = 'COMMUTE_IN'
                    
                    # T3: ì¶œì…í¬ì¸íŠ¸(OUT) -> í‡´ê·¼
                    daily_data.loc[daily_data['tag_code'] == 'T3', 'activity_code'] = 'COMMUTE_OUT'
                else:
                    # ê¸°ì¡´ ë¼ë²¨ë§ ê¸°ë°˜ ë¶„ë¥˜ (í˜¸í™˜ì„±)
                    if 'activity_label' in daily_data.columns:
                        # GM: ê·¼ë¬´êµ¬ì—­ ì¤‘ 1ì„ ê²Œì´íŠ¸ë¡œ ë“¤ì–´ì˜´ (ì´ë™)
                        daily_data.loc[daily_data['activity_label'] == 'GM', 'activity_code'] = 'MOVEMENT'
                        
                        # NM: ë¹„ê·¼ë¬´êµ¬ì—­ì—ì„œ ì´ë™ì¤‘
                        daily_data.loc[daily_data['activity_label'] == 'NM', 'activity_code'] = 'MOVEMENT'
                        
                        # YW: ê·¼ë¬´êµ¬ì—­ì—ì„œ ê·¼ë¬´ì¤‘
                        daily_data.loc[daily_data['activity_label'] == 'YW', 'activity_code'] = 'WORK'
                        
                        # NN: ë¹„ê·¼ë¬´êµ¬ì—­ì—ì„œ ë¹„ê·¼ë¬´ì¤‘ (íœ´ì‹)
                        daily_data.loc[daily_data['activity_label'] == 'NN', 'activity_code'] = 'REST'
                        
                        # YM: ê·¼ë¬´êµ¬ì—­ì—ì„œ ì´ë™ì¤‘
                        daily_data.loc[daily_data['activity_label'] == 'YM', 'activity_code'] = 'MOVEMENT'
            
            # HMM ë¶„ë¥˜ê¸° ì‚¬ìš©
            try:
                hmm_classifier = HMMActivityClassifier()
                daily_data = hmm_classifier.classify(daily_data, tag_location_master)
                self.logger.info("HMM ë¶„ë¥˜ ì„±ê³µ")
            except Exception as hmm_error:
                self.logger.warning(f"HMM ë¶„ë¥˜ ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´: {hmm_error}")
                # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ë¡œ í´ë°±
                daily_data = self._apply_rule_based_classification(daily_data, tag_location_master)
            
            # Tag_Code ê¸°ë°˜ ì‹ ë¢°ë„ ì„¸ë¶„í™”
            if 'tag_code' in daily_data.columns:
                # T2, T3 (ì¶œí‡´ê·¼ í¬ì¸íŠ¸)ëŠ” ê°€ì¥ í™•ì‹¤í•œ ë°ì´í„° - 100%
                daily_data.loc[daily_data['tag_code'].isin(['T2', 'T3']), 'confidence'] = 100
                
                # G3 (í˜‘ì—…ê³µê°„), G4 (êµìœ¡ê³µê°„)ëŠ” ëª…í™•í•œ í™œë™ - 95%
                daily_data.loc[daily_data['tag_code'].isin(['G3', 'G4']), 'confidence'] = 95
                
                # G1 (ì£¼ì—…ë¬´ê³µê°„), G2 (ë³´ì¡°ì—…ë¬´ê³µê°„)ëŠ” ì¼ë°˜ ì‘ì—… - 90%
                daily_data.loc[daily_data['tag_code'].isin(['G1', 'G2']), 'confidence'] = 90
                
                # N1, N2 (íœ´ê²Œ/ë³µì§€ê³µê°„) - 90%
                daily_data.loc[daily_data['tag_code'].isin(['N1', 'N2']), 'confidence'] = 90
                
                # T1 (ë‚´ë¶€ ì´ë™) - 85%
                daily_data.loc[daily_data['tag_code'] == 'T1', 'confidence'] = 85
            
            # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìƒì„¸ í™œë™ ë¶„ë¥˜
            # ì°¸ê³ : Tag_Code T2(ì¶œê·¼), T3(í‡´ê·¼)ì´ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, 
            # ë” ì •í™•í•œ ì¶œí‡´ê·¼ ì‹œê°„ëŒ€ ê²€ì¦ë§Œ ì¶”ê°€
            
            # 1. ì‹ì‚¬ì‹œê°„ ë¶„ë¥˜ (CAFETERIA ìœ„ì¹˜ + ì‹œê°„ëŒ€)
            cafeteria_mask = daily_data['DR_NM'].str.contains('CAFETERIA|ì‹ë‹¹|êµ¬ë‚´ì‹ë‹¹', case=False, na=False)
            
            # ì‹œê°„ëŒ€ë³„ ì‹ì‚¬ ë¶„ë¥˜ (ë” ì •í™•í•œ ì‹œê°„ëŒ€)
            breakfast_mask = cafeteria_mask & (daily_data['datetime'].dt.time >= pd.to_datetime('06:30').time()) & (daily_data['datetime'].dt.time <= pd.to_datetime('09:00').time())
            lunch_mask = cafeteria_mask & (daily_data['datetime'].dt.time >= pd.to_datetime('11:20').time()) & (daily_data['datetime'].dt.time <= pd.to_datetime('13:20').time())
            dinner_mask = cafeteria_mask & (daily_data['datetime'].dt.time >= pd.to_datetime('17:00').time()) & (daily_data['datetime'].dt.time <= pd.to_datetime('20:00').time())
            midnight_mask = cafeteria_mask & ((daily_data['datetime'].dt.time >= pd.to_datetime('23:30').time()) | (daily_data['datetime'].dt.time <= pd.to_datetime('01:00').time()))
            
            daily_data.loc[breakfast_mask, 'activity_code'] = 'BREAKFAST'
            daily_data.loc[lunch_mask, 'activity_code'] = 'LUNCH'
            daily_data.loc[dinner_mask, 'activity_code'] = 'DINNER'
            daily_data.loc[midnight_mask, 'activity_code'] = 'MIDNIGHT_MEAL'
            
            # ì‹ì‚¬ í™œë™ì€ ìœ„ì¹˜+ì‹œê°„ì´ ëª¨ë‘ ì¼ì¹˜í•˜ë¯€ë¡œ ì‹ ë¢°ë„ ìƒí–¥
            meal_masks = breakfast_mask | lunch_mask | dinner_mask | midnight_mask
            # ì‹ì‚¬ í™œë™ì´ë©´ì„œ tag_codeê°€ G1ì¸ ê²½ìš°ë§Œ 95%ë¡œ ìƒí–¥ (ë‚˜ë¨¸ì§€ëŠ” ê¸°ì¡´ ìœ ì§€)
            if 'tag_code' in daily_data.columns:
                daily_data.loc[meal_masks & (daily_data['tag_code'] == 'G1'), 'confidence'] = 95
            
            # 2. íŠ¹ìˆ˜ í™œë™ ë¶„ë¥˜ (ìœ„ì¹˜ëª… ê¸°ë°˜ ì„¸ë¶€ ë¶„ë¥˜)
            # íšŒì˜ì‹¤
            meeting_mask = daily_data['DR_NM'].str.contains('MEETING|íšŒì˜|CONFERENCE', case=False, na=False)
            daily_data.loc[meeting_mask, 'activity_code'] = 'MEETING'
            # tag_codeê°€ G3(í˜‘ì—…ê³µê°„)ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì‹ ë¢°ë„ ì¡°ì •
            if 'tag_code' in daily_data.columns:
                daily_data.loc[meeting_mask & (daily_data['tag_code'] != 'G3'), 'confidence'] = 88
            
            # í”¼íŠ¸ë‹ˆìŠ¤/ìš´ë™ì‹¤
            fitness_mask = daily_data['DR_NM'].str.contains('FITNESS|GYM|ì²´ë ¥ë‹¨ë ¨|ìš´ë™ì‹¤', case=False, na=False)
            daily_data.loc[fitness_mask, 'activity_code'] = 'FITNESS'
            # tag_codeê°€ N2(ë³µì§€ê³µê°„)ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì‹ ë¢°ë„ ì¡°ì •
            if 'tag_code' in daily_data.columns:
                daily_data.loc[fitness_mask & (daily_data['tag_code'] != 'N2'), 'confidence'] = 87
            
            # ì¥ë¹„ì‹¤/ê¸°ê³„ì‹¤
            equipment_mask = daily_data['DR_NM'].str.contains('EQUIPMENT|MACHINE|ì¥ë¹„|ê¸°ê³„ì‹¤', case=False, na=False)
            daily_data.loc[equipment_mask & (daily_data['activity_code'] == 'WORK'), 'activity_code'] = 'EQUIPMENT_OPERATION'
            
            # ì‘ì—…ì¤€ë¹„ì‹¤
            prep_mask = daily_data['DR_NM'].str.contains('PREP|ì¤€ë¹„ì‹¤|SETUP', case=False, na=False)
            daily_data.loc[prep_mask & (daily_data['activity_code'] == 'WORK'), 'activity_code'] = 'WORK_PREPARATION'
            
            # íœ´ê²Œì‹¤
            rest_mask = daily_data['DR_NM'].str.contains('REST|LOUNGE|íœ´ê²Œì‹¤|íƒˆì˜ì‹¤', case=False, na=False)
            daily_data.loc[rest_mask, 'activity_code'] = 'REST'
            # tag_codeê°€ N1(íœ´ê²Œê³µê°„)ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì‹ ë¢°ë„ ì¡°ì •
            if 'tag_code' in daily_data.columns:
                daily_data.loc[rest_mask & (daily_data['tag_code'] != 'N1'), 'confidence'] = 86
            
            # 3. ì§‘ì¤‘ê·¼ë¬´ íŒë³„ (ê°™ì€ ì‘ì—… ìœ„ì¹˜ì— 30ë¶„ ì´ìƒ ì²´ë¥˜)
            # ì²´ë¥˜ì‹œê°„ ê³„ì‚°
            daily_data['next_time'] = daily_data['datetime'].shift(-1)
            daily_data['duration_minutes'] = (daily_data['next_time'] - daily_data['datetime']).dt.total_seconds() / 60
            
            # NaN ê°’ ì²˜ë¦¬
            daily_data['duration_minutes'] = daily_data['duration_minutes'].fillna(5)  # ê¸°ë³¸ê°’ 5ë¶„
            
            # ë§ˆì§€ë§‰ ë ˆì½”ë“œëŠ” 5ë¶„ìœ¼ë¡œ ê°€ì •
            if len(daily_data) > 0:
                daily_data.loc[daily_data.index[-1], 'duration_minutes'] = 5
            
            # ê°™ì€ ìœ„ì¹˜ì—ì„œ 30ë¶„ ì´ìƒ ì‘ì—…í•œ ê²½ìš° ì§‘ì¤‘ê·¼ë¬´ë¡œ ë¶„ë¥˜
            focused_work_mask = (
                (daily_data['activity_code'] == 'WORK') & 
                (daily_data['duration_minutes'] >= 30) &
                (daily_data['DR_NM'].str.contains('WORK_AREA', case=False, na=False))
            )
            daily_data.loc[focused_work_mask, 'activity_code'] = 'FOCUSED_WORK'
            # ì§‘ì¤‘ê·¼ë¬´ëŠ” ì¶”ë¡  ê¸°ë°˜ì´ë¯€ë¡œ ì•½ê°„ ë‚®ì€ ì‹ ë¢°ë„
            daily_data.loc[focused_work_mask & (daily_data['confidence'] > 85), 'confidence'] = 83
            
            # 4. í™œë™ íƒ€ì… ë§¤í•‘ (ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„±)
            activity_type_mapping = {
                'WORK': 'work',
                'FOCUSED_WORK': 'work',
                'EQUIPMENT_OPERATION': 'work',
                'WORK_PREPARATION': 'work',
                'WORKING': 'work',
                'TRAINING': 'education',
                'MEETING': 'meeting',
                'MOVEMENT': 'movement',
                'COMMUTE_IN': 'commute',
                'COMMUTE_OUT': 'commute',
                'BREAKFAST': 'breakfast',
                'LUNCH': 'lunch',
                'DINNER': 'dinner',
                'MIDNIGHT_MEAL': 'midnight_meal',
                'REST': 'rest',
                'FITNESS': 'rest',
                'LEAVE': 'rest',
                'IDLE': 'rest',
                'UNKNOWN': 'work'
            }
            daily_data['activity_type'] = daily_data['activity_code'].map(activity_type_mapping).fillna('work')
            
            return daily_data
            
        except Exception as e:
            self.logger.error(f"í™œë™ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ ì‹œì—ë„ ê¸°ë³¸ê°’ ì„¤ì •
            if 'activity_code' not in daily_data.columns:
                daily_data['activity_code'] = 'WORK'
            if 'activity_type' not in daily_data.columns:
                daily_data['activity_type'] = 'work'
            if 'duration_minutes' not in daily_data.columns:
                daily_data['duration_minutes'] = 5
            if 'confidence' not in daily_data.columns:
                daily_data['confidence'] = 80
            return daily_data
    
    def _apply_rule_based_classification(self, daily_data: pd.DataFrame, tag_location_master: pd.DataFrame) -> pd.DataFrame:
        """
        ê·œì¹™ ê¸°ë°˜ í™œë™ ë¶„ë¥˜ (HMM ì‹¤íŒ¨ ì‹œ í´ë°±)
        """
        # ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜ ë¡œì§ì„ ì—¬ê¸°ì— êµ¬í˜„
        # í˜„ì¬ ì½”ë“œì—ì„œëŠ” ì´ë¯¸ ê¸°ë³¸ê°’ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ
        # ì¶”ê°€ì ì¸ ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ëŠ” í•„ìš”ì‹œ êµ¬í˜„
        return daily_data
    
    def analyze_daily_data(self, employee_id: str, selected_date: date, classified_data: pd.DataFrame):
        """ì¼ì¼ ë°ì´í„° ë¶„ì„"""
        try:
            # ê·¼ë¬´ì‹œê°„ ê³„ì‚°
            work_start = classified_data['datetime'].min()
            work_end = classified_data['datetime'].max()
            total_hours = (work_end - work_start).total_seconds() / 3600
            
            # í™œë™ë³„ ì‹œê°„ ì§‘ê³„ (ìƒˆë¡œìš´ activity_code ê¸°ì¤€)
            if 'duration_minutes' in classified_data.columns:
                activity_summary = classified_data.groupby('activity_code')['duration_minutes'].sum()
                activity_type_summary = classified_data.groupby('activity_type')['duration_minutes'].sum()
                
                # ê·¼ë¬´êµ¬ì—­ë³„ ì‹œê°„ ì§‘ê³„
                if 'work_area_type' in classified_data.columns:
                    area_summary = classified_data.groupby('work_area_type')['duration_minutes'].sum()
                else:
                    area_summary = pd.Series()
            else:
                # duration_minutesê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 5ë¶„ìœ¼ë¡œ ê°€ì •
                classified_data['duration_minutes'] = 5
                activity_summary = classified_data.groupby('activity_code')['duration_minutes'].sum()
                activity_type_summary = classified_data.groupby('activity_type')['duration_minutes'].sum()
                
                if 'work_area_type' in classified_data.columns:
                    area_summary = classified_data.groupby('work_area_type')['duration_minutes'].sum()
                else:
                    area_summary = pd.Series()
            
            # êµ¬ê°„ë³„ í™œë™ ì •ë¦¬
            activity_segments = []
            for idx, row in classified_data.iterrows():
                # next_timeì´ NaTì¸ ê²½ìš° ì²˜ë¦¬
                end_time = row.get('next_time')
                if pd.isna(end_time):
                    end_time = row['datetime'] + timedelta(minutes=5)
                
                activity_segments.append({
                    'start_time': row['datetime'],
                    'end_time': end_time,
                    'activity': row['activity_type'],
                    'activity_code': row.get('activity_code', 'WORK'),
                    'location': row['DR_NM'],
                    'duration_minutes': row.get('duration_minutes', 5),
                    'confidence': row.get('confidence', 80)  # ì‹ ë¢°ë„ ì¶”ê°€
                })
            
            # Claim ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            claim_data = self.get_daily_claim_data(employee_id, selected_date)
            
            # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
            data_quality = self.analyze_data_quality(classified_data)
            
            # í™œë™ë³„ ì‹œê°„ í†µê³„ (ì‹œê°„ ë‹¨ìœ„ë¡œ)
            work_time_analysis = {
                'actual_work_hours': activity_type_summary.get('work', 0) / 60,
                'claimed_work_hours': claim_data['claim_hours'] if claim_data else 8.0,
                'efficiency_ratio': 0,
                'work_breakdown': {}
            }
            
            # íš¨ìœ¨ì„± ê³„ì‚°
            if work_time_analysis['claimed_work_hours'] > 0:
                work_time_analysis['efficiency_ratio'] = (
                    work_time_analysis['actual_work_hours'] / 
                    work_time_analysis['claimed_work_hours'] * 100
                )
            
            # í™œë™ë³„ ì‹œê°„ ë¶„ì„
            for activity_type, minutes in activity_type_summary.items():
                work_time_analysis['work_breakdown'][activity_type] = minutes / 60
            
            return {
                'employee_id': employee_id,
                'analysis_date': selected_date,
                'work_start': work_start,
                'work_end': work_end,
                'total_hours': total_hours,
                'activity_summary': activity_summary.to_dict(),
                'area_summary': area_summary.to_dict() if not area_summary.empty else {},
                'activity_segments': activity_segments,
                'raw_data': classified_data,
                'total_records': len(classified_data),
                'claim_data': claim_data,
                'data_quality': data_quality,
                'work_time_analysis': work_time_analysis
            }
            
        except Exception as e:
            self.logger.error(f"ì¼ì¼ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def analyze_data_quality(self, classified_data: pd.DataFrame) -> dict:
        """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        if 'confidence' not in classified_data.columns:
            return {
                'overall_quality_score': 80,
                'tag_data_completeness': 100,
                'confidence_distribution': {
                    'high': 50,
                    'medium': 40,
                    'low': 10
                }
            }
        
        # ì‹ ë¢°ë„ ë¶„í¬ ê³„ì‚°
        confidence_values = classified_data['confidence']
        high_conf = (confidence_values >= 90).sum()
        medium_conf = ((confidence_values >= 80) & (confidence_values < 90)).sum()
        low_conf = (confidence_values < 80).sum()
        total = len(classified_data)
        
        confidence_dist = {
            'high': round(high_conf / total * 100, 1) if total > 0 else 0,
            'medium': round(medium_conf / total * 100, 1) if total > 0 else 0,
            'low': round(low_conf / total * 100, 1) if total > 0 else 0
        }
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ (í‰ê·  ì‹ ë¢°ë„)
        overall_score = round(confidence_values.mean(), 1) if len(confidence_values) > 0 else 80
        
        # íƒœê·¸ ë°ì´í„° ì™„ì„±ë„ (íƒœê·¸ ì½”ë“œê°€ ìˆëŠ” ë¹„ìœ¨)
        if 'tag_code' in classified_data.columns:
            completeness = (classified_data['tag_code'].notna().sum() / total * 100) if total > 0 else 0
        else:
            completeness = 100
        
        return {
            'overall_quality_score': overall_score,
            'tag_data_completeness': round(completeness, 1),
            'confidence_distribution': confidence_dist
        }
    
    def render(self):
        """ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        st.markdown("### ğŸ‘¤ ê°œì¸ë³„ ê·¼ë¬´ ë¶„ì„")
        
        # ì§ì› ì„ íƒ ë° ê¸°ê°„ ì„¤ì •
        self.render_controls()
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ” ë¶„ì„ ì‹¤í–‰", type="primary"):
            self.execute_analysis()
    
    def render_controls(self):
        """ì»¨íŠ¸ë¡¤ íŒ¨ë„ ë Œë”ë§"""
        # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì§ì› ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        employee_list = self.get_available_employees()
        date_range_info = self.get_available_date_range()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # ì§ì› ì„ íƒ ë°©ì‹
            selection_method = st.radio(
                "ì§ì› ì„ íƒ ë°©ì‹",
                ["ëª©ë¡ì—ì„œ ì„ íƒ", "ì§ì ‘ ì…ë ¥"],
                key="employee_selection_method"
            )
            
            if selection_method == "ëª©ë¡ì—ì„œ ì„ íƒ":
                if employee_list:
                    employee_id = st.selectbox(
                        "ì§ì› ì„ íƒ",
                        employee_list,
                        key="individual_employee_select"
                    )
                else:
                    st.warning("ë¡œë“œëœ ì§ì› ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    employee_id = st.text_input("ì§ì› ID ì…ë ¥", key="manual_employee_input")
            else:
                employee_id = st.text_input(
                    "ì§ì› ID ì…ë ¥",
                    placeholder="ì˜ˆ: E001234",
                    key="individual_employee_input"
                )
            
            st.session_state.selected_employee = employee_id
        
        with col2:
            # ë¶„ì„ ë‚ ì§œ (ë‹¨ì¼ ë‚ ì§œ ì„ íƒ)
            st.markdown("**ë¶„ì„ ë‚ ì§œ**")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„ í‘œì‹œ
            if date_range_info:
                st.info(f"ë°ì´í„° ë²”ìœ„: {date_range_info['min_date']} ~ {date_range_info['max_date']}")
                
                # ê¸°ë³¸ê°’ì„ ë°ì´í„° ë²”ìœ„ ë‚´ë¡œ ì„¤ì •
                default_date = min(date_range_info['max_date'], date.today())
                
                selected_date = st.date_input(
                    "ë‚ ì§œ ì„ íƒ",
                    value=default_date,
                    min_value=date_range_info['min_date'],
                    max_value=date_range_info['max_date'],
                    key="individual_analysis_date"
                )
            else:
                # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                selected_date = st.date_input(
                    "ë‚ ì§œ ì„ íƒ",
                    value=date.today(),
                    key="individual_analysis_date_default"
                )
            
            st.session_state.analysis_date = selected_date
        
        with col3:
            # ë¶„ì„ ì˜µì…˜
            analysis_options = st.multiselect(
                "ë¶„ì„ ì˜µì…˜",
                ["ê·¼ë¬´ì‹œê°„ ë¶„ì„", "ì‹ì‚¬ì‹œê°„ ë¶„ì„", "êµëŒ€ ê·¼ë¬´ ë¶„ì„", "íš¨ìœ¨ì„± ë¶„ì„"],
                default=["ê·¼ë¬´ì‹œê°„ ë¶„ì„", "íš¨ìœ¨ì„± ë¶„ì„"],
                key="individual_analysis_options"
            )
            st.session_state.analysis_options = analysis_options
    
    def execute_analysis(self):
        """ë¶„ì„ ì‹¤í–‰"""
        employee_id = st.session_state.get('selected_employee')
        selected_date = st.session_state.get('analysis_date')
        
        if not employee_id or not selected_date:
            st.error("ì§ì›ê³¼ ë¶„ì„ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        try:
            # ë¶„ì„ ì‹¤í–‰
            with st.spinner("ë¶„ì„ ì¤‘..."):
                # ì‹¤ì œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                daily_data = self.get_daily_tag_data(employee_id, selected_date)
                
                if daily_data is None or daily_data.empty:
                    st.warning(f"ì„ íƒí•œ ë‚ ì§œ({selected_date})ì— í•´ë‹¹ ì§ì›({employee_id})ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                # í™œë™ ë¶„ë¥˜ ìˆ˜í–‰
                classified_data = self.classify_activities(daily_data)
                
                # ë¶„ì„ ê²°ê³¼ ìƒì„±
                analysis_result = self.analyze_daily_data(employee_id, selected_date, classified_data)
                
                # ê²°ê³¼ ë Œë”ë§
                self.render_analysis_results(analysis_result)
                
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.logger.error(f"ê°œì¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def create_sample_analysis_result(self, employee_id: str, date_range: tuple):
        """ìƒ˜í”Œ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        return {
            'employee_id': employee_id,
            'analysis_period': {
                'start_date': date_range[0].isoformat(),
                'end_date': date_range[1].isoformat()
            },
            'work_time_analysis': {
                'actual_work_hours': 8.5,
                'claimed_work_hours': 8.0,
                'efficiency_ratio': 89.5,
                'work_breakdown': {
                    'work': 6.5,
                    'meeting': 1.2,
                    'movement': 0.8
                }
            },
            'meal_time_analysis': {
                'meal_patterns': {
                    'ì¡°ì‹': {'frequency': 5, 'avg_duration': 25},
                    'ì¤‘ì‹': {'frequency': 7, 'avg_duration': 45},
                    'ì„ì‹': {'frequency': 3, 'avg_duration': 35},
                    'ì•¼ì‹': {'frequency': 2, 'avg_duration': 20}
                },
                'total_meal_time': 180
            },
            'shift_analysis': {
                'preferred_shift': 'ì£¼ê°„',
                'shift_patterns': {
                    'ì£¼ê°„': {'work_hours': 6.5, 'activity_count': 45},
                    'ì•¼ê°„': {'work_hours': 2.0, 'activity_count': 15}
                }
            },
            'timeline_data': self.create_sample_timeline_data(date_range),
            'data_quality': {
                'overall_quality_score': 85,
                'tag_data_completeness': 90,
                'confidence_distribution': {
                    'high': 70,
                    'medium': 25,
                    'low': 5
                }
            }
        }
    
    def create_sample_timeline_data(self, date_range: tuple):
        """ìƒ˜í”Œ íƒ€ì„ë¼ì¸ ë°ì´í„° ìƒì„±"""
        timeline_data = []
        
        # í•˜ë£¨ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        base_date = date_range[0]
        activities = [
            {'time': '08:00', 'activity': 'ì¶œê·¼', 'location': 'GATE_A', 'confidence': 100},
            {'time': '08:15', 'activity': 'ê·¼ë¬´', 'location': 'WORK_AREA_1', 'confidence': 95},
            {'time': '10:30', 'activity': 'íšŒì˜', 'location': 'MEETING_ROOM_1', 'confidence': 90},
            {'time': '11:30', 'activity': 'ê·¼ë¬´', 'location': 'WORK_AREA_1', 'confidence': 95},
            {'time': '12:00', 'activity': 'ì¤‘ì‹', 'location': 'CAFETERIA', 'confidence': 100},
            {'time': '13:00', 'activity': 'ê·¼ë¬´', 'location': 'WORK_AREA_1', 'confidence': 95},
            {'time': '15:00', 'activity': 'ì´ë™', 'location': 'CORRIDOR', 'confidence': 80},
            {'time': '15:30', 'activity': 'ì‘ì—…', 'location': 'WORK_AREA_2', 'confidence': 90},
            {'time': '17:00', 'activity': 'í‡´ê·¼', 'location': 'GATE_A', 'confidence': 100}
        ]
        
        for activity in activities:
            timeline_data.append({
                'datetime': datetime.combine(base_date, datetime.strptime(activity['time'], '%H:%M').time()),
                'activity': activity['activity'],
                'location': activity['location'],
                'confidence': activity['confidence']
            })
        
        return timeline_data
    
    def render_analysis_results(self, analysis_result: dict):
        """ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
        st.markdown("---")
        st.markdown(f"## ğŸ“Š {analysis_result['analysis_date']} ë¶„ì„ ê²°ê³¼")
        
        # ê¸°ë³¸ ì •ë³´
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì¶œê·¼ ì‹œê°", analysis_result['work_start'].strftime('%H:%M'))
        with col2:
            st.metric("í‡´ê·¼ ì‹œê°", analysis_result['work_end'].strftime('%H:%M'))
        with col3:
            st.metric("ì´ ê·¼ë¬´ì‹œê°„", f"{analysis_result['total_hours']:.1f}ì‹œê°„")
        with col4:
            st.metric("íƒœê·¸ ê¸°ë¡ ìˆ˜", f"{analysis_result['total_records']}ê±´")
        
        # Claim ë°ì´í„° ë¹„êµ (ìˆì„ ê²½ìš°)
        if analysis_result.get('claim_data'):
            st.markdown("### ğŸ“‹ ê·¼ë¬´ì‹œê°„ Claim ë¹„êµ")
            self.render_claim_comparison(analysis_result)
        
        # í™œë™ë³„ ì‹œê°„ ìš”ì•½
        st.markdown("### ğŸ“Š í™œë™ë³„ ì‹œê°„ ë¶„ì„")
        self.render_activity_summary(analysis_result)
        
        # êµ¬ì—­ë³„ ì²´ë¥˜ ì‹œê°„ ë¶„ì„
        st.markdown("### ğŸ“ êµ¬ì—­ë³„ ì²´ë¥˜ ì‹œê°„ ë¶„ì„")
        self.render_area_summary(analysis_result)
        
        # ì‹œê³„ì—´ íƒ€ì„ë¼ì¸
        st.markdown("### ğŸ“… ì¼ì¼ í™œë™ íƒ€ì„ë¼ì¸")
        self.render_timeline_view(analysis_result)
        
        # ìƒì„¸ Gantt ì°¨íŠ¸
        st.markdown("### ğŸ“Š í™œë™ ì‹œí€€ìŠ¤ íƒ€ì„ë¼ì¸")
        # ê°œì„ ëœ Gantt ì°¨íŠ¸ ì‚¬ìš©
        improved_chart = render_improved_gantt_chart(analysis_result)
        if improved_chart:
            st.plotly_chart(improved_chart, use_container_width=True)
        else:
            # fallback to original chart
            self.render_detailed_gantt_chart(analysis_result)
        
        # ìƒì„¸ íƒœê·¸ ê¸°ë¡
        st.markdown("### ğŸ“‹ ìƒì„¸ íƒœê·¸ ê¸°ë¡")
        self.render_detailed_records(analysis_result)
    
    def render_daily_summary(self, analysis_result: dict):
        """ì¼ì¼ í™œë™ ìš”ì•½ ë Œë”ë§ (UI ì°¸ì¡°ìë£Œ ê¸°ë°˜)"""
        st.markdown("### ğŸ“ˆ ì¼ì¼ í™œë™ ìš”ì•½")
        
        work_analysis = analysis_result['work_time_analysis']
        
        # ì£¼ìš” ì§€í‘œ ëŒ€ì‹œë³´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ì‹¤ì œ ê·¼ë¬´ì‹œê°„",
                f"{work_analysis['actual_work_hours']:.1f}h",
                f"{work_analysis['actual_work_hours'] - work_analysis['claimed_work_hours']:+.1f}h"
            )
        
        with col2:
            st.metric(
                "ì—…ë¬´ íš¨ìœ¨ì„±",
                f"{work_analysis['efficiency_ratio']:.1f}%",
                "2.3%"
            )
        
        with col3:
            st.metric(
                "ë°ì´í„° ì‹ ë¢°ë„",
                f"{analysis_result['data_quality']['overall_quality_score']}%",
                "1.5%"
            )
        
        with col4:
            st.metric(
                "í™œë™ ë‹¤ì–‘ì„±",
                f"{len(work_analysis['work_breakdown'])}ê°œ",
                "1ê°œ"
            )
        
        # í™œë™ ë¶„ë¥˜ë³„ ì‹œê°„ ë¶„í¬ (í”„ë¡œê·¸ë ˆìŠ¤ ë°” ìŠ¤íƒ€ì¼)
        st.markdown("#### ğŸ“Š í™œë™ ë¶„ë¥˜ë³„ ì‹œê°„ ë¶„í¬")
        
        work_breakdown = work_analysis['work_breakdown']
        total_hours = sum(work_breakdown.values())
        
        for activity, hours in work_breakdown.items():
            percentage = (hours / total_hours * 100) if total_hours > 0 else 0
            col1, col2, col3 = st.columns([2, 6, 2])
            
            with col1:
                st.write(f"**{activity}**")
            
            with col2:
                st.progress(percentage / 100)
            
            with col3:
                st.write(f"{hours:.1f}h ({percentage:.1f}%)")
    
    def render_activity_timeline(self, analysis_result: dict):
        """í™œë™ íƒ€ì„ë¼ì¸ ë Œë”ë§ (UI ì°¸ì¡°ìë£Œ ê¸°ë°˜)"""
        st.markdown("### ğŸ“… í™œë™ íƒ€ì„ë¼ì¸")
        
        timeline_data = analysis_result['timeline_data']
        
        if not timeline_data:
            st.warning("íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # íƒ€ì„ë¼ì¸ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        df_timeline = pd.DataFrame(timeline_data)
        
        # 24ì‹œê°„ íƒ€ì„ë¼ì¸ ì°¨íŠ¸ ìƒì„±
        fig = go.Figure()
        
        # í™œë™ë³„ ìƒ‰ìƒ ë§¤í•‘
        activity_colors = {
            'ì¶œê·¼': self.colors['work'],
            'ê·¼ë¬´': self.colors['work'],
            'ì‘ì—…': self.colors['work'],
            'íšŒì˜': self.colors['meeting'],
            'ì´ë™': self.colors['movement'],
            'ì¤‘ì‹': self.colors['meal'],
            'ì¡°ì‹': self.colors['meal'],
            'ì„ì‹': self.colors['meal'],
            'ì•¼ì‹': self.colors['meal'],
            'íœ´ì‹': self.colors['rest'],
            'í‡´ê·¼': self.colors['work']
        }
        
        # ê° í™œë™ì— ëŒ€í•œ ì ê³¼ ì„  ì¶”ê°€
        for i, row in df_timeline.iterrows():
            activity = row['activity']
            color = activity_colors.get(activity, self.colors['work'])
            
            # ì‹ ë¢°ë„ì— ë”°ë¥¸ íˆ¬ëª…ë„ ì¡°ì •
            confidence = row['confidence']
            opacity = 0.5 + (confidence / 100) * 0.5
            
            fig.add_trace(go.Scatter(
                x=[row['datetime']],
                y=[activity],
                mode='markers',
                marker=dict(
                    size=15,
                    color=color,
                    opacity=opacity,
                    line=dict(width=2, color='white')
                ),
                name=activity,
                hovertemplate=(
                    f"<b>{activity}</b><br>" +
                    f"ì‹œê°„: {row['datetime'].strftime('%H:%M')}<br>" +
                    f"ìœ„ì¹˜: {row['location']}<br>" +
                    f"ì‹ ë¢°ë„: {confidence}%<br>" +
                    "<extra></extra>"
                ),
                showlegend=False
            ))
        
        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig.update_layout(
            title="ì¼ì¼ í™œë™ íƒ€ì„ë¼ì¸",
            xaxis_title="ì‹œê°„",
            yaxis_title="í™œë™",
            height=400,
            hovermode='closest'
        )
        
        # Xì¶• ì‹œê°„ í˜•ì‹ ì„¤ì •
        fig.update_xaxes(
            tickformat='%H:%M',
            dtick=3600000,  # 1ì‹œê°„ ê°„ê²©
            tickangle=45
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ë°ì´í„° ì‹ ë¢°ë„ ì‹œê°í™”
        st.markdown("#### ğŸ¯ ë°ì´í„° ì‹ ë¢°ë„ ë¶„ì„")
        
        confidence_dist = analysis_result['data_quality']['confidence_distribution']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ì‹ ë¢°ë„ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
            fig_conf = px.pie(
                values=list(confidence_dist.values()),
                names=list(confidence_dist.keys()),
                title="ë°ì´í„° ì‹ ë¢°ë„ ë¶„í¬",
                color_discrete_map={
                    'high': '#4CAF50',
                    'medium': '#FF9800',
                    'low': '#F44336'
                }
            )
            st.plotly_chart(fig_conf, use_container_width=True)
        
        with col2:
            # ì‹ ë¢°ë„ í†µê³„
            st.markdown("**ì‹ ë¢°ë„ í†µê³„**")
            st.write(f"â€¢ ë†’ì€ ì‹ ë¢°ë„: {confidence_dist['high']}%")
            st.write(f"â€¢ ì¤‘ê°„ ì‹ ë¢°ë„: {confidence_dist['medium']}%")
            st.write(f"â€¢ ë‚®ì€ ì‹ ë¢°ë„: {confidence_dist['low']}%")
            
            overall_score = analysis_result['data_quality']['overall_quality_score']
            st.write(f"â€¢ ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {overall_score}%")
    
    def render_detailed_analysis(self, analysis_result: dict):
        """ìƒì„¸ ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
        st.markdown("### ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        
        # íƒ­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ½ï¸ ì‹ì‚¬ì‹œê°„", "ğŸ”„ êµëŒ€ê·¼ë¬´", "ğŸ“Š íš¨ìœ¨ì„±", "ğŸ“ˆ íŠ¸ë Œë“œ"])
        
        with tab1:
            self.render_meal_analysis(analysis_result)
        
        with tab2:
            self.render_shift_analysis(analysis_result)
        
        with tab3:
            self.render_efficiency_analysis(analysis_result)
        
        with tab4:
            self.render_trend_analysis(analysis_result)
    
    def render_meal_analysis(self, analysis_result: dict):
        """ì‹ì‚¬ì‹œê°„ ë¶„ì„ ë Œë”ë§"""
        st.markdown("#### ğŸ½ï¸ ì‹ì‚¬ì‹œê°„ ë¶„ì„ (4ë²ˆ ì‹ì‚¬)")
        
        meal_analysis = analysis_result['meal_time_analysis']
        meal_patterns = meal_analysis['meal_patterns']
        
        # ì‹ì‚¬ë³„ í†µê³„
        col1, col2 = st.columns(2)
        
        with col1:
            # ì‹ì‚¬ ë¹ˆë„ ì°¨íŠ¸
            meal_names = list(meal_patterns.keys())
            frequencies = [meal_patterns[meal]['frequency'] for meal in meal_names]
            
            fig_freq = px.bar(
                x=meal_names,
                y=frequencies,
                title="ì‹ì‚¬ë³„ ë¹ˆë„",
                color=meal_names,
                color_discrete_map={
                    'ì¡°ì‹': '#FF6B6B',
                    'ì¤‘ì‹': '#4ECDC4',
                    'ì„ì‹': '#45B7D1',
                    'ì•¼ì‹': '#96CEB4'
                }
            )
            st.plotly_chart(fig_freq, use_container_width=True)
        
        with col2:
            # ì‹ì‚¬ ì§€ì†ì‹œê°„ ì°¨íŠ¸
            durations = [meal_patterns[meal]['avg_duration'] for meal in meal_names]
            
            fig_duration = px.bar(
                x=meal_names,
                y=durations,
                title="ì‹ì‚¬ë³„ í‰ê·  ì§€ì†ì‹œê°„ (ë¶„)",
                color=meal_names,
                color_discrete_map={
                    'ì¡°ì‹': '#FF6B6B',
                    'ì¤‘ì‹': '#4ECDC4',
                    'ì„ì‹': '#45B7D1',
                    'ì•¼ì‹': '#96CEB4'
                }
            )
            st.plotly_chart(fig_duration, use_container_width=True)
        
        # ì‹ì‚¬ íŒ¨í„´ ìš”ì•½
        st.markdown("**ì‹ì‚¬ íŒ¨í„´ ìš”ì•½**")
        total_meal_time = meal_analysis['total_meal_time']
        st.write(f"â€¢ ì´ ì‹ì‚¬ì‹œê°„: {total_meal_time}ë¶„ ({total_meal_time/60:.1f}ì‹œê°„)")
        
        for meal, data in meal_patterns.items():
            st.write(f"â€¢ {meal}: {data['frequency']}íšŒ, í‰ê·  {data['avg_duration']}ë¶„")
    
    def render_shift_analysis(self, analysis_result: dict):
        """êµëŒ€ê·¼ë¬´ ë¶„ì„ ë Œë”ë§"""
        st.markdown("#### ğŸ”„ êµëŒ€ê·¼ë¬´ ë¶„ì„")
        
        shift_analysis = analysis_result['shift_analysis']
        shift_patterns = shift_analysis['shift_patterns']
        
        # êµëŒ€ë³„ ê·¼ë¬´ì‹œê°„ ë¹„êµ
        shifts = list(shift_patterns.keys())
        work_hours = [shift_patterns[shift]['work_hours'] for shift in shifts]
        activity_counts = [shift_patterns[shift]['activity_count'] for shift in shifts]
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_hours = px.bar(
                x=shifts,
                y=work_hours,
                title="êµëŒ€ë³„ ê·¼ë¬´ì‹œê°„",
                color=shifts,
                color_discrete_map={
                    'ì£¼ê°„': '#87CEEB',
                    'ì•¼ê°„': '#4169E1'
                }
            )
            st.plotly_chart(fig_hours, use_container_width=True)
        
        with col2:
            fig_activities = px.bar(
                x=shifts,
                y=activity_counts,
                title="êµëŒ€ë³„ í™œë™ ìˆ˜",
                color=shifts,
                color_discrete_map={
                    'ì£¼ê°„': '#87CEEB',
                    'ì•¼ê°„': '#4169E1'
                }
            )
            st.plotly_chart(fig_activities, use_container_width=True)
        
        # êµëŒ€ ì„ í˜¸ë„
        preferred_shift = shift_analysis['preferred_shift']
        st.success(f"**ì„ í˜¸ êµëŒ€:** {preferred_shift}")
        
        # êµëŒ€ë³„ íš¨ìœ¨ì„± ê³„ì‚°
        for shift in shifts:
            hours = shift_patterns[shift]['work_hours']
            activities = shift_patterns[shift]['activity_count']
            efficiency = (activities / hours) if hours > 0 else 0
            st.write(f"â€¢ {shift} êµëŒ€ íš¨ìœ¨ì„±: {efficiency:.1f} í™œë™/ì‹œê°„")
    
    def render_efficiency_analysis(self, analysis_result: dict):
        """íš¨ìœ¨ì„± ë¶„ì„ ë Œë”ë§"""
        st.markdown("#### ğŸ“Š íš¨ìœ¨ì„± ë¶„ì„")
        
        work_analysis = analysis_result['work_time_analysis']
        efficiency_ratio = work_analysis['efficiency_ratio']
        
        # íš¨ìœ¨ì„± ê²Œì´ì§€ ì°¨íŠ¸
        fig_gauge = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = efficiency_ratio,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "ì—…ë¬´ íš¨ìœ¨ì„± (%)"},
            delta = {'reference': 85},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 50], 'color': "lightgray"},
                    {'range': [50, 80], 'color': "gray"},
                    {'range': [80, 100], 'color': "lightgreen"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        
        st.plotly_chart(fig_gauge, use_container_width=True)
        
        # íš¨ìœ¨ì„± ë¶„ì„ ìš”ì•½
        st.markdown("**íš¨ìœ¨ì„± ë¶„ì„ ìš”ì•½**")
        
        if efficiency_ratio >= 90:
            st.success("ğŸ‰ ë§¤ìš° ìš°ìˆ˜í•œ íš¨ìœ¨ì„±ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤!")
        elif efficiency_ratio >= 80:
            st.info("ğŸ‘ ì–‘í˜¸í•œ íš¨ìœ¨ì„±ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
        elif efficiency_ratio >= 70:
            st.warning("âš ï¸ íš¨ìœ¨ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.error("âŒ íš¨ìœ¨ì„±ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ê°œì„  ì œì•ˆ
        if efficiency_ratio < 85:
            st.markdown("**ê°œì„  ì œì•ˆ**")
            st.write("â€¢ ì§‘ì¤‘ ê·¼ë¬´ ì‹œê°„ ëŠ˜ë¦¬ê¸°")
            st.write("â€¢ ë¶ˆí•„ìš”í•œ ì´ë™ ì¤„ì´ê¸°")
            st.write("â€¢ íš¨ìœ¨ì ì¸ ì—…ë¬´ ìŠ¤ì¼€ì¤„ë§")
    
    def render_trend_analysis(self, analysis_result: dict):
        """íŠ¸ë Œë“œ ë¶„ì„ ë Œë”ë§"""
        st.markdown("#### ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„")
        
        # ìƒ˜í”Œ ì£¼ê°„ íŠ¸ë Œë“œ ë°ì´í„°
        dates = pd.date_range(start=date.today()-timedelta(days=7), 
                             end=date.today(), freq='D')
        
        trend_data = pd.DataFrame({
            'date': dates,
            'efficiency': np.random.uniform(80, 95, len(dates)),
            'work_hours': np.random.uniform(7.5, 9.0, len(dates)),
            'activity_count': np.random.randint(30, 60, len(dates))
        })
        
        # íŠ¸ë Œë“œ ì°¨íŠ¸
        fig_trend = make_subplots(
            rows=2, cols=2,
            subplot_titles=('ì¼ë³„ íš¨ìœ¨ì„±', 'ì¼ë³„ ê·¼ë¬´ì‹œê°„', 'ì¼ë³„ í™œë™ ìˆ˜', 'ì¢…í•© íŠ¸ë Œë“œ'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": True}]]
        )
        
        # íš¨ìœ¨ì„± íŠ¸ë Œë“œ
        fig_trend.add_trace(
            go.Scatter(x=trend_data['date'], y=trend_data['efficiency'], 
                      mode='lines+markers', name='íš¨ìœ¨ì„±'),
            row=1, col=1
        )
        
        # ê·¼ë¬´ì‹œê°„ íŠ¸ë Œë“œ
        fig_trend.add_trace(
            go.Scatter(x=trend_data['date'], y=trend_data['work_hours'], 
                      mode='lines+markers', name='ê·¼ë¬´ì‹œê°„'),
            row=1, col=2
        )
        
        # í™œë™ ìˆ˜ íŠ¸ë Œë“œ
        fig_trend.add_trace(
            go.Scatter(x=trend_data['date'], y=trend_data['activity_count'], 
                      mode='lines+markers', name='í™œë™ ìˆ˜'),
            row=2, col=1
        )
        
        # ì¢…í•© íŠ¸ë Œë“œ (íš¨ìœ¨ì„±ê³¼ ê·¼ë¬´ì‹œê°„)
        fig_trend.add_trace(
            go.Scatter(x=trend_data['date'], y=trend_data['efficiency'], 
                      mode='lines', name='íš¨ìœ¨ì„±', line=dict(color='blue')),
            row=2, col=2
        )
        
        fig_trend.add_trace(
            go.Scatter(x=trend_data['date'], y=trend_data['work_hours'], 
                      mode='lines', name='ê·¼ë¬´ì‹œê°„', line=dict(color='red')),
            row=2, col=2, secondary_y=True
        )
        
        fig_trend.update_layout(height=600, showlegend=True)
        st.plotly_chart(fig_trend, use_container_width=True)
        
        # íŠ¸ë Œë“œ ë¶„ì„ ìš”ì•½
        st.markdown("**íŠ¸ë Œë“œ ë¶„ì„ ìš”ì•½**")
        
        efficiency_trend = "ì¦ê°€" if trend_data['efficiency'].iloc[-1] > trend_data['efficiency'].iloc[0] else "ê°ì†Œ"
        work_hours_trend = "ì¦ê°€" if trend_data['work_hours'].iloc[-1] > trend_data['work_hours'].iloc[0] else "ê°ì†Œ"
        
        st.write(f"â€¢ íš¨ìœ¨ì„± íŠ¸ë Œë“œ: {efficiency_trend}")
        st.write(f"â€¢ ê·¼ë¬´ì‹œê°„ íŠ¸ë Œë“œ: {work_hours_trend}")
        st.write(f"â€¢ í‰ê·  ì¼ì¼ í™œë™ ìˆ˜: {trend_data['activity_count'].mean():.1f}ê°œ")
    
    def render_activity_summary(self, analysis_result: dict):
        """í™œë™ë³„ ì‹œê°„ ìš”ì•½ ë Œë”ë§"""
        activity_summary = analysis_result['activity_summary']
        
        # ë°ì´í„° ì¤€ë¹„
        activities = []
        for activity_code, minutes in activity_summary.items():
            activities.append({
                'í™œë™': get_activity_name(activity_code, 'ko'),
                'ì‹œê°„(ë¶„)': round(minutes, 1),
                'ì‹œê°„': f"{int(minutes//60)}ì‹œê°„ {int(minutes%60)}ë¶„",
                'ë¹„ìœ¨(%)': round(minutes / sum(activity_summary.values()) * 100, 1),
                'activity_code': activity_code  # ìƒ‰ìƒ ë§¤í•‘ìš©
            })
        
        df_activities = pd.DataFrame(activities)
        
        # ì°¨íŠ¸ì™€ í…Œì´ë¸” í‘œì‹œ
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # íŒŒì´ ì°¨íŠ¸ - ìƒˆë¡œìš´ ìƒ‰ìƒ ë§¤í•‘
            color_map = {}
            for _, row in df_activities.iterrows():
                activity_name = row['í™œë™']
                activity_code = row['activity_code']
                color_map[activity_name] = get_activity_color(activity_code)
            
            fig = px.pie(df_activities, values='ì‹œê°„(ë¶„)', names='í™œë™', 
                        title='í™œë™ë³„ ì‹œê°„ ë¶„í¬',
                        color_discrete_map=color_map)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ìš”ì•½ í…Œì´ë¸”
            st.dataframe(df_activities[['í™œë™', 'ì‹œê°„', 'ë¹„ìœ¨(%)']], 
                        use_container_width=True, hide_index=True)
    
    def render_timeline_view(self, analysis_result: dict):
        """ì‹œê³„ì—´ íƒ€ì„ë¼ì¸ ë·° ë Œë”ë§ - Gantt ì°¨íŠ¸ í˜•íƒœ"""
        segments = analysis_result['activity_segments']
        
        # í™œë™ë³„ ìƒ‰ìƒ ë° í•œê¸€ëª…
        activity_colors = {
            'work': self.colors['work'],
            'meeting': self.colors['meeting'],
            'movement': self.colors['movement'],
            'breakfast': self.colors['meal'],
            'lunch': self.colors['meal'],
            'dinner': self.colors['meal'],
            'midnight_meal': self.colors['meal'],
            'rest': self.colors['rest']
        }
        
        activity_names = {
            'work': 'ì—…ë¬´',
            'meeting': 'íšŒì˜',
            'movement': 'ì´ë™',
            'breakfast': 'ì¡°ì‹',
            'lunch': 'ì¤‘ì‹',
            'dinner': 'ì„ì‹',
            'midnight_meal': 'ì•¼ì‹',
            'rest': 'íœ´ì‹'
        }
        
        # Gantt ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
        gantt_data = []
        for i, segment in enumerate(segments):
            # NaT ì²˜ë¦¬
            if pd.notna(segment['start_time']) and pd.notna(segment['end_time']):
                activity_code = segment.get('activity_code', 'WORK')
                gantt_data.append({
                    'Task': get_activity_name(activity_code, 'ko'),
                    'Start': segment['start_time'],
                    'Finish': segment['end_time'],
                    'Resource': activity_code,
                    'Location': segment['location'],
                    'Duration': segment['duration_minutes']
                })
        
        if not gantt_data:
            st.warning("íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # Gantt ì°¨íŠ¸ ìƒì„±
        df_gantt = pd.DataFrame(gantt_data)
        
        # ìƒ‰ìƒ ë§¤í•‘ ìƒì„±
        color_map = {}
        for code in df_gantt['Resource'].unique():
            color_map[code] = get_activity_color(code)
        
        fig = px.timeline(
            df_gantt,
            x_start="Start",
            x_end="Finish",
            y="Task",
            color="Resource",
            color_discrete_map=color_map,
            hover_data={'Location': True, 'Duration': True},
            title="ì¼ì¼ í™œë™ íƒ€ì„ë¼ì¸ (Gantt Chart)"
        )
        
        # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
        # ë²”ë¡€ë¥¼ í•œê¸€ë¡œ í‘œì‹œ
        for trace in fig.data:
            if trace.name in color_map:
                # Resource ì½”ë“œë¥¼ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜
                korean_name = get_activity_name(trace.name, 'ko')
                trace.name = korean_name
        
        fig.update_layout(
            height=300,
            xaxis_title="ì‹œê°„",
            yaxis_title="í™œë™",
            showlegend=True,
            legend_title_text="í™œë™ ìœ í˜•",
            hovermode='closest'
        )
        
        # Yì¶•ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë ¬ (ì¶œê·¼ ë§¨ ìœ„, í‡´ê·¼ ë§¨ ì•„ë˜)
        category_order = [
            'ì¶œê·¼',  # ë§¨ ìœ„
            'ì§‘ì¤‘ê·¼ë¬´', 'ê·¼ë¬´', 'ì‘ì—…ì¤‘', 'ì¥ë¹„ì¡°ì‘', 'ì‘ì—…ì¤€ë¹„',  # ê·¼ë¬´ ê´€ë ¨
            'íšŒì˜',  # íšŒì˜
            'ì¡°ì‹', 'ì¤‘ì‹', 'ì„ì‹', 'ì•¼ì‹',  # ì‹ì‚¬
            'í”¼íŠ¸ë‹ˆìŠ¤', 'íœ´ì‹',  # íœ´ì‹
            'ì´ë™',  # ì´ë™
            'ëŒ€ê¸°', 'ë¯¸ë¶„ë¥˜',  # ê¸°íƒ€
            'í‡´ê·¼'  # ë§¨ ì•„ë˜
        ]
        # ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§í•˜ê³  ìˆœì„œ ìœ ì§€
        actual_categories = list(df_gantt['Task'].unique())
        filtered_order = []
        
        # ì •ì˜ëœ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
        for cat in category_order:
            if cat in actual_categories:
                filtered_order.append(cat)
        
        # ì •ì˜ë˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ê°€ ìˆìœ¼ë©´ ì¤‘ê°„ì— ì¶”ê°€
        for cat in actual_categories:
            if cat not in filtered_order:
                # í‡´ê·¼ ë°”ë¡œ ìœ„ì— ì¶”ê°€
                if 'í‡´ê·¼' in filtered_order:
                    idx = filtered_order.index('í‡´ê·¼')
                    filtered_order.insert(idx, cat)
                else:
                    filtered_order.append(cat)
        
        fig.update_yaxes(categoryorder="array", categoryarray=filtered_order)
        
        # Xì¶• ì‹œê°„ í¬ë§· ì„¤ì •
        fig.update_xaxes(
            tickformat='%H:%M',
            dtick=3600000,  # 1ì‹œê°„ ê°„ê²©
            tickangle=0
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def render_detailed_gantt_chart(self, analysis_result: dict):
        """ìƒì„¸ Gantt ì°¨íŠ¸ ë Œë”ë§ - ëª¨ë“  í™œë™ì„ í•œ ì¤„ì— í‘œì‹œ"""
        segments = analysis_result['activity_segments']
        
        # í™œë™ë³„ ìƒ‰ìƒ
        activity_colors = {
            'work': self.colors['work'],
            'meeting': self.colors['meeting'],
            'movement': self.colors['movement'],
            'breakfast': self.colors['meal'],
            'lunch': self.colors['meal'],
            'dinner': self.colors['meal'],
            'midnight_meal': self.colors['meal'],
            'rest': self.colors['rest']
        }
        
        # í™œë™ í•œê¸€ëª…
        activity_names = {
            'work': 'ì—…ë¬´',
            'meeting': 'íšŒì˜',
            'movement': 'ì´ë™',
            'breakfast': 'ì¡°ì‹',
            'lunch': 'ì¤‘ì‹',
            'dinner': 'ì„ì‹',
            'midnight_meal': 'ì•¼ì‹',
            'rest': 'íœ´ì‹'
        }
        
        # ì‘ì—… ì‹œì‘/ì¢…ë£Œ ì‹œê°„
        work_start = analysis_result['work_start']
        work_end = analysis_result['work_end']
        
        # ëª¨ë“  í™œë™ì„ í•˜ë‚˜ì˜ íƒ€ì„ë¼ì¸ì— í‘œì‹œ
        fig = go.Figure()
        
        for i, segment in enumerate(segments):
            if pd.notna(segment['start_time']) and pd.notna(segment['end_time']):
                activity_code = segment.get('activity_code', 'WORK')
                
                # ì‹œê°„ì„ ë¶„ ë‹¨ìœ„ë¡œ ë³€í™˜
                start_minutes = (segment['start_time'] - work_start).total_seconds() / 60
                duration = segment['duration_minutes']
                
                # hover í…ìŠ¤íŠ¸ ìƒì„±
                hover_text = (
                    f"<b>{get_activity_name(activity_code, 'ko')}</b><br>" +
                    f"ì‹œê°„: {segment['start_time'].strftime('%H:%M')} - {segment['end_time'].strftime('%H:%M')}<br>" +
                    f"ìœ„ì¹˜: {segment['location']}<br>" +
                    f"ì²´ë¥˜: {duration:.0f}ë¶„"
                )
                
                # ë§‰ëŒ€ ì¶”ê°€
                fig.add_trace(go.Bar(
                    x=[duration],
                    y=['í™œë™'],
                    orientation='h',
                    base=start_minutes,
                    marker_color=get_activity_color(activity_code),
                    name=get_activity_name(activity_code, 'ko'),
                    hovertemplate=hover_text + "<extra></extra>",
                    showlegend=False,
                    width=0.8
                ))
        
        # ë ˆì „ë“œë¥¼ ìœ„í•œ ë”ë¯¸ íŠ¸ë ˆì´ìŠ¤ ì¶”ê°€
        added_legends = set()
        # ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ” í™œë™ ì½”ë“œë§Œ ë ˆì „ë“œì— ì¶”ê°€
        activity_codes_in_data = set(seg.get('activity_code', 'WORK') for seg in segments)
        
        for activity_code in activity_codes_in_data:
            if activity_code not in added_legends:
                fig.add_trace(go.Scatter(
                    x=[None],
                    y=[None],
                    mode='markers',
                    marker=dict(color=get_activity_color(activity_code), size=10),
                    name=get_activity_name(activity_code, 'ko'),
                    showlegend=True
                ))
                added_legends.add(activity_code)
        
        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        total_minutes = (work_end - work_start).total_seconds() / 60
        
        fig.update_layout(
            title="í•˜ë£¨ ì „ì²´ í™œë™ ì‹œí€€ìŠ¤",
            height=250,
            barmode='overlay',
            xaxis=dict(
                title="ì‹œê°„",
                tickmode='array',
                tickvals=[i * 60 for i in range(int(total_minutes // 60) + 2)],
                ticktext=[(work_start + timedelta(hours=i)).strftime('%H:%M') 
                         for i in range(int(total_minutes // 60) + 2)],
                range=[0, total_minutes]
            ),
            yaxis=dict(
                showticklabels=False,
                range=[-0.5, 0.5]
            ),
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ì£¼ìš” í™œë™ êµ¬ê°„ í‘œì‹œ
        st.markdown("#### ì£¼ìš” í™œë™ êµ¬ê°„")
        
        # 30ë¶„ ì´ìƒ ì²´ë¥˜í•œ êµ¬ê°„ë§Œ í‘œì‹œ
        major_segments = [s for s in segments if s['duration_minutes'] >= 30]
        
        if major_segments:
            segment_data = []
            for seg in major_segments[:10]:  # ìƒìœ„ 10ê°œë§Œ
                # NaT ì²˜ë¦¬
                start_str = seg['start_time'].strftime('%H:%M') if pd.notna(seg['start_time']) else 'N/A'
                end_str = seg['end_time'].strftime('%H:%M') if pd.notna(seg['end_time']) else 'N/A'
                
                segment_data.append({
                    'ì‹œì‘': start_str,
                    'ì¢…ë£Œ': end_str,
                    'í™œë™': get_activity_name(seg.get('activity_code', 'WORK'), 'ko'),
                    'ìœ„ì¹˜': seg['location'],
                    'ì²´ë¥˜ì‹œê°„': f"{int(seg['duration_minutes'])}ë¶„"
                })
            
            df_segments = pd.DataFrame(segment_data)
            st.dataframe(df_segments, use_container_width=True, hide_index=True)
    
    def render_detailed_records(self, analysis_result: dict):
        """ìƒì„¸ íƒœê·¸ ê¸°ë¡ ë Œë”ë§"""
        raw_data = analysis_result['raw_data']
        
        # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
        display_columns = ['datetime', 'DR_NO', 'DR_NM', 'INOUT_GB', 'activity_code', 'activity_type', 
                          'work_area_type', 'work_status', 'activity_label', 'duration_minutes']
        
        # ì¼ë¶€ ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í™•ì¸
        available_columns = [col for col in display_columns if col in raw_data.columns]
        
        # ì»¬ëŸ¼ëª… í•œê¸€í™”
        column_names = {
            'datetime': 'ì‹œê°',
            'DR_NO': 'ê²Œì´íŠ¸ ë²ˆí˜¸',
            'DR_NM': 'ìœ„ì¹˜',
            'INOUT_GB': 'ì…/ì¶œ',
            'activity_code': 'í™œë™ ì½”ë“œ',
            'activity_type': 'í™œë™ ë¶„ë¥˜',
            'work_area_type': 'êµ¬ì—­',
            'work_status': 'ìƒíƒœ',
            'activity_label': 'ë¼ë²¨',
            'duration_minutes': 'ì²´ë¥˜ì‹œê°„(ë¶„)'
        }
        
        # ë°ì´í„°í”„ë ˆì„ ì¤€ë¹„
        df_display = raw_data[available_columns].copy()
        df_display['datetime'] = df_display['datetime'].dt.strftime('%H:%M:%S')
        df_display['duration_minutes'] = df_display['duration_minutes'].round(1)
        
        # í™œë™ ì½”ë“œë¥¼ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜
        if 'activity_code' in df_display.columns:
            df_display['activity_code'] = df_display['activity_code'].apply(
                lambda x: get_activity_name(x, 'ko')
            )
        
        # êµ¬ì—­ íƒ€ì… í•œê¸€ ë³€í™˜
        if 'work_area_type' in df_display.columns:
            area_type_map = {'Y': 'ê·¼ë¬´êµ¬ì—­', 'G': '1ì„ ê²Œì´íŠ¸', 'N': 'ë¹„ê·¼ë¬´êµ¬ì—­'}
            df_display['work_area_type'] = df_display['work_area_type'].map(area_type_map).fillna(df_display['work_area_type'])
        
        # ìƒíƒœ í•œê¸€ ë³€í™˜
        if 'work_status' in df_display.columns:
            status_map = {'W': 'ê·¼ë¬´', 'M': 'ì´ë™', 'N': 'ë¹„ê·¼ë¬´'}
            df_display['work_status'] = df_display['work_status'].map(status_map).fillna(df_display['work_status'])
        
        df_display = df_display.rename(columns=column_names)
        
        # í•„í„°ë§ ì˜µì…˜
        col1, col2 = st.columns(2)
        with col1:
            activity_filter = st.multiselect(
                "í™œë™ ìœ í˜• í•„í„°",
                options=df_display['í™œë™ ë¶„ë¥˜'].unique(),
                default=df_display['í™œë™ ë¶„ë¥˜'].unique()
            )
        
        with col2:
            location_filter = st.text_input("ìœ„ì¹˜ ê²€ìƒ‰", "")
        
        # í•„í„° ì ìš©
        filtered_df = df_display[df_display['í™œë™ ë¶„ë¥˜'].isin(activity_filter)]
        if location_filter:
            filtered_df = filtered_df[filtered_df['ìœ„ì¹˜'].str.contains(location_filter, case=False, na=False)]
        
        # ë°ì´í„° í‘œì‹œ (height ì œê±°í•˜ì—¬ ì „ì²´ í‘œì‹œ)
        st.dataframe(filtered_df, use_container_width=True, hide_index=True)
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        csv = filtered_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"íƒœê·¸ê¸°ë¡_{analysis_result['employee_id']}_{analysis_result['analysis_date']}.csv",
            mime='text/csv'
        )
    
    def render_claim_comparison(self, analysis_result: dict):
        """Claim ë°ì´í„°ì™€ ì‹¤ì œ ê·¼ë¬´ì‹œê°„ ë¹„êµ"""
        claim_data = analysis_result['claim_data']
        
        # ì‹¤ì œ ê·¼ë¬´ì‹œê°„ê³¼ Claim ì‹œê°„ ë¹„êµ
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**ğŸ·ï¸ Claim ë°ì´í„°**")
            st.write(f"â€¢ ì‹ ê³  ì¶œê·¼: {claim_data['claim_start']}")
            st.write(f"â€¢ ì‹ ê³  í‡´ê·¼: {claim_data['claim_end']}")
            st.write(f"â€¢ ì‹ ê³  ê·¼ë¬´ì‹œê°„: {claim_data['claim_hours']}ì‹œê°„")
            st.write(f"â€¢ ê·¼ë¬´ìœ í˜•: {claim_data['claim_type']}")
            if claim_data['overtime'] > 0:
                st.write(f"â€¢ ì´ˆê³¼ê·¼ë¬´: {claim_data['overtime']}ì‹œê°„")
        
        with col2:
            st.markdown("**ğŸ“ ì‹¤ì œ íƒœê·¸ ë°ì´í„°**")
            st.write(f"â€¢ ì‹¤ì œ ì¶œê·¼: {analysis_result['work_start'].strftime('%H:%M')}")
            st.write(f"â€¢ ì‹¤ì œ í‡´ê·¼: {analysis_result['work_end'].strftime('%H:%M')}")
            st.write(f"â€¢ ì‹¤ì œ ê·¼ë¬´ì‹œê°„: {analysis_result['total_hours']:.1f}ì‹œê°„")
            
            # ì‹¤ì œ í™œë™ ì‹œê°„ ê³„ì‚°
            activity_summary = analysis_result['activity_summary']
            work_activities = ['work', 'meeting']
            actual_work_time = sum(activity_summary.get(act, 0) for act in work_activities) / 60
            st.write(f"â€¢ ìˆœìˆ˜ ì—…ë¬´ì‹œê°„: {actual_work_time:.1f}ì‹œê°„")
        
        with col3:
            st.markdown("**ğŸ“Š ì°¨ì´ ë¶„ì„**")
            
            # ì‹œê°„ ì°¨ì´ ê³„ì‚°
            time_diff = analysis_result['total_hours'] - claim_data['claim_hours']
            
            if abs(time_diff) < 0.5:
                st.success(f"âœ… ê±°ì˜ ì¼ì¹˜ (ì°¨ì´: {abs(time_diff):.1f}ì‹œê°„)")
            elif time_diff > 0:
                st.warning(f"âš ï¸ ì‹¤ì œê°€ ë” ê¹€ (+{time_diff:.1f}ì‹œê°„)")
            else:
                st.info(f"â„¹ï¸ ì‹ ê³ ê°€ ë” ê¹€ ({time_diff:.1f}ì‹œê°„)")
            
            # íš¨ìœ¨ì„± ê³„ì‚°
            if claim_data['claim_hours'] > 0:
                efficiency = (actual_work_time / claim_data['claim_hours']) * 100
                st.write(f"â€¢ ì—…ë¬´ íš¨ìœ¨ì„±: {efficiency:.1f}%")
        
        # ì‹œê°ì  ë¹„êµ
        st.markdown("#### ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ë¹„êµ")
        self.render_time_comparison_chart(analysis_result, claim_data)
    
    def render_time_comparison_chart(self, analysis_result: dict, claim_data: dict):
        """ì‹œê°„ëŒ€ë³„ ë¹„êµ ì°¨íŠ¸"""
        fig = go.Figure()
        
        # Claim ì‹œê°„ëŒ€
        claim_start_str = str(claim_data['claim_start'])
        claim_end_str = str(claim_data['claim_end'])
        
        # ì‹œê°„ íŒŒì‹± ì‹œë„
        try:
            if len(claim_start_str) == 4:  # HHMM í˜•ì‹
                claim_start_hour = int(claim_start_str[:2])
                claim_start_min = int(claim_start_str[2:])
            else:
                claim_start_hour = 8
                claim_start_min = 0
                
            if len(claim_end_str) == 4:  # HHMM í˜•ì‹
                claim_end_hour = int(claim_end_str[:2])
                claim_end_min = int(claim_end_str[2:])
            else:
                claim_end_hour = 17
                claim_end_min = 0
        except:
            claim_start_hour, claim_start_min = 8, 0
            claim_end_hour, claim_end_min = 17, 0
        
        # ì‹¤ì œ ê·¼ë¬´ì‹œê°„
        actual_start = analysis_result['work_start'].hour + analysis_result['work_start'].minute / 60
        actual_end = analysis_result['work_end'].hour + analysis_result['work_end'].minute / 60
        
        # Claim ê·¼ë¬´ì‹œê°„
        claim_start = claim_start_hour + claim_start_min / 60
        claim_end = claim_end_hour + claim_end_min / 60
        
        # ì°¨íŠ¸ì— ì¶”ê°€
        fig.add_trace(go.Bar(
            x=[actual_end - actual_start],
            y=['ì‹¤ì œ ê·¼ë¬´'],
            orientation='h',
            name='ì‹¤ì œ',
            marker_color='lightblue',
            base=actual_start,
            text=f"{analysis_result['work_start'].strftime('%H:%M')} - {analysis_result['work_end'].strftime('%H:%M')}",
            textposition='inside'
        ))
        
        fig.add_trace(go.Bar(
            x=[claim_end - claim_start],
            y=['ì‹ ê³  ê·¼ë¬´'],
            orientation='h',
            name='Claim',
            marker_color='lightgreen',
            base=claim_start,
            text=f"{claim_start_hour:02d}:{claim_start_min:02d} - {claim_end_hour:02d}:{claim_end_min:02d}",
            textposition='inside'
        ))
        
        # ë ˆì´ì•„ì›ƒ
        fig.update_layout(
            title="ê·¼ë¬´ì‹œê°„ ë¹„êµ",
            xaxis_title="ì‹œê°„",
            height=200,
            showlegend=True,
            xaxis=dict(
                tickmode='linear',
                tick0=0,
                dtick=2,
                range=[0, 24]
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def render_area_summary(self, analysis_result: dict):
        """êµ¬ì—­ë³„ ì²´ë¥˜ ì‹œê°„ ë¶„ì„ ë Œë”ë§"""
        area_summary = analysis_result.get('area_summary', {})
        
        if not area_summary:
            st.info("êµ¬ì—­ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # êµ¬ì—­ í•œê¸€ëª… ë§¤í•‘
        area_names = {
            'Y': 'ê·¼ë¬´êµ¬ì—­',
            'G': '1ì„ ê²Œì´íŠ¸',
            'N': 'ë¹„ê·¼ë¬´êµ¬ì—­'
        }
        
        # ì „ì²´ ì‹œê°„ ê³„ì‚°
        total_minutes = sum(area_summary.values())
        
        col1, col2, col3 = st.columns(3)
        
        # ê·¼ë¬´êµ¬ì—­ ì‹œê°„
        work_area_minutes = area_summary.get('Y', 0)
        work_area_hours = work_area_minutes / 60
        work_area_percent = (work_area_minutes / total_minutes * 100) if total_minutes > 0 else 0
        
        with col1:
            st.metric(
                "ê·¼ë¬´êµ¬ì—­ ì²´ë¥˜",
                f"{work_area_hours:.1f}ì‹œê°„",
                f"{work_area_percent:.1f}%"
            )
        
        # ë¹„ê·¼ë¬´êµ¬ì—­ ì‹œê°„
        non_work_minutes = area_summary.get('N', 0)
        non_work_hours = non_work_minutes / 60
        non_work_percent = (non_work_minutes / total_minutes * 100) if total_minutes > 0 else 0
        
        with col2:
            st.metric(
                "ë¹„ê·¼ë¬´êµ¬ì—­ ì²´ë¥˜",
                f"{non_work_hours:.1f}ì‹œê°„",
                f"{non_work_percent:.1f}%",
                delta_color="inverse"  # ë¹„ê·¼ë¬´êµ¬ì—­ì€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
            )
        
        # ê²Œì´íŠ¸ í†µê³¼ ì‹œê°„
        gate_minutes = area_summary.get('G', 0)
        gate_percent = (gate_minutes / total_minutes * 100) if total_minutes > 0 else 0
        
        with col3:
            st.metric(
                "ê²Œì´íŠ¸ í†µê³¼",
                f"{gate_minutes:.0f}ë¶„",
                f"{gate_percent:.1f}%"
            )
        
        # êµ¬ì—­ë³„ ë¶„í¬ ì°¨íŠ¸
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # íŒŒì´ ì°¨íŠ¸
            area_data = []
            for area_code, minutes in area_summary.items():
                area_data.append({
                    'êµ¬ì—­': area_names.get(area_code, area_code),
                    'ì‹œê°„(ë¶„)': minutes,
                    'ë¹„ìœ¨(%)': round(minutes / total_minutes * 100, 1) if total_minutes > 0 else 0
                })
            
            df_areas = pd.DataFrame(area_data)
            
            # ìƒ‰ìƒ ì„¤ì •
            colors = {
                'ê·¼ë¬´êµ¬ì—­': '#2E86AB',  # íŒŒë€ìƒ‰
                'ë¹„ê·¼ë¬´êµ¬ì—­': '#FF6B6B',  # ë¹¨ê°„ìƒ‰
                '1ì„ ê²Œì´íŠ¸': '#FFD700'  # ê¸ˆìƒ‰
            }
            
            fig = px.pie(
                df_areas, 
                values='ì‹œê°„(ë¶„)', 
                names='êµ¬ì—­',
                title='êµ¬ì—­ë³„ ì²´ë¥˜ ì‹œê°„ ë¶„í¬',
                color_discrete_map=colors
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ìš”ì•½ í…Œì´ë¸”
            st.markdown("#### êµ¬ì—­ë³„ ìƒì„¸")
            for _, row in df_areas.iterrows():
                st.write(f"**{row['êµ¬ì—­']}**")
                st.write(f"- ì‹œê°„: {int(row['ì‹œê°„(ë¶„)']//60)}ì‹œê°„ {int(row['ì‹œê°„(ë¶„)']%60)}ë¶„")
                st.write(f"- ë¹„ìœ¨: {row['ë¹„ìœ¨(%)']}%")
                st.write("")
        
        # ë¹„ê·¼ë¬´êµ¬ì—­ ì²´ë¥˜ê°€ ë§ì€ ê²½ìš° ê²½ê³ 
        if non_work_percent > 30:
            st.warning(f"âš ï¸ ë¹„ê·¼ë¬´êµ¬ì—­ ì²´ë¥˜ ì‹œê°„ì´ {non_work_percent:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì—…ë¬´ íš¨ìœ¨ì„± ê°œì„ ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif non_work_percent > 20:
            st.info(f"â„¹ï¸ ë¹„ê·¼ë¬´êµ¬ì—­ ì²´ë¥˜ ì‹œê°„: {non_work_percent:.1f}%")