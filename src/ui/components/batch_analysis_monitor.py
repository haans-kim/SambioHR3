"""
ë°°ì¹˜ ë¶„ì„ ëª¨ë‹ˆí„°ë§ UI ì»´í¬ë„ŒíŠ¸
ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í‘œì‹œ ë° ë³‘ë ¬ ì²˜ë¦¬ ê´€ë¦¬
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, date, timedelta
import time
import threading
from typing import Dict, Any, Optional
import psutil
import logging

from src.analysis.parallel_batch_analyzer import ParallelBatchAnalyzer
from src.database import get_database_manager, get_pickle_manager


class BatchAnalysisMonitor:
    """ë°°ì¹˜ ë¶„ì„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"""
    
    def __init__(self):
        self.analyzer = None
        self.analysis_thread = None
        self.is_running = False
        
    def render(self):
        """ë©”ì¸ UI ë Œë”ë§"""
        st.title("ğŸš€ ëŒ€ê·œëª¨ ë°°ì¹˜ ë¶„ì„ ëª¨ë‹ˆí„°")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
        self._render_system_status()
        
        # ë¶„ì„ ì„¤ì •
        with st.container():
            self._render_analysis_settings()
        
        # ì‹¤í–‰ ì»¨íŠ¸ë¡¤
        self._render_controls()
        
        # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°
        if self.is_running or st.session_state.get('analysis_results'):
            self._render_progress_monitor()
        
        # ê²°ê³¼ í‘œì‹œ
        if st.session_state.get('analysis_results'):
            self._render_results()
    
    def _render_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            cpu_count = psutil.cpu_count()
            cpu_percent = psutil.cpu_percent(interval=1)
            st.metric("CPU ì½”ì–´", f"{cpu_count}ê°œ", f"ì‚¬ìš©ë¥  {cpu_percent}%")
        
        with col2:
            mem = psutil.virtual_memory()
            mem_available = mem.available / (1024**3)
            st.metric("ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬", f"{mem_available:.1f}GB", f"ì „ì²´ {mem.total/(1024**3):.1f}GB")
        
        with col3:
            # ë°ì´í„° ìƒíƒœ
            pickle_manager = get_pickle_manager()
            files = pickle_manager.list_pickle_files()
            st.metric("ìºì‹œëœ ë°ì´í„°", f"{len(files)}ê°œ", "ì¤€ë¹„ë¨" if files else "ì—†ìŒ")
        
        with col4:
            # ì˜ˆìƒ ì²˜ë¦¬ ì†ë„
            workers = min(cpu_count - 1, 12)
            expected_rate = workers * 0.8  # ì›Œì»¤ë‹¹ 0.8ê±´/ì´ˆ ì˜ˆìƒ
            st.metric("ì˜ˆìƒ ì²˜ë¦¬ ì†ë„", f"{expected_rate:.1f}ê±´/ì´ˆ", f"ì›Œì»¤ {workers}ê°œ")
    
    def _render_analysis_settings(self):
        """ë¶„ì„ ì„¤ì • UI"""
        st.subheader("ğŸ“‹ ë¶„ì„ ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ë‚ ì§œ ì„ íƒ
            analysis_date = st.date_input(
                "ë¶„ì„ ë‚ ì§œ",
                value=date.today() - timedelta(days=1),
                key="batch_analysis_date"
            )
            
            # ë‚ ì§œ ë²”ìœ„ ì˜µì…˜
            use_date_range = st.checkbox("ë‚ ì§œ ë²”ìœ„ ë¶„ì„")
            
            if use_date_range:
                date_range = st.date_input(
                    "ë‚ ì§œ ë²”ìœ„",
                    value=(date.today() - timedelta(days=7), date.today() - timedelta(days=1)),
                    key="batch_date_range"
                )
        
        with col2:
            # ì¡°ì§ ì„ íƒ
            st.selectbox(
                "ì„¼í„° ì„ íƒ",
                options=["ì „ì²´"] + self._get_centers(),
                key="batch_center"
            )
            
            st.selectbox(
                "ê·¸ë£¹ ì„ íƒ",
                options=["ì „ì²´"] + self._get_groups(),
                key="batch_group"
            )
            
            st.selectbox(
                "íŒ€ ì„ íƒ",
                options=["ì „ì²´"] + self._get_teams(),
                key="batch_team"
            )
        
        # ê³ ê¸‰ ì„¤ì •
        with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                num_workers = st.slider(
                    "ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜",
                    min_value=1,
                    max_value=psutil.cpu_count(),
                    value=min(psutil.cpu_count() - 1, 12),
                    key="batch_workers"
                )
            
            with col2:
                save_to_db = st.checkbox("DB ì €ì¥", value=True, key="batch_save_db")
                
            with col3:
                batch_size = st.number_input(
                    "ë°°ì¹˜ í¬ê¸°",
                    min_value=10,
                    max_value=1000,
                    value=100,
                    step=10,
                    key="batch_size"
                )
        
        # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚°
        self._calculate_estimated_time()
    
    def _render_controls(self):
        """ì‹¤í–‰ ì»¨íŠ¸ë¡¤"""
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", disabled=self.is_running):
                self._start_analysis()
        
        with col2:
            if st.button("â¸ï¸ ì¼ì‹œ ì •ì§€", disabled=not self.is_running):
                self._pause_analysis()
        
        with col3:
            if st.button("ğŸ›‘ ì¤‘ì§€", disabled=not self.is_running):
                self._stop_analysis()
    
    def _render_progress_monitor(self):
        """ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°"""
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©")
        
        # ì§„í–‰ë¥  í‘œì‹œ
        if 'batch_progress' in st.session_state:
            progress = st.session_state.batch_progress
            
            # ì „ì²´ ì§„í–‰ë¥ 
            progress_pct = progress.get('completed', 0) / progress.get('total', 1)
            st.progress(progress_pct)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ì „ì²´", f"{progress.get('total', 0):,}ê±´")
            
            with col2:
                st.metric("ì™„ë£Œ", f"{progress.get('completed', 0):,}ê±´", 
                         f"{progress_pct*100:.1f}%")
            
            with col3:
                st.metric("ì„±ê³µ", f"{progress.get('success', 0):,}ê±´",
                         f"{progress.get('success_rate', 0):.1f}%")
            
            with col4:
                elapsed = progress.get('elapsed_seconds', 0)
                if elapsed > 0:
                    rate = progress.get('completed', 0) / elapsed
                    remaining = (progress.get('total', 0) - progress.get('completed', 0)) / rate if rate > 0 else 0
                    st.metric("ë‚¨ì€ ì‹œê°„", f"{remaining/60:.1f}ë¶„",
                             f"ì†ë„: {rate:.1f}ê±´/ì´ˆ")
        
        # ì‹¤ì‹œê°„ ì°¨íŠ¸
        self._render_live_charts()
    
    def _render_live_charts(self):
        """ì‹¤ì‹œê°„ ì°¨íŠ¸"""
        if 'batch_metrics' not in st.session_state:
            return
        
        metrics = st.session_state.batch_metrics
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ì²˜ë¦¬ ì†ë„ ì°¨íŠ¸
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=metrics.get('timestamps', []),
                y=metrics.get('rates', []),
                mode='lines',
                name='ì²˜ë¦¬ ì†ë„',
                line=dict(color='blue', width=2)
            ))
            fig.update_layout(
                title="ì²˜ë¦¬ ì†ë„ (ê±´/ì´ˆ)",
                xaxis_title="ì‹œê°„",
                yaxis_title="ì†ë„",
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=metrics.get('timestamps', []),
                y=metrics.get('cpu_usage', []),
                mode='lines',
                name='CPU',
                line=dict(color='red', width=2)
            ))
            fig.add_trace(go.Scatter(
                x=metrics.get('timestamps', []),
                y=metrics.get('memory_usage', []),
                mode='lines',
                name='ë©”ëª¨ë¦¬',
                line=dict(color='green', width=2)
            ))
            fig.update_layout(
                title="ì‹œìŠ¤í…œ ì‚¬ìš©ë¥  (%)",
                xaxis_title="ì‹œê°„",
                yaxis_title="ì‚¬ìš©ë¥ ",
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_results(self):
        """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        st.subheader("ğŸ“ˆ ë¶„ì„ ê²°ê³¼")
        
        results = st.session_state.get('analysis_results', {})
        
        if not results:
            st.info("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ìš”ì•½ ì •ë³´
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ ë¶„ì„", f"{results.get('total_employees', 0):,}ëª…")
        
        with col2:
            st.metric("ì„±ê³µ", f"{results.get('analyzed_count', 0):,}ëª…")
        
        with col3:
            st.metric("ì‹¤íŒ¨", f"{results.get('error_count', 0):,}ëª…")
        
        with col4:
            st.metric("ì†Œìš” ì‹œê°„", f"{results.get('elapsed_seconds', 0)/60:.1f}ë¶„")
        
        # í‰ê·  ì§€í‘œ
        if 'averages' in results:
            st.write("### í‰ê·  ì§€í‘œ")
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("í‰ê·  íš¨ìœ¨ì„±", f"{results['averages']['efficiency_ratio']:.1f}%")
            
            with col2:
                st.metric("í‰ê·  ì‹¤ê·¼ë¬´ì‹œê°„", f"{results['averages']['actual_work_hours']:.1f}ì‹œê°„")
        
        # ìƒì„¸ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        if st.button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"):
            self._download_results(results)
    
    def _start_analysis(self):
        """ë¶„ì„ ì‹œì‘"""
        self.is_running = True
        
        # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        analysis_date = st.session_state.batch_analysis_date
        num_workers = st.session_state.batch_workers
        center = st.session_state.batch_center if st.session_state.batch_center != "ì „ì²´" else None
        group = st.session_state.batch_group if st.session_state.batch_group != "ì „ì²´" else None
        team = st.session_state.batch_team if st.session_state.batch_team != "ì „ì²´" else None
        save_to_db = st.session_state.batch_save_db
        
        # ë¶„ì„ê¸° ìƒì„±
        self.analyzer = ParallelBatchAnalyzer(num_workers=num_workers)
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        def run_analysis():
            try:
                # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
                st.session_state.batch_progress = {
                    'total': 0,
                    'completed': 0,
                    'success': 0,
                    'error': 0,
                    'success_rate': 0,
                    'elapsed_seconds': 0
                }
                
                # ë¶„ì„ ì‹¤í–‰
                results = self.analyzer.batch_analyze_parallel(
                    analysis_date,
                    center_id=center,
                    group_id=group,
                    team_id=team,
                    save_to_db=save_to_db
                )
                
                # ê²°ê³¼ ì €ì¥
                st.session_state.analysis_results = results
                
            finally:
                self.is_running = False
        
        self.analysis_thread = threading.Thread(target=run_analysis)
        self.analysis_thread.start()
        
        st.success("ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()
    
    def _pause_analysis(self):
        """ë¶„ì„ ì¼ì‹œ ì •ì§€"""
        # êµ¬í˜„ ì˜ˆì •
        st.info("ì¼ì‹œ ì •ì§€ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
    
    def _stop_analysis(self):
        """ë¶„ì„ ì¤‘ì§€"""
        self.is_running = False
        if self.analyzer:
            # ë¶„ì„ ì¤‘ì§€ ë¡œì§
            pass
        st.warning("ë¶„ì„ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _calculate_estimated_time(self):
        """ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚°"""
        # ì§ì› ìˆ˜ ì¶”ì •
        pickle_manager = get_pickle_manager()
        org_data = pickle_manager.load_dataframe('organization_data')
        
        if org_data is not None:
            # í•„í„°ë§ëœ ì§ì› ìˆ˜
            total_employees = len(org_data)
            
            # ì˜ˆìƒ ì²˜ë¦¬ ì†ë„ (ì›Œì»¤ë‹¹ 0.8ê±´/ì´ˆ)
            workers = st.session_state.get('batch_workers', 12)
            rate = workers * 0.8
            
            estimated_seconds = total_employees / rate
            
            st.info(f"ğŸ“Š ì˜ˆìƒ: {total_employees:,}ëª… ë¶„ì„, ì•½ {estimated_seconds/60:.1f}ë¶„ ì†Œìš”")
    
    def _get_centers(self):
        """ì„¼í„° ëª©ë¡ ì¡°íšŒ"""
        try:
            pickle_manager = get_pickle_manager()
            org_data = pickle_manager.load_dataframe('organization_data')
            if org_data is not None:
                return sorted(org_data['ì„¼í„°'].unique().tolist())
        except:
            pass
        return []
    
    def _get_groups(self):
        """ê·¸ë£¹ ëª©ë¡ ì¡°íšŒ"""
        try:
            pickle_manager = get_pickle_manager()
            org_data = pickle_manager.load_dataframe('organization_data')
            if org_data is not None:
                center = st.session_state.get('batch_center')
                if center and center != "ì „ì²´":
                    filtered = org_data[org_data['ì„¼í„°'] == center]
                    return sorted(filtered['ê·¸ë£¹'].unique().tolist())
                return sorted(org_data['ê·¸ë£¹'].unique().tolist())
        except:
            pass
        return []
    
    def _get_teams(self):
        """íŒ€ ëª©ë¡ ì¡°íšŒ"""
        try:
            pickle_manager = get_pickle_manager()
            org_data = pickle_manager.load_dataframe('organization_data')
            if org_data is not None:
                group = st.session_state.get('batch_group')
                if group and group != "ì „ì²´":
                    filtered = org_data[org_data['ê·¸ë£¹'] == group]
                    return sorted(filtered['íŒ€'].unique().tolist())
                return sorted(org_data['íŒ€'].unique().tolist())
        except:
            pass
        return []
    
    def _download_results(self, results):
        """ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
        import json
        
        # JSONìœ¼ë¡œ ë³€í™˜
        json_str = json.dumps(results, ensure_ascii=False, indent=2)
        
        st.download_button(
            label="JSON ë‹¤ìš´ë¡œë“œ",
            data=json_str,
            file_name=f"batch_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )