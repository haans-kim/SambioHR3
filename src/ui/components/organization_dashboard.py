"""
ì¡°ì§ë³„ ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import date, datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
from sqlalchemy import text

from ...database import DatabaseManager
from ...data_processing import PickleManager

class OrganizationDashboard:
    """ì¡°ì§ë³„ ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, db_manager: DatabaseManager, pickle_manager: PickleManager):
        self.db_manager = db_manager
        self.pickle_manager = pickle_manager
        self.logger = logging.getLogger(__name__)
        self._organizations_cache = {}
    
    def get_organizations_by_level(self, org_level: str) -> list:
        """ì¡°ì§ ë ˆë²¨ì— ë”°ë¥¸ ì¡°ì§ ëª©ë¡ ì¡°íšŒ"""
        try:
            # ìºì‹œ í™•ì¸
            if org_level in self._organizations_cache:
                return self._organizations_cache[org_level]
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°ì§ ëª©ë¡ ì¡°íšŒ
            from sqlalchemy import text
            
            query = text("""
            SELECT DISTINCT org_code, org_name 
            FROM organization_master 
            WHERE org_level = :org_level 
                AND is_active = 1
            ORDER BY org_name
            """)
            
            with self.db_manager.get_session() as session:
                result = session.execute(query, {"org_level": org_level})
                # ì¡°ì§ëª…ë§Œ í‘œì‹œ (ì½”ë“œëŠ” ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì‚¬ìš©)
                organizations = [(row[0], row[1]) for row in result.fetchall()]
                
            # ìºì‹œ ì €ì¥
            self._organizations_cache[org_level] = organizations
            return organizations
            
        except Exception as e:
            st.error(f"ì¡°ì§ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
            if org_level == "team":
                return ["Production_A", "Production_B", "Quality_Team", "Maintenance"]
            elif org_level == "group":
                return ["Group_A", "Group_B", "Group_C"]
            elif org_level == "center":
                return ["Center_1", "Center_2"]
            return []
    
    def get_organization_statistics(self, org_id: str, org_level: str, start_date, end_date):
        """ì¡°ì§ í†µê³„ ë°ì´í„° ì¡°íšŒ - ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ"""
        try:
            # ì¡°ì§ ì •ë³´ ì¡°íšŒ
            org_query = text("""
                SELECT org_name FROM organization_master
                WHERE org_code = :org_code
            """)
            
            with self.db_manager.get_session() as session:
                result = session.execute(org_query, {'org_code': org_id}).fetchone()
                if result:
                    org_name = result[0]
                else:
                    # org_idê°€ ì´ë¯¸ ì¡°ì§ëª…ì¼ ìˆ˜ ìˆìŒ
                    org_name = org_id
                
                # ì§ì› ìˆ˜ ì¡°íšŒ - ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ
                if org_level == 'center':
                    count_query = text("""
                        SELECT COUNT(DISTINCT employee_id) FROM employees
                        WHERE center_name = :org_name
                    """)
                elif org_level == 'group':
                    count_query = text("""
                        SELECT COUNT(DISTINCT employee_id) FROM employees
                        WHERE group_name = :org_name
                    """)
                else:  # team
                    count_query = text("""
                        SELECT COUNT(DISTINCT employee_id) FROM employees
                        WHERE team_name = :org_name
                    """)
                
                result = session.execute(count_query, {'org_name': org_name}).fetchone()
                total_employees = result[0] if result else 0
                
                # ê·¼ë¬´ ë°ì´í„° ì¡°íšŒ - daily_work_data í…Œì´ë¸”ì—ì„œ
                if org_level == 'center':
                    work_query = text("""
                        SELECT 
                            AVG(dwd.actual_work_time) as avg_work_hours,
                            COUNT(DISTINCT dwd.employee_id) as active_employees
                        FROM daily_work_data dwd
                        JOIN employees e ON dwd.employee_id = e.employee_id
                        WHERE e.center_name = :org_name
                        AND dwd.work_date BETWEEN :start_date AND :end_date
                    """)
                elif org_level == 'group':
                    work_query = text("""
                        SELECT 
                            AVG(dwd.actual_work_time) as avg_work_hours,
                            COUNT(DISTINCT dwd.employee_id) as active_employees
                        FROM daily_work_data dwd
                        JOIN employees e ON dwd.employee_id = e.employee_id
                        WHERE e.group_name = :org_name
                        AND dwd.work_date BETWEEN :start_date AND :end_date
                    """)
                else:  # team
                    work_query = text("""
                        SELECT 
                            AVG(dwd.actual_work_time) as avg_work_hours,
                            COUNT(DISTINCT dwd.employee_id) as active_employees
                        FROM daily_work_data dwd
                        JOIN employees e ON dwd.employee_id = e.employee_id
                        WHERE e.team_name = :org_name
                        AND dwd.work_date BETWEEN :start_date AND :end_date
                    """)
                
                work_result = conn.execute(work_query, {
                    'org_name': org_name,
                    'start_date': start_date.strftime('%Y-%m-%d'),
                    'end_date': end_date.strftime('%Y-%m-%d')
                }).fetchone()
                
                avg_work_hours = 0
                utilization_rate = 0
                efficiency_score = 0
                
                if work_result and work_result[0]:
                    avg_work_hours = work_result[0]
                    # ê°€ë™ë¥  ê³„ì‚° (ì‹¤ì œê·¼ë¬´ì‹œê°„ / 8ì‹œê°„ ê¸°ì¤€)
                    utilization_rate = min(100, (avg_work_hours / 8) * 100)
                    # íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°
                    efficiency_score = min(100, utilization_rate * 0.95)
                else:
                    # Pickle ë°ì´í„° í´ë°± - organization_data ì‚¬ìš©
                    org_data = self.pickle_manager.load_dataframe('organization_data')
                    if org_data is not None:
                        # ì¡°ì§ ë ˆë²¨ì— ë”°ë¥¸ í•„í„°ë§
                        if org_level == 'center' and 'ì„¼í„°' in org_data.columns:
                            filtered_data = org_data[org_data['ì„¼í„°'] == org_name]
                        elif org_level == 'team' and 'íŒ€' in org_data.columns:
                            filtered_data = org_data[org_data['íŒ€'] == org_name]
                        elif org_level == 'group' and 'ê·¸ë£¹' in org_data.columns:
                            filtered_data = org_data[org_data['ê·¸ë£¹'] == org_name]
                        else:
                            filtered_data = org_data
                        
                        # claim_dataì—ì„œ ê·¼ë¬´ í†µê³„ ê³„ì‚°
                        claim_data = self.pickle_manager.load_dataframe('claim_data')
                        if claim_data is not None and not claim_data.empty:
                            # ë‚ ì§œ í•„í„°ë§
                            if 'ê·¼ë¬´ì¼' in claim_data.columns:
                                claim_data['ê·¼ë¬´ì¼'] = pd.to_datetime(claim_data['ê·¼ë¬´ì¼'])
                                mask = (claim_data['ê·¼ë¬´ì¼'].dt.date >= start_date) & (claim_data['ê·¼ë¬´ì¼'].dt.date <= end_date)
                                period_data = claim_data[mask]
                                
                                # ì§ì› ID ë¦¬ìŠ¤íŠ¸
                                employee_ids = filtered_data['ì‚¬ë²ˆ'].tolist() if 'ì‚¬ë²ˆ' in filtered_data.columns else []
                                
                                if employee_ids and 'ì‚¬ë²ˆ' in period_data.columns:
                                    # í•´ë‹¹ ì¡°ì§ ì§ì›ë“¤ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                                    org_claim_data = period_data[period_data['ì‚¬ë²ˆ'].isin(employee_ids)]
                                    
                                    if not org_claim_data.empty and 'ì‹¤ì œê·¼ë¬´ì‹œê°„' in org_claim_data.columns:
                                        avg_work_hours = org_claim_data['ì‹¤ì œê·¼ë¬´ì‹œê°„'].mean()
                                        
                                        if 'ê¸°ì¤€ê·¼ë¬´ì‹œê°„' in org_claim_data.columns and org_claim_data['ê¸°ì¤€ê·¼ë¬´ì‹œê°„'].mean() > 0:
                                            utilization_rate = (avg_work_hours / org_claim_data['ê¸°ì¤€ê·¼ë¬´ì‹œê°„'].mean()) * 100
                                        else:
                                            utilization_rate = (avg_work_hours / 8) * 100
                                        
                                        efficiency_score = min(100, utilization_rate * 0.9)
            
            return {
                'total_employees': total_employees,
                'avg_work_hours': avg_work_hours if avg_work_hours else 0,
                'utilization_rate': utilization_rate if utilization_rate else 0,
                'efficiency_score': efficiency_score if efficiency_score else 0,
                'org_name': org_name,
                'org_level': org_level
            }
            
        except Exception as e:
            self.logger.error(f"ì¡°ì§ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
            return None
    
    def get_available_date_range(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # íƒœê¹… ë°ì´í„°ì—ì„œ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ
            tag_data = self.pickle_manager.load_dataframe(name='tag_data')
            if tag_data is not None and 'ENTE_DT' in tag_data.columns:
                # YYYYMMDD í˜•ì‹ì„ date ê°ì²´ë¡œ ë³€í™˜
                dates = pd.to_datetime(tag_data['ENTE_DT'].astype(str), format='%Y%m%d', errors='coerce')
                dates = dates.dropna()
                
                if not dates.empty:
                    min_date = dates.min().date()
                    max_date = dates.max().date()
                    self.logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„: {min_date} ~ {max_date}")
                    return (min_date, max_date)
            
            # ëŒ€ì²´ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„ (claim_data)
            claim_data = self.pickle_manager.load_dataframe(name='claim_data')
            if claim_data is not None and 'ê·¼ë¬´ì¼' in claim_data.columns:
                dates = pd.to_datetime(claim_data['ê·¼ë¬´ì¼'])
                if not dates.empty:
                    min_date = dates.min().date()
                    max_date = dates.max().date()
                    return (min_date, max_date)
            
            return None
        except Exception as e:
            self.logger.warning(f"ë‚ ì§œ ë²”ìœ„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def render(self):
        """ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        st.markdown("### ì¡°ì§ë³„ ê·¼ë¬´ ë¶„ì„")
        
        # íƒ­ ìƒì„±
        tab1, tab2, tab3 = st.tabs(["ì„¼í„°-ì§ê¸‰ë³„ ë¶„ì„", "ê¸°ì¡´ ì¡°ì§ ë¶„ì„", "ìƒì„¸ ë¶„ì„"])
        
        with tab1:
            self.render_center_grade_analysis()
        
        with tab2:
            # ê¸°ì¡´ ì¡°ì§ ì„ íƒ ë° ê¸°ê°„ ì„¤ì •
            col1, col2, col3 = st.columns(3)
            
            with col1:
                org_level = st.selectbox(
                    "ì¡°ì§ ë ˆë²¨",
                    ["team", "group", "center"],
                    format_func=lambda x: {"team": "íŒ€", "group": "ê·¸ë£¹", "center": "ì„¼í„°"}.get(x, x),
                    key="org_level_select"
                )
            
            with col2:
                # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°ì§ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                organizations = self.get_organizations_by_level(org_level)
                if organizations:
                    # ì¡°ì§ ì½”ë“œë¥¼ ì¸ë±ìŠ¤ë¡œ, ì¡°ì§ëª…ì„ í‘œì‹œ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                    org_options = {org[0]: org[1] for org in organizations}
                    org_id = st.selectbox(
                        "ì¡°ì§ ì„ íƒ",
                        options=list(org_options.keys()),
                        format_func=lambda x: org_options[x],
                        key="org_id_select"
                    )
                else:
                    org_id = st.selectbox(
                        "ì¡°ì§ ì„ íƒ",
                        ["ë°ì´í„° ì—†ìŒ"],
                        key="org_id_select"
                    )
            
            with col3:
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°
                available_dates = self.get_available_date_range()
                if available_dates:
                    min_date, max_date = available_dates
                    # ê¸°ë³¸ê°’ ì„¤ì • (ìµœê·¼ 30ì¼ ë˜ëŠ” ê°€ëŠ¥í•œ ë²”ìœ„)
                    default_start = max(min_date, max_date - timedelta(days=30))
                    default_end = max_date
                    
                    date_range = st.date_input(
                        "ë¶„ì„ ê¸°ê°„",
                        value=(default_start, default_end),
                        min_value=min_date,
                        max_value=max_date,
                        key="org_date_range"
                    )
                else:
                    st.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    date_range = st.date_input(
                        "ë¶„ì„ ê¸°ê°„",
                        value=(date.today() - timedelta(days=30), date.today()),
                        key="org_date_range"
                    )
            
            # ë¶„ì„ ì‹¤í–‰
            if st.button("ì¡°ì§ ë¶„ì„ ì‹¤í–‰", type="primary"):
                self.execute_organization_analysis(org_id, org_level, date_range)
        
        with tab3:
            st.info("ìƒì„¸ ë¶„ì„ ê¸°ëŠ¥ì€ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤.")
    
    def execute_organization_analysis(self, org_id: str, org_level: str, date_range: tuple):
        """ì¡°ì§ ë¶„ì„ ì‹¤í–‰ - ê°œì¸ë³„ ë¶„ì„ ìˆ˜í–‰ í›„ DB ì €ì¥"""
        with st.spinner("ì¡°ì§ ë¶„ì„ ì¤‘..."):
            try:
                # ë‚ ì§œ ì²˜ë¦¬
                if isinstance(date_range, tuple) and len(date_range) == 2:
                    start_date, end_date = date_range
                else:
                    # ë‹¨ì¼ ë‚ ì§œì¸ ê²½ìš°
                    start_date = end_date = date_range
                
                # ì¡°ì§ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                if org_level == 'center':
                    # org_idê°€ CENTER_003 ê°™ì€ ì½”ë“œì¸ ê²½ìš°
                    org_query = text("""
                        SELECT org_name FROM organization_master
                        WHERE org_code = :org_code
                    """)
                    with self.db_manager.get_session() as session:
                        result = session.execute(org_query, {'org_code': org_id}).fetchone()
                        org_name = result[0] if result else org_id
                else:
                    org_name = org_id  # ì´ë¯¸ ì¡°ì§ëª…ì¼ ìˆ˜ ìˆìŒ
                
                # ì¡°ì§ì— ì†í•œ ì§ì›ë“¤ ê°€ì ¸ì˜¤ê¸°
                employees = self._get_organization_employees(org_name, org_level)
                
                self.logger.info(f"ì¡°ì§ {org_name}({org_level})ì—ì„œ ì§ì› {len(employees) if employees else 0}ëª… ë°œê²¬")
                if employees:
                    self.logger.info(f"ì§ì› ëª©ë¡ (ì²˜ìŒ 5ëª…): {employees[:5]}")
                
                if not employees:
                    st.warning(f"{org_name}ì— ì†í•œ ì§ì›ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                st.info(f"{org_name} ì†Œì† {len(employees)}ëª…ì˜ ì§ì› ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                
                # ì„ íƒí•œ ì§ì› ëª©ë¡ í‘œì‹œ
                st.markdown("### ğŸ“‹ ë¶„ì„ ëŒ€ìƒ ì§ì› ëª©ë¡")
                employees_df = pd.DataFrame({
                    'ìˆœë²ˆ': range(1, len(employees) + 1),
                    'ì‚¬ë²ˆ': employees,
                    'ìƒíƒœ': ['ëŒ€ê¸°ì¤‘'] * len(employees)
                })
                employees_table = st.empty()
                employees_table.dataframe(employees_df, use_container_width=True)
                
                # Progress bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
                st.markdown("### ğŸ“Š ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼")
                results_table = st.empty()
                current_results = []
                
                # ê°œì¸ë³„ ë¶„ì„ê¸° ì´ˆê¸°í™”
                import sys
                from pathlib import Path
                # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
                project_root = Path(__file__).parent.parent.parent.parent
                if str(project_root) not in sys.path:
                    sys.path.append(str(project_root))
                
                from src.analysis.individual_analyzer import IndividualAnalyzer
                from src.data_processing import PickleManager
                from src.database import DatabaseManager
                from datetime import datetime
                
                # ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹±ê¸€í†¤ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                db_mgr = DatabaseManager()
                pickle_mgr = PickleManager(base_path="data/pickles")  # ëª…ì‹œì  ê²½ë¡œ ì§€ì •
                individual_analyzer = IndividualAnalyzer(db_mgr, None)
                individual_analyzer.pickle_manager = pickle_mgr
                
                # ê° ì§ì›ë³„ë¡œ ë¶„ì„ ìˆ˜í–‰
                analyzed_count = 0
                failed_count = 0
                total_work_hours = 0
                total_actual_work_time = 0
                total_days = 0  # ì´ ë¶„ì„ ì¼ìˆ˜
                employee_results = []  # ê°œì¸ë³„ ë¶„ì„ ê²°ê³¼ ì €ì¥
                
                for idx, employee_id in enumerate(employees):
                    try:
                        # Progress ì—…ë°ì´íŠ¸
                        progress = (idx + 1) / len(employees)
                        progress_bar.progress(progress)
                        status_text.text(f"ë¶„ì„ ì¤‘... ({idx + 1}/{len(employees)}) - {employee_id}")
                        
                        # ì§ì› ìƒíƒœ ì—…ë°ì´íŠ¸ (ë¶„ì„ ì¤‘)
                        employees_df.loc[idx, 'ìƒíƒœ'] = 'ë¶„ì„ì¤‘'
                        employees_table.dataframe(employees_df, use_container_width=True)
                        
                        # ê°œì¸ë³„ ë¶„ì„ ìˆ˜í–‰ - ì„ì‹œë¡œ ê°„ë‹¨í•œ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
                        # start_dateì™€ end_dateê°€ tupleì¸ ê²½ìš° ì²˜ë¦¬
                        if isinstance(start_date, tuple):
                            start_dt = start_date[0] if len(start_date) > 0 else date.today()
                        else:
                            start_dt = start_date
                            
                        if isinstance(end_date, tuple):
                            end_dt = end_date[-1] if len(end_date) > 0 else date.today()
                        else:
                            end_dt = end_date
                        
                        # ê°œì¸ë³„ ë¶„ì„ ìˆ˜í–‰ - individual_dashboardì™€ ë™ì¼í•œ ë°©ì‹ ì‚¬ìš©
                        analysis_results = self._analyze_employee(
                            employee_id,
                            start_dt,
                            end_dt
                        )
                        
                        if analysis_results and len(analysis_results) > 0:
                            analyzed_count += 1
                            
                            # ë¶„ì„ ê²°ê³¼ ì €ì¥
                            self._save_employee_analysis(analysis_results)
                            
                            # ì§ì› ìƒíƒœ ì—…ë°ì´íŠ¸ (ì™„ë£Œ)
                            employees_df.loc[idx, 'ìƒíƒœ'] = f'ì™„ë£Œ ({len(analysis_results)}ê±´)'
                            employees_table.dataframe(employees_df, use_container_width=True)
                            
                            # ì „ì²´ í†µê³„ ê³„ì‚°ìš© ë°ì´í„° ìˆ˜ì§‘
                            for result in analysis_results:
                                work_hours = result.get('attendance_hours', 0)
                                actual_hours = result.get('actual_work_hours', 0)
                                
                                # ë””ë²„ê¹… ë¡œê·¸
                                if idx < 5:  # ì²˜ìŒ 5ëª…ë§Œ ë¡œê·¸
                                    self.logger.info(f"ì§ì› {employee_id}: ê·¼íƒœ={work_hours:.1f}h, ì‹¤ì œ={actual_hours:.1f}h")
                                
                                total_work_hours += work_hours
                                total_actual_work_time += actual_hours
                                total_days += 1
                                
                                # ê°œì¸ë³„ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•˜ê³  ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
                                new_result = {
                                    'ì‚¬ë²ˆ': employee_id,
                                    'ë‚ ì§œ': result.get('analysis_date', ''),
                                    'ê·¼íƒœê¸°ë¡ì‹œê°„': f"{work_hours:.1f}h",
                                    'ì‹¤ì œì‘ì—…ì‹œê°„': f"{actual_hours:.1f}h",
                                    'ì‘ì—…ì‹œê°„ì¶”ì •ë¥ ': f"{result.get('work_estimation_rate', 0):.1f}%",
                                    'íšŒì˜ì‹œê°„': f"{result.get('meeting_time', 0):.1f}h",
                                    'ì‹ì‚¬ì‹œê°„': f"{result.get('meal_time', 0):.1f}h",
                                    'ì´ë™ì‹œê°„': f"{result.get('movement_time', 0):.1f}h",
                                    'íœ´ì‹ì‹œê°„': f"{result.get('rest_time', 0):.1f}h",
                                    'ë°ì´í„°ì‹ ë¢°ë„': f"{result.get('data_reliability', 0):.1f}ì "
                                }
                                employee_results.append(new_result)
                                current_results.append(new_result)
                                
                                # ì‹¤ì‹œê°„ ê²°ê³¼ í…Œì´ë¸” ì—…ë°ì´íŠ¸
                                if current_results:
                                    results_df = pd.DataFrame(current_results)
                                    results_table.dataframe(results_df, use_container_width=True)
                        else:
                            # ë¶„ì„ ì‹¤íŒ¨
                            employees_df.loc[idx, 'ìƒíƒœ'] = 'ì‹¤íŒ¨ (ë°ì´í„° ì—†ìŒ)'
                            employees_table.dataframe(employees_df, use_container_width=True)
                    
                    except Exception as e:
                        failed_count += 1
                        # ë¶„ì„ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
                        employees_df.loc[idx, 'ìƒíƒœ'] = f'ì˜¤ë¥˜: {str(e)[:30]}...'
                        employees_table.dataframe(employees_df, use_container_width=True)
                        
                        self.logger.warning(f"ì§ì› {employee_id} ë¶„ì„ ì‹¤íŒ¨: {e}")
                        st.error(f"ì§ì› {employee_id} ë¶„ì„ ì‹¤íŒ¨: {e}")
                        import traceback
                        self.logger.error(traceback.format_exc())
                        continue
                
                # Progress ì™„ë£Œ
                progress_bar.progress(1.0)
                status_text.text("")
                
                # ë¶„ì„ ê²°ê³¼ ìš”ì•½
                if analyzed_count > 0 and total_days > 0:
                    # ì¼ í‰ê· ìœ¼ë¡œ ê³„ì‚°
                    avg_work_hours = total_work_hours / total_days
                    avg_actual_work = total_actual_work_time / total_days
                    
                    # íš¨ìœ¨ì„± ê³„ì‚°
                    if avg_work_hours > 0:
                        utilization_rate = (avg_actual_work / avg_work_hours * 100)
                    else:
                        # ê·¼íƒœ ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì‹¤ì œ ì‘ì—…ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
                        utilization_rate = (avg_actual_work / 8) * 100  # 8ì‹œê°„ ê¸°ì¤€
                    
                    efficiency_score = min(100, utilization_rate * 0.95)
                    
                    self.logger.info(f"ë¶„ì„ ì™„ë£Œ: ì§ì› {analyzed_count}ëª…, ì´ {total_days}ì¼")
                    self.logger.info(f"í‰ê·  ê·¼íƒœ: {avg_work_hours:.1f}h, í‰ê·  ì‹¤ì œ: {avg_actual_work:.1f}h")
                    self.logger.info(f"ê°€ë™ë¥ : {utilization_rate:.1f}%, íš¨ìœ¨ì„±: {efficiency_score:.1f}ì ")
                    
                    # ì¡°ì§ ë¶„ì„ ê²°ê³¼ DB ì €ì¥
                    self._save_organization_analysis_result(
                        org_id, org_name, org_level, start_date, end_date,
                        analyzed_count, avg_work_hours, utilization_rate, efficiency_score
                    )
                    
                    st.success(f"ë¶„ì„ ì™„ë£Œ! ì„±ê³µ: {analyzed_count}ëª…, ì‹¤íŒ¨: {failed_count}ëª…")
                    
                    # ì¡°ì§ KPI í‘œì‹œ
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("ë¶„ì„ ì¸ì›", f"{analyzed_count}ëª…")
                    
                    with col2:
                        if pd.isna(avg_work_hours) or avg_work_hours == 0:
                            st.metric("í‰ê·  ê·¼ë¬´ì‹œê°„", "ë°ì´í„° ì—†ìŒ")
                        else:
                            st.metric("í‰ê·  ê·¼ë¬´ì‹œê°„", f"{avg_work_hours:.1f}ì‹œê°„")
                    
                    with col3:
                        if pd.isna(utilization_rate):
                            st.metric("ê°€ë™ë¥ ", "ê³„ì‚° ë¶ˆê°€")
                        else:
                            st.metric("ê°€ë™ë¥ ", f"{utilization_rate:.1f}%")
                    
                    with col4:
                        if pd.isna(efficiency_score):
                            st.metric("íš¨ìœ¨ì„± ì ìˆ˜", "ê³„ì‚° ë¶ˆê°€")
                        else:
                            st.metric("íš¨ìœ¨ì„± ì ìˆ˜", f"{efficiency_score:.1f}ì ")
                    
                    # ìµœì¢… ë¶„ì„ ê²°ê³¼ ìš”ì•½
                    if employee_results:
                        st.markdown("### ğŸ“Š ìµœì¢… ë¶„ì„ ê²°ê³¼ ìš”ì•½")
                        st.markdown("*DBì— ì €ì¥ëœ ë°ì´í„°*")
                        
                        # DataFrameìœ¼ë¡œ ë³€í™˜
                        final_results_df = pd.DataFrame(employee_results)
                        
                        # ìµœì¢… í…Œì´ë¸” í‘œì‹œ (ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
                        st.dataframe(
                            final_results_df,
                            use_container_width=True,
                            height=400  # ë†’ì´ ì œí•œìœ¼ë¡œ ìŠ¤í¬ë¡¤ ê°€ëŠ¥
                        )
                        
                        # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        csv = final_results_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="ğŸ“¥ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                            data=csv,
                            file_name=f"{org_name}_ë¶„ì„ê²°ê³¼_{start_date}_{end_date}.csv",
                            mime="text/csv"
                        )
                    
                else:
                    st.error("ë¶„ì„ì— ì„±ê³µí•œ ì§ì›ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                self.logger.error(f"ì¡°ì§ ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
    
    def render_organization_charts(self):
        """ì¡°ì§ ì°¨íŠ¸ ë Œë”ë§ (ìƒ˜í”Œ ë°ì´í„°)"""
        st.markdown("""
        <div style="background: #f8f9fa; 
                    border-left: 3px solid #2E86AB; 
                    padding: 0.8rem 1.2rem; 
                    border-radius: 0 6px 6px 0; 
                    margin: 1rem 0 0.5rem 0;">
            <h4 style="margin: 0; color: #2E86AB; font-weight: 600; font-size: 1.1rem;">
                Organization Performance Analysis
            </h4>
            <p style="margin: 0.3rem 0 0 0; color: #6c757d; font-size: 0.9rem;">
                ì¡°ì§ ì„±ê³¼ ë¶„ì„
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # ìƒ˜í”Œ ë°ì´í„°
        employees = [f"ì§ì›{i+1}" for i in range(10)]
        productivity = np.random.uniform(70, 95, 10)
        
        # ê°œì¸ë³„ ìƒì‚°ì„± ì°¨íŠ¸
        fig = px.bar(x=employees, y=productivity, title="ê°œì¸ë³„ ìƒì‚°ì„± ì ìˆ˜")
        st.plotly_chart(fig, use_container_width=True)
        
        # êµëŒ€ë³„ ë¶„ì„
        shifts = ['ì£¼ê°„', 'ì•¼ê°„']
        shift_productivity = [85.3, 82.1]
        
        fig2 = px.bar(x=shifts, y=shift_productivity, title="êµëŒ€ë³„ í‰ê·  ìƒì‚°ì„±")
        st.plotly_chart(fig2, use_container_width=True)
    
    def _get_organization_name(self, org_id: str) -> str:
        """ì¡°ì§ IDë¡œ ì¡°ì§ëª… ê°€ì ¸ì˜¤ê¸°"""
        try:
            org_query = text("""
                SELECT org_name FROM organization_master
                WHERE org_code = :org_code
            """)
            
            with self.db_manager.get_session() as session:
                result = session.execute(org_query, {'org_code': org_id}).fetchone()
                if result:
                    return result[0]
                else:
                    # org_idê°€ ì´ë¯¸ ì¡°ì§ëª…ì¼ ìˆ˜ ìˆìŒ
                    return org_id
        except Exception as e:
            self.logger.error(f"ì¡°ì§ëª… ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return org_id
    
    def _get_organization_employees(self, org_name: str, org_level: str) -> List[str]:
        """ì¡°ì§ì— ì†í•œ ì§ì› ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            self.logger.info(f"ì¡°ì§ ì§ì› ì¡°íšŒ: {org_name} ({org_level})")
            
            # pickle ë°ì´í„°ì—ì„œ ì¡°ì§ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            org_df = self.pickle_manager.load_dataframe('organization_data')
            if org_df is None or org_df.empty:
                self.logger.warning("organization_dataë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. organization ì‹œë„")
                org_df = self.pickle_manager.load_dataframe('organization')
                if org_df is None or org_df.empty:
                    self.logger.warning("organizationë„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return []
            
            self.logger.info(f"ì¡°ì§ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(org_df)}í–‰, ì»¬ëŸ¼: {list(org_df.columns)}")
            
            # ì¡°ì§ ë ˆë²¨ì— ë”°ë¥¸ í•„í„°ë§
            if org_level == 'center':
                if 'ì„¼í„°' in org_df.columns:
                    filtered = org_df[org_df['ì„¼í„°'] == org_name]
                    self.logger.info(f"'ì„¼í„°' ì»¬ëŸ¼ìœ¼ë¡œ í•„í„°ë§: {len(filtered)}ëª…")
                elif 'center' in org_df.columns:
                    filtered = org_df[org_df['center'] == org_name]
                    self.logger.info(f"'center' ì»¬ëŸ¼ìœ¼ë¡œ í•„í„°ë§: {len(filtered)}ëª…")
                else:
                    self.logger.warning("ì„¼í„° ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return []
            elif org_level == 'group':
                if 'ê·¸ë£¹' in org_df.columns:
                    filtered = org_df[org_df['ê·¸ë£¹'] == org_name]
                elif 'group_name' in org_df.columns:
                    filtered = org_df[org_df['group_name'] == org_name]
                else:
                    self.logger.warning("ê·¸ë£¹ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return []
            else:  # team
                if 'íŒ€' in org_df.columns:
                    filtered = org_df[org_df['íŒ€'] == org_name]
                elif 'team' in org_df.columns:
                    filtered = org_df[org_df['team'] == org_name]
                else:
                    self.logger.warning("íŒ€ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return []
            
            # ì§ì› ID ì¶”ì¶œ
            employee_list = []
            if 'ì‚¬ë²ˆ' in filtered.columns:
                employee_list = filtered['ì‚¬ë²ˆ'].dropna().unique().tolist()
            elif 'employee_no' in filtered.columns:
                employee_list = filtered['employee_no'].dropna().unique().tolist()
            elif 'employee_id' in filtered.columns:
                employee_list = filtered['employee_id'].dropna().unique().tolist()
            
            # ë¬¸ìì—´ë¡œ ë³€í™˜
            employee_list = [str(emp_id) for emp_id in employee_list]
            
            self.logger.info(f"ì¡°íšŒëœ ì§ì› ìˆ˜: {len(employee_list)}")
            if len(employee_list) > 0:
                self.logger.info(f"ì²« 5ëª…: {employee_list[:5]}")
            
            return employee_list
                
        except Exception as e:
            self.logger.error(f"ì§ì› ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return []
    
    def _save_organization_analysis_result(self, org_id: str, org_name: str, org_level: str,
                                          start_date, end_date, employee_count: int,
                                          avg_work_hours: float, utilization_rate: float,
                                          efficiency_score: float):
        """ì¡°ì§ ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥"""
        try:
            # organization_daily_stats í…Œì´ë¸”ì— ì €ì¥
            insert_query = text("""
                INSERT OR REPLACE INTO organization_daily_stats 
                (org_code, work_date, total_employees, avg_actual_work_hours, 
                 avg_work_efficiency, created_at, updated_at)
                VALUES (:org_code, :work_date, :total_employees, :avg_actual_work_hours,
                        :avg_work_efficiency, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """)
            
            with self.db_manager.get_session() as session:
                # ê¸°ê°„ì˜ ê° ë‚ ì§œë³„ë¡œ ì €ì¥
                current_date = start_date
                while current_date <= end_date:
                    session.execute(insert_query, {
                        'org_code': org_id,
                        'work_date': current_date.strftime('%Y-%m-%d'),
                        'total_employees': employee_count,
                        'avg_actual_work_hours': avg_work_hours,
                        'avg_work_efficiency': efficiency_score
                    })
                    current_date += timedelta(days=1)
                session.commit()
                
            self.logger.info(f"ì¡°ì§ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {org_name}")
            
        except Exception as e:
            self.logger.error(f"ì¡°ì§ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def render_organization_charts_with_data(self, org_stats: dict):
        """ì‹¤ì œ ë°ì´í„°ë¡œ ì¡°ì§ ì°¨íŠ¸ ë Œë”ë§"""
        st.markdown("""
        <div style="background: #f8f9fa; 
                    border-left: 3px solid #2E86AB; 
                    padding: 0.8rem 1.2rem; 
                    border-radius: 0 6px 6px 0; 
                    margin: 1rem 0 0.5rem 0;">
            <h4 style="margin: 0; color: #2E86AB; font-weight: 600; font-size: 1.1rem;">
                Organization Performance Analysis
            </h4>
            <p style="margin: 0.3rem 0 0 0; color: #6c757d; font-size: 0.9rem;">
                ì¡°ì§ ì„±ê³¼ ë¶„ì„
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        filtered_data = org_stats.get('filtered_data')
        
        if filtered_data is not None and not filtered_data.empty:
            # ì§ê¸‰ë³„ ì¸ì› ë¶„í¬
            if 'ì§ê¸‰ëª…' in filtered_data.columns:
                grade_counts = filtered_data['ì§ê¸‰ëª…'].value_counts().head(10)
                fig1 = px.bar(x=grade_counts.index, y=grade_counts.values, 
                             title=f"{org_stats['org_name']} ì§ê¸‰ë³„ ì¸ì› ë¶„í¬",
                             labels={'x': 'ì§ê¸‰', 'y': 'ì¸ì›ìˆ˜'})
                st.plotly_chart(fig1, use_container_width=True)
            
            # ì„±ë³„ ë¶„í¬
            if 'ì„±ë³„' in filtered_data.columns:
                gender_counts = filtered_data['ì„±ë³„'].value_counts()
                fig2 = px.pie(values=gender_counts.values, names=gender_counts.index,
                             title=f"{org_stats['org_name']} ì„±ë³„ ë¶„í¬")
                st.plotly_chart(fig2, use_container_width=True)
            
            # ì…ì‚¬ì—°ë„ë³„ ë¶„í¬
            if 'ì…ì‚¬ë…„ë„' in filtered_data.columns:
                year_counts = filtered_data['ì…ì‚¬ë…„ë„'].value_counts().sort_index().tail(10)
                fig3 = px.bar(x=year_counts.index, y=year_counts.values,
                             title=f"{org_stats['org_name']} ìµœê·¼ 10ë…„ ì…ì‚¬ í˜„í™©",
                             labels={'x': 'ì…ì‚¬ë…„ë„', 'y': 'ì¸ì›ìˆ˜'})
                st.plotly_chart(fig3, use_container_width=True)
        else:
            # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ì°¨íŠ¸ í‘œì‹œ
            self.render_organization_charts()
    
    def render_center_grade_analysis(self):
        """ì„¼í„°-ì§ê¸‰ë³„ ê·¼ë¬´ì‹œê°„ ë¶„ì„"""
        st.markdown("""
        <div style="background: #f8f9fa; 
                    border-left: 3px solid #2E86AB; 
                    padding: 0.8rem 1.2rem; 
                    border-radius: 0 6px 6px 0; 
                    margin: 1rem 0 0.5rem 0;">
            <h4 style="margin: 0; color: #2E86AB; font-weight: 600; font-size: 1.1rem;">
                Center-Grade Weekly Analysis
            </h4>
            <p style="margin: 0.3rem 0 0 0; color: #6c757d; font-size: 0.9rem;">
                ì„¼í„°-ì§ê¸‰ë³„ ì£¼ê°„ ê·¼ë¬´ì‹œê°„ ë¹„êµ
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # ì›” ì„ íƒ - ë°ì´í„°ë² ì´ìŠ¤ì˜ ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜
        col1, col2 = st.columns([2, 6])
        with col1:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°
            available_dates = self.get_available_date_range()
            
            if available_dates:
                min_date, max_date = available_dates
                min_year = min_date.year
                max_year = max_date.year
                current_year = date.today().year if min_year <= date.today().year <= max_year else max_year
                current_month = date.today().month if current_year == date.today().year else max_date.month
            else:
                # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’
                current_year = date.today().year
                current_month = date.today().month
                min_year = 2024
                max_year = current_year
            
            # ì—°ë„ ì„ íƒ
            year = st.selectbox(
                "ì—°ë„",
                options=list(range(min_year, max_year + 1)),
                index=list(range(min_year, max_year + 1)).index(current_year) if current_year in range(min_year, max_year + 1) else 0,
                key="year_select"
            )
            
            # ì›” ì„ íƒ - ì„ íƒëœ ì—°ë„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì›”ë§Œ í‘œì‹œ
            if available_dates:
                if year == min_year and year == max_year:
                    # ê°™ì€ ì—°ë„ì¸ ê²½ìš°
                    available_months = list(range(min_date.month, max_date.month + 1))
                elif year == min_year:
                    # ìµœì†Œ ì—°ë„ì¸ ê²½ìš°
                    available_months = list(range(min_date.month, 13))
                elif year == max_year:
                    # ìµœëŒ€ ì—°ë„ì¸ ê²½ìš°
                    available_months = list(range(1, max_date.month + 1))
                else:
                    # ì¤‘ê°„ ì—°ë„ì¸ ê²½ìš°
                    available_months = list(range(1, 13))
                
                # í˜„ì¬ ì›”ì´ ì‚¬ìš© ê°€ëŠ¥í•œ ì›”ì— ìˆëŠ”ì§€ í™•ì¸
                if current_month in available_months:
                    default_month_index = available_months.index(current_month)
                else:
                    default_month_index = len(available_months) - 1  # ê°€ì¥ ìµœê·¼ ì›”
            else:
                available_months = list(range(1, 13))
                default_month_index = current_month - 1
            
            month = st.selectbox(
                "ì›”",
                options=available_months,
                format_func=lambda x: f"{x}ì›”",
                index=default_month_index,
                key="month_select"
            )
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ë¶„ì„ ì‹¤í–‰", type="primary", key="analyze_center_grade"):
            self.analyze_center_grade_data(year, month)
    
    def analyze_center_grade_data(self, year: int, month: int):
        """ì„¼í„°-ì§ê¸‰ë³„ ë°ì´í„° ë¶„ì„"""
        with st.spinner("Claim ë°ì´í„° ë¶„ì„ ì¤‘..."):
            try:
                # Claim ë°ì´í„° ë¡œë“œ
                claim_df = self.pickle_manager.load_dataframe('claim_data')
                
                if claim_df is None:
                    st.error("Claim ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    return
                
                # ì„ íƒí•œ ì›”ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                claim_df['ê·¼ë¬´ì¼'] = pd.to_datetime(claim_df['ê·¼ë¬´ì¼'])
                month_data = claim_df[(claim_df['ê·¼ë¬´ì¼'].dt.year == year) & 
                                     (claim_df['ê·¼ë¬´ì¼'].dt.month == month)].copy()
                
                if month_data.empty:
                    st.warning(f"{year}ë…„ {month}ì›” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                # ì¡°ì§í˜„í™© ë°ì´í„° ë¡œë“œí•˜ì—¬ ì„¼í„° ì •ë³´ ë§¤í•‘
                org_df = self.pickle_manager.load_dataframe('organization_data')
                if org_df is None:
                    # organization_dataë¡œ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ organizationìœ¼ë¡œ ì‹œë„
                    org_df = self.pickle_manager.load_dataframe('organization')
                
                if org_df is not None and 'ë¶€ì„œëª…' in org_df.columns and 'ì„¼í„°' in org_df.columns:
                    # ë¶€ì„œë³„ ì„¼í„° ë§¤í•‘ ìƒì„±
                    dept_center_map = org_df.drop_duplicates(subset=['ë¶€ì„œëª…'])[['ë¶€ì„œëª…', 'ì„¼í„°']].set_index('ë¶€ì„œëª…')['ì„¼í„°'].to_dict()
                    
                    # ì„¼í„° ì •ë³´ ë§¤í•‘
                    month_data['ì„¼í„°'] = month_data['ë¶€ì„œ'].map(dept_center_map).fillna('Unknown')
                    
                    # ì„¼í„° ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    valid_centers = sorted(org_df['ì„¼í„°'].dropna().unique().tolist())
                else:
                    st.error("ì¡°ì§í˜„í™© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    return
                
                # ë°ì´í„° í™•ì¸ì„ ìœ„í•œ ë¡œê·¸
                with st.expander("ë°ì´í„° í™•ì¸"):
                    st.write(f"ì´ ë°ì´í„° í–‰ ìˆ˜: {len(month_data)}")
                    unique_centers = month_data['ì„¼í„°'].unique()
                    st.write(f"ì„¼í„° ê°œìˆ˜: {len(unique_centers)}")
                    st.write(f"ì„¼í„° ëª©ë¡: {sorted(unique_centers)}")
                    
                    # ì„¼í„°ë³„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                    center_counts = month_data['ì„¼í„°'].value_counts()
                    st.write("ì„¼í„°ë³„ ë°ì´í„° ìˆ˜:")
                    st.dataframe(center_counts.head(20))
                    
                    st.write(f"ì‹¤ì œê·¼ë¬´ì‹œê°„ í†µê³„:")
                    st.write(month_data['ì‹¤ì œê·¼ë¬´ì‹œê°„'].describe())
                
                # ì§ê¸‰ ê·¸ë£¹í™” (Lv.1~4ë¡œ ê·¸ë£¹í•‘)
                def grade_to_level(grade):
                    if pd.isna(grade):
                        return 'Unknown'
                    grade_str = str(grade)
                    if 'E1' in grade_str or 'O1' in grade_str or 'S1' in grade_str or 'G1' in grade_str:
                        return 'Lv. 1'
                    elif 'E2' in grade_str or 'O2' in grade_str or 'S2' in grade_str or 'G2' in grade_str:
                        return 'Lv. 2'
                    elif 'E3' in grade_str or 'O3' in grade_str or 'S3' in grade_str or 'G3' in grade_str:
                        return 'Lv. 3'
                    elif 'E4' in grade_str or 'O4' in grade_str or 'S4' in grade_str or 'G4' in grade_str:
                        return 'Lv. 4'
                    else:
                        return 'Unknown'
                
                month_data['ì§ê¸‰ë ˆë²¨'] = month_data['ì§ê¸‰'].apply(grade_to_level)
                
                # ì£¼ì°¨ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‰ê·  ê·¼ë¬´ì‹œê°„ ê³„ì‚°
                month_data['ì£¼ì°¨'] = month_data['ê·¼ë¬´ì¼'].dt.isocalendar().week
                
                # ì„¼í„°ë³„, ì§ê¸‰ë³„, ì£¼ì°¨ë³„ í‰ê·  ê·¼ë¬´ì‹œê°„ ê³„ì‚°
                # ë¨¼ì € ì§ì›ë³„, ì£¼ì°¨ë³„ë¡œ í•©ê³„ë¥¼ êµ¬í•œ í›„ í‰ê· ì„ ê³„ì‚°
                employee_weekly = month_data.groupby(['ì‚¬ë²ˆ', 'ì„¼í„°', 'ì§ê¸‰ë ˆë²¨', 'ì£¼ì°¨'])['ì‹¤ì œê·¼ë¬´ì‹œê°„'].sum().reset_index()
                weekly_avg = employee_weekly.groupby(['ì„¼í„°', 'ì§ê¸‰ë ˆë²¨', 'ì£¼ì°¨'])['ì‹¤ì œê·¼ë¬´ì‹œê°„'].mean().reset_index()
                
                # í”¼ë²— í…Œì´ë¸” ìƒì„±
                pivot_tables = {}
                for level in ['Lv. 1', 'Lv. 2', 'Lv. 3', 'Lv. 4']:
                    level_data = weekly_avg[weekly_avg['ì§ê¸‰ë ˆë²¨'] == level]
                    if not level_data.empty:
                        pivot = level_data.pivot(index='ì£¼ì°¨', columns='ì„¼í„°', values='ì‹¤ì œê·¼ë¬´ì‹œê°„')
                        pivot_tables[level] = pivot
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("ë¶„ì„ ì™„ë£Œ!")
                
                # ì „ì²´ í‰ê·  í‘œì‹œ - ì§ì›ë³„ë¡œ ì›” í•©ê³„ë¥¼ êµ¬í•œ í›„ í‰ê·  ê³„ì‚°
                employee_monthly = month_data.groupby(['ì‚¬ë²ˆ', 'ì„¼í„°', 'ì§ê¸‰ë ˆë²¨'])['ì‹¤ì œê·¼ë¬´ì‹œê°„'].sum().reset_index()
                total_avg = employee_monthly.groupby(['ì„¼í„°', 'ì§ê¸‰ë ˆë²¨'])['ì‹¤ì œê·¼ë¬´ì‹œê°„'].mean().reset_index()
                total_pivot = total_avg.pivot(index='ì§ê¸‰ë ˆë²¨', columns='ì„¼í„°', values='ì‹¤ì œê·¼ë¬´ì‹œê°„')
                
                st.markdown("""
                <div style="background: #f8f9fa; 
                            border-left: 3px solid #28a745; 
                            padding: 0.8rem 1.2rem; 
                            border-radius: 0 6px 6px 0; 
                            margin: 1rem 0 0.5rem 0;">
                    <h4 style="margin: 0; color: #28a745; font-weight: 600; font-size: 1.1rem;">
                        {}ë…„ {}ì›” ì„¼í„°-ì§ê¸‰ë³„ í‰ê·  ê·¼ë¬´ì‹œê°„
                    </h4>
                </div>
                """.format(year, month), unsafe_allow_html=True)
                st.markdown(f"**ìµœì†Œ: {month_data['ì‹¤ì œê·¼ë¬´ì‹œê°„'].min():.2f}h | ìµœëŒ€: {month_data['ì‹¤ì œê·¼ë¬´ì‹œê°„'].max():.2f}h**")
                
                # í‰ê·  í–‰ê³¼ ì—´ ì¶”ê°€
                # ì—´ í‰ê·  (ì„¼í„° í‰ê· ) ê³„ì‚°
                center_avg = total_pivot.mean(axis=0)
                total_pivot.loc['ì„¼í„° í‰ê· '] = center_avg
                
                # í–‰ í‰ê·  (ì „ì²´ í‰ê· ) ê³„ì‚°
                total_pivot['ì „ì²´ í‰ê· '] = total_pivot.mean(axis=1)
                
                # ìŠ¤íƒ€ì¼ë§ëœ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ - 256 ë ˆë²¨ ê·¸ë¼ë°ì´ì…˜
                def color_cells(val):
                    """ìƒ‰ìƒ ì§€ì • í•¨ìˆ˜ - ë” ì„¸ë°€í•œ ê·¸ë¼ë°ì´ì…˜"""
                    if pd.isna(val):
                        return ''
                    
                    # ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” (35-50 ì‹œê°„ ë²”ìœ„)
                    min_val, max_val = 35, 50
                    normalized = (val - min_val) / (max_val - min_val)
                    normalized = max(0, min(1, normalized))  # 0-1 ë²”ìœ„ë¡œ ì œí•œ
                    
                    # 256 ë ˆë²¨ ìƒ‰ìƒ ê³„ì‚°
                    if val >= 47:  # ë§¤ìš° ë†’ì€ ê°’ - ì§„í•œ ë¹¨ê°„ìƒ‰
                        r = 255
                        g = int(107 - normalized * 60)
                        b = int(107 - normalized * 60)
                        return f'background-color: rgb({r}, {g}, {b}); color: white; font-weight: bold'
                    elif val >= 44:  # ë†’ì€ ê°’ - ë¹¨ê°„ìƒ‰ ê³„ì—´
                        intensity = (val - 44) / 3 * 255
                        r = 255
                        g = int(160 - intensity * 0.3)
                        b = int(160 - intensity * 0.3)
                        return f'background-color: rgb({r}, {g}, {b})'
                    elif val >= 40:  # ì¤‘ê°„ ê°’ - ì—°í•œ ë¹¨ê°„ìƒ‰
                        intensity = (val - 40) / 4 * 100
                        r = 255
                        g = int(200 - intensity * 0.4)
                        b = int(200 - intensity * 0.4)
                        return f'background-color: rgb({r}, {g}, {b})'
                    elif val >= 37:  # ì •ìƒ ë²”ìœ„ - ì—°í•œ ìƒ‰
                        gray = int(245 - (val - 37) * 10)
                        return f'background-color: rgb({gray}, {gray}, {gray})'
                    else:  # ë‚®ì€ ê°’ - íšŒìƒ‰
                        gray = int(230 + (37 - val) * 3)
                        gray = min(245, gray)
                        return f'background-color: rgb({gray}, {gray}, {gray})'
                
                styled_df = total_pivot.style.format("{:.1f}").applymap(color_cells)
                st.dataframe(styled_df, use_container_width=True)
                
                # ì£¼ì°¨ë³„ ìƒì„¸ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ í†µí•© í…Œì´ë¸”ë¡œ í‘œì‹œ
                st.markdown("""
                <div style="background: #f8f9fa; 
                            border-left: 3px solid #6f42c1; 
                            padding: 0.8rem 1.2rem; 
                            border-radius: 0 6px 6px 0; 
                            margin: 1rem 0 0.5rem 0;">
                    <h4 style="margin: 0; color: #6f42c1; font-weight: 600; font-size: 1.1rem;">
                        Weekly Working Hours Comparison
                    </h4>
                    <p style="margin: 0.3rem 0 0 0; color: #6c757d; font-size: 0.9rem;">
                        ì„¼í„°-ì›”ë³„ ì£¼ê°„ ê·¼ë¬´ì‹œê°„ ë¹„êµ
                    </p>
                </div>
                """, unsafe_allow_html=True)
                
                # ëª¨ë“  ì£¼ì°¨ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ í†µí•©
                weeks_in_month = sorted(month_data['ì£¼ì°¨'].unique())
                
                # ì£¼ì°¨ë³„ í‰ê· ì„ ì„¼í„°ë³„ë¡œ ì •ë¦¬
                weekly_summary = {}
                for center in sorted(month_data['ì„¼í„°'].unique()):
                    weekly_summary[center] = {}
                    for week in weeks_in_month:
                        week_data = month_data[(month_data['ì„¼í„°'] == center) & (month_data['ì£¼ì°¨'] == week)]
                        if not week_data.empty:
                            # ì§ì›ë³„ë¡œ ì£¼ê°„ í•©ê³„ë¥¼ êµ¬í•œ í›„ í‰ê· 
                            employee_week_sum = week_data.groupby('ì‚¬ë²ˆ')['ì‹¤ì œê·¼ë¬´ì‹œê°„'].sum()
                            weekly_summary[center][f'{month}.{week}ì£¼'] = employee_week_sum.mean()
                        else:
                            weekly_summary[center][f'{month}.{week}ì£¼'] = None
                
                # DataFrameìœ¼ë¡œ ë³€í™˜
                weekly_df = pd.DataFrame(weekly_summary).T
                
                # í‰ê·  ì—´ ì¶”ê°€
                weekly_df['ì›” í‰ê· '] = weekly_df.mean(axis=1)
                
                # í‰ê·  í–‰ ì¶”ê°€
                weekly_df.loc['ì„¼í„° í‰ê· '] = weekly_df.mean(axis=0)
                
                # ë‚ ì§œ ì •ë³´ ì¶”ê°€ (ìµœì†Œ/ìµœëŒ€)
                min_hours = weekly_df.min().min()
                max_hours = weekly_df.max().max()
                st.markdown(f"**ìµœì†Œ: {min_hours:.1f}h | ìµœëŒ€: {max_hours:.1f}h**")
                
                # ìŠ¤íƒ€ì¼ ì ìš©
                styled_weekly = weekly_df.style.format("{:.1f}").applymap(color_cells)
                st.dataframe(styled_weekly, use_container_width=True)
                
                # ì‹œê°í™”
                st.markdown("""
                <div style="background: #f8f9fa; 
                            border-left: 3px solid #fd7e14; 
                            padding: 0.8rem 1.2rem; 
                            border-radius: 0 6px 6px 0; 
                            margin: 1rem 0 0.5rem 0;">
                    <h4 style="margin: 0; color: #fd7e14; font-weight: 600; font-size: 1.1rem;">
                        Data Visualization
                    </h4>
                    <p style="margin: 0.3rem 0 0 0; color: #6c757d; font-size: 0.9rem;">
                        ë°ì´í„° ì‹œê°í™”
                    </p>
                </div>
                """, unsafe_allow_html=True)
                
                # ì„¼í„°ë³„ í‰ê·  ê·¼ë¬´ì‹œê°„ ì°¨íŠ¸
                center_avg = month_data.groupby('ì„¼í„°')['ì‹¤ì œê·¼ë¬´ì‹œê°„'].mean().sort_values(ascending=False)
                fig1 = px.bar(x=center_avg.index, y=center_avg.values, 
                             title="ì„¼í„°ë³„ í‰ê·  ê·¼ë¬´ì‹œê°„",
                             labels={'x': 'ì„¼í„°', 'y': 'í‰ê·  ê·¼ë¬´ì‹œê°„(h)'})
                st.plotly_chart(fig1, use_container_width=True)
                
                # ì§ê¸‰ë³„ í‰ê·  ê·¼ë¬´ì‹œê°„ ì°¨íŠ¸
                grade_avg = month_data.groupby('ì§ê¸‰ë ˆë²¨')['ì‹¤ì œê·¼ë¬´ì‹œê°„'].mean().sort_values(ascending=False)
                fig2 = px.bar(x=grade_avg.index, y=grade_avg.values, 
                             title="ì§ê¸‰ë³„ í‰ê·  ê·¼ë¬´ì‹œê°„",
                             labels={'x': 'ì§ê¸‰', 'y': 'í‰ê·  ê·¼ë¬´ì‹œê°„(h)'})
                st.plotly_chart(fig2, use_container_width=True)
                
            except Exception as e:
                st.error(f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                import traceback
                st.text(traceback.format_exc())
    
    def _analyze_employee(self, employee_id: str, start_date, end_date):
        """ê°œì¸ë³„ ë¶„ì„ ìˆ˜í–‰ - individual_dashboardì˜ ì‹¤ì œ ë¡œì§ ì‚¬ìš©"""
        try:
            self.logger.info(f"ì§ì› {employee_id} ë¶„ì„ ì‹œì‘: {start_date} ~ {end_date}")
            
            # IndividualDashboard ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            from .individual_dashboard import IndividualDashboard
            from src.analysis.individual_analyzer import IndividualAnalyzer
            
            # IndividualAnalyzer ìƒì„±
            individual_analyzer = IndividualAnalyzer(self.db_manager, None)
            individual_analyzer.pickle_manager = self.pickle_manager
            
            # IndividualDashboard ìƒì„± 
            individual_dash = IndividualDashboard(individual_analyzer)
            
            # ë‚ ì§œë³„ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
            daily_results = []
            current_date = start_date
            
            while current_date <= end_date:
                try:
                    self.logger.info(f"  {current_date}: individual_dashboard.execute_analysis í˜¸ì¶œ")
                    
                    # ë¨¼ì € í•´ë‹¹ ë‚ ì§œì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    daily_tag_data = individual_dash.get_daily_tag_data(employee_id, current_date)
                    if daily_tag_data is None or daily_tag_data.empty:
                        self.logger.warning(f"  {current_date}: í•´ë‹¹ ë‚ ì§œì— íƒœê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                        continue
                    
                    self.logger.info(f"  {current_date}: íƒœê·¸ ë°ì´í„° {len(daily_tag_data)}ê±´ ë°œê²¬")
                    
                    # individual_dashboardì˜ execute_analysis ë©”ì„œë“œ í˜¸ì¶œ 
                    # ë°˜ë“œì‹œ employee_idì™€ selected_dateë¥¼ ì„¤ì •í•´ì•¼ meal_dataë¥¼ ì œëŒ€ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
                    self.logger.info(f"  {current_date}: execute_analysis í˜¸ì¶œ ì „ íŒŒë¼ë¯¸í„°: employee_id={employee_id}, selected_date={current_date}")
                    analysis_result = individual_dash.execute_analysis(
                        employee_id=employee_id,
                        selected_date=current_date,
                        return_data=True  # ë°ì´í„°ë§Œ ë°˜í™˜, UI ë Œë”ë§ ì•ˆí•¨
                    )
                    
                    self.logger.info(f"  {current_date}: analysis_result íƒ€ì…: {type(analysis_result)}")
                    if analysis_result:
                        self.logger.info(f"  {current_date}: analysis_result í‚¤ë“¤: {list(analysis_result.keys()) if isinstance(analysis_result, dict) else 'dictê°€ ì•„ë‹˜'}")
                        # ë¶„ì„ ê²°ê³¼ë¥¼ DB ì €ì¥ìš© í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        db_result = self._convert_to_db_format(analysis_result, employee_id, current_date)
                        if db_result:
                            daily_results.append(db_result)
                            self.logger.info(f"  {current_date}: ë¶„ì„ ì™„ë£Œ (DB ê²°ê³¼: {db_result.keys()})")
                        else:
                            self.logger.warning(f"  {current_date}: _convert_to_db_format ê²°ê³¼ ì—†ìŒ")
                    else:
                        self.logger.warning(f"  {current_date}: analysis_resultê°€ None ë˜ëŠ” ë¹ˆ ê°’")
                        # Noneì´ ë°˜í™˜ëœ ì´ìœ ë¥¼ ë” ìì„¸íˆ ì¡°ì‚¬
                        self.logger.info(f"  {current_date}: ì§ì ‘ analyze_daily_data í˜¸ì¶œ ì‹œë„")
                        try:
                            # ë¨¼ì € meal_dataê°€ ìˆëŠ”ì§€ í™•ì¸
                            meal_data = individual_dash.get_meal_data(employee_id, current_date)
                            if meal_data is not None and not meal_data.empty:
                                self.logger.info(f"  {current_date}: meal_data {len(meal_data)}ê±´ ë°œê²¬")
                            else:
                                self.logger.info(f"  {current_date}: meal_data ì—†ìŒ")
                            
                            classified_data = individual_dash.classify_activities(daily_tag_data, employee_id, current_date)
                            self.logger.info(f"  {current_date}: classify_activities ê²°ê³¼: {len(classified_data) if classified_data is not None else 0}ê±´")
                            
                            if classified_data is not None and not classified_data.empty:
                                # M1, M2 íƒœê·¸ í™•ì¸
                                m1_count = len(classified_data[classified_data.get('Tag_Code', '') == 'M1'])
                                m2_count = len(classified_data[classified_data.get('Tag_Code', '') == 'M2'])
                                meal_activities = len(classified_data[classified_data.get('activity_code', '').isin(['BREAKFAST', 'LUNCH', 'DINNER', 'MIDNIGHT_MEAL'])])
                                self.logger.info(f"  {current_date}: M1 íƒœê·¸: {m1_count}ê±´, M2 íƒœê·¸: {m2_count}ê±´, ì‹ì‚¬ í™œë™: {meal_activities}ê±´")
                                
                                analysis_result = individual_dash.analyze_daily_data(employee_id, current_date, classified_data)
                                self.logger.info(f"  {current_date}: analyze_daily_data ê²°ê³¼: {type(analysis_result)}")
                                
                                if analysis_result:
                                    self.logger.info(f"  {current_date}: analysis_result í‚¤ë“¤: {list(analysis_result.keys())}")
                                    
                                    # ì‹ì‚¬ ê´€ë ¨ ë°ì´í„° í™•ì¸
                                    if 'activity_summary' in analysis_result:
                                        act_sum = analysis_result['activity_summary']
                                        self.logger.info(f"  {current_date}: ì‹ì‚¬ í™œë™ - BREAKFAST:{act_sum.get('BREAKFAST',0)}, LUNCH:{act_sum.get('LUNCH',0)}, DINNER:{act_sum.get('DINNER',0)}")
                                    
                                    if 'meal_time_analysis' in analysis_result:
                                        meal_analysis = analysis_result['meal_time_analysis']
                                        self.logger.info(f"  {current_date}: meal_time_analysis: {meal_analysis}")
                                    
                                    db_result = self._convert_to_db_format(analysis_result, employee_id, current_date)
                                    if db_result:
                                        daily_results.append(db_result)
                                        self.logger.info(f"  {current_date}: ì§ì ‘ í˜¸ì¶œë¡œ ë¶„ì„ ì™„ë£Œ")
                                else:
                                    self.logger.warning(f"  {current_date}: analyze_daily_dataê°€ None ë°˜í™˜")
                        except Exception as direct_e:
                            self.logger.error(f"  {current_date}: ì§ì ‘ í˜¸ì¶œë„ ì‹¤íŒ¨: {direct_e}")
                            import traceback
                            self.logger.error(f"  {current_date}: ì§ì ‘ í˜¸ì¶œ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                    
                except Exception as e:
                    self.logger.error(f"  {current_date} ë¶„ì„ ì‹¤íŒ¨: {e}")
                    import traceback
                    self.logger.error(f"  {current_date} ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                
                current_date += timedelta(days=1)
            
            self.logger.info(f"ì§ì› {employee_id}: {len(daily_results)}ì¼ì¹˜ ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
            return daily_results if daily_results else None
            
        except Exception as e:
            self.logger.error(f"ì§ì› {employee_id} ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None
    
    def _convert_to_db_format(self, analysis_result, employee_id, work_date):
        """individual_dashboardì˜ ë¶„ì„ ê²°ê³¼ë¥¼ DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸
            self.logger.info(f"ë¶„ì„ ê²°ê³¼ êµ¬ì¡° - ì§ì› {employee_id}:")
            self.logger.info(f"  ì „ì²´ í‚¤ë“¤: {list(analysis_result.keys())}")
            
            # work_time_analysisì—ì„œ ë°ì´í„° ì¶”ì¶œ
            work_analysis = analysis_result.get('work_time_analysis', {})
            activity_summary = analysis_result.get('activity_summary', {})
            meal_analysis = analysis_result.get('meal_time_analysis', {})
            
            # ë””ë²„ê¹… ì •ë³´
            self.logger.info(f"  work_analysis í‚¤ë“¤: {list(work_analysis.keys()) if work_analysis else 'ì—†ìŒ'}")
            self.logger.info(f"  activity_summary í‚¤ë“¤: {list(activity_summary.keys()) if activity_summary else 'ì—†ìŒ'}")
            self.logger.info(f"  meal_analysis í‚¤ë“¤: {list(meal_analysis.keys()) if meal_analysis else 'ì—†ìŒ'}")
            
            if activity_summary:
                self.logger.info(f"  activity_summary ê°’ë“¤: {activity_summary}")
            if meal_analysis:
                self.logger.info(f"  meal_analysis ê°’ë“¤: {meal_analysis}")
            
            # ê·¼íƒœ ì‹œê°„ê³¼ ì‹¤ì œ ì‘ì—… ì‹œê°„
            attendance_hours = work_analysis.get('claimed_work_hours', 0)
            actual_work_hours = work_analysis.get('actual_work_hours', 0)
            
            # í™œë™ë³„ ì‹œê°„ ê³„ì‚° (ë¶„ -> ì‹œê°„)
            meeting_hours = activity_summary.get('MEETING', 0) / 60
            movement_hours = activity_summary.get('MOVEMENT', 0) / 60
            rest_hours = (activity_summary.get('REST', 0) + activity_summary.get('IDLE', 0)) / 60
            
            # ì‹ì‚¬ ì‹œê°„ - ê°œì¸ë³„ ë¶„ì„ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ meal_dataì—ì„œ ì§ì ‘ ê³„ì‚°
            # 1. activity_summaryì—ì„œ ì§ì ‘
            breakfast_hours = activity_summary.get('BREAKFAST', 0) / 60
            lunch_hours = activity_summary.get('LUNCH', 0) / 60  
            dinner_hours = activity_summary.get('DINNER', 0) / 60
            midnight_meal_hours = activity_summary.get('MIDNIGHT_MEAL', 0) / 60
            
            # 2. meal_data í…Œì´ë¸”ì—ì„œ ì§ì ‘ ê³„ì‚° (ê°œì¸ë³„ ë¶„ì„ ë°©ì‹ê³¼ ë™ì¼)
            try:
                from .individual_dashboard import IndividualDashboard
                from src.analysis.individual_analyzer import IndividualAnalyzer
                
                # IndividualDashboard ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆë‹¤ë©´ ì¬ì‚¬ìš©)
                individual_analyzer = IndividualAnalyzer(self.db_manager, None)
                individual_analyzer.pickle_manager = self.pickle_manager
                individual_dash = IndividualDashboard(individual_analyzer)
                
                # meal_dataì—ì„œ ì§ì ‘ ì‹ì‚¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                meal_data = individual_dash.get_meal_data(employee_id, work_date)
                if meal_data is not None and not meal_data.empty:
                    self.logger.info(f"  meal_dataì—ì„œ {len(meal_data)}ê±´ì˜ ì‹ì‚¬ ë°ì´í„° ë°œê²¬")
                    
                    # ì‹¤ì œ ì‹ì‚¬ë³„ë¡œ ì‹œê°„ ê³„ì‚° (ê°œì¸ë³„ ë¶„ì„ê³¼ ë™ì¼í•œ ë¡œì§)
                    calculated_meal_minutes = 0
                    date_column = 'ì·¨ì‹ì¼ì‹œ' if 'ì·¨ì‹ì¼ì‹œ' in meal_data.columns else 'meal_datetime'
                    
                    for _, meal in meal_data.iterrows():
                        meal_type = meal.get('ì‹ì‚¬ëŒ€ë¶„ë¥˜', meal.get('meal_category', ''))
                        ë°°ì‹êµ¬ = meal.get('ë°°ì‹êµ¬', '')
                        í…Œì´í¬ì•„ì›ƒ = meal.get('í…Œì´í¬ì•„ì›ƒ', '')
                        
                        # ë°°ì‹êµ¬ ê¸°ì¤€ í…Œì´í¬ì•„ì›ƒ íŒë‹¨
                        is_takeout = (í…Œì´í¬ì•„ì›ƒ == 'Y') or ('í…Œì´í¬ì•„ì›ƒ' in str(ë°°ì‹êµ¬))
                        
                        if is_takeout:
                            # í…Œì´í¬ì•„ì›ƒì€ 10ë¶„ ê³ ì •
                            calculated_meal_minutes += 10
                        else:
                            # í˜„ì¥ ì‹ì‚¬ëŠ” 30ë¶„ ê¸°ë³¸, ì•¼ì‹ì€ 20ë¶„
                            if meal_type == 'ì•¼ì‹':
                                calculated_meal_minutes += 20
                            else:
                                calculated_meal_minutes += 30
                    
                    if calculated_meal_minutes > 0:
                        meal_hours = calculated_meal_minutes / 60
                        self.logger.info(f"  meal_dataì—ì„œ ì§ì ‘ ê³„ì‚°í•œ ì‹ì‚¬ì‹œê°„: {calculated_meal_minutes}ë¶„ ({meal_hours:.1f}ì‹œê°„)")
                    else:
                        # activity_summaryì—ì„œ ê³„ì‚°
                        meal_hours = breakfast_hours + lunch_hours + dinner_hours + midnight_meal_hours
                        self.logger.info(f"  activity_summaryì—ì„œ ê³„ì‚°í•œ ì‹ì‚¬ì‹œê°„: {meal_hours:.1f}ì‹œê°„")
                else:
                    # meal_dataê°€ ì—†ìœ¼ë©´ activity_summaryì—ì„œ ê³„ì‚°
                    meal_hours = breakfast_hours + lunch_hours + dinner_hours + midnight_meal_hours
                    self.logger.info(f"  meal_data ì—†ìŒ - activity_summaryì—ì„œ ê³„ì‚°í•œ ì‹ì‚¬ì‹œê°„: {meal_hours:.1f}ì‹œê°„")
            except Exception as meal_e:
                self.logger.warning(f"  meal_data ê³„ì‚° ì‹¤íŒ¨: {meal_e}")
                # activity_summaryì—ì„œ ê³„ì‚°
                meal_hours = breakfast_hours + lunch_hours + dinner_hours + midnight_meal_hours
                self.logger.info(f"  meal_data ì˜¤ë¥˜ë¡œ activity_summaryì—ì„œ ê³„ì‚°í•œ ì‹ì‚¬ì‹œê°„: {meal_hours:.1f}ì‹œê°„")
            
            # 3. meal_time_analysisì—ì„œ ì‹œë„ (ë³´ì¡°)
            if meal_analysis and 'total_meal_time' in meal_analysis:
                total_meal_minutes = meal_analysis.get('total_meal_time', 0)
                if total_meal_minutes > 0:
                    meal_hours_from_analysis = total_meal_minutes / 60
                    self.logger.info(f"  meal_analysisì—ì„œ ì‹ì‚¬ì‹œê°„: {total_meal_minutes}ë¶„ ({meal_hours_from_analysis:.1f}ì‹œê°„)")
                    # ë” ë†’ì€ ê°’ì„ ì„ íƒ (ë°ì´í„° ëˆ„ë½ ë°©ì§€)
                    if meal_hours_from_analysis > meal_hours:
                        meal_hours = meal_hours_from_analysis
            
            # 4. ê°œë³„ ì‹ì‚¬ íŒ¨í„´ì—ì„œ ì‹œë„ (meal_time_analysis ë‚´ë¶€)
            if meal_analysis and 'meal_patterns' in meal_analysis:
                meal_patterns = meal_analysis['meal_patterns']
                total_meal_from_patterns = 0
                for meal_type, pattern in meal_patterns.items():
                    if isinstance(pattern, dict) and 'avg_duration' in pattern and 'frequency' in pattern:
                        total_meal_from_patterns += pattern['avg_duration'] * pattern['frequency']
                if total_meal_from_patterns > 0:
                    meal_hours_from_patterns = total_meal_from_patterns / 60
                    self.logger.info(f"  meal_patternsì—ì„œ ê³„ì‚°í•œ ì‹ì‚¬ì‹œê°„: {total_meal_from_patterns}ë¶„ ({meal_hours_from_patterns:.1f}ì‹œê°„)")
                    # ë” ë†’ì€ ê°’ì„ ì„ íƒ (ë°ì´í„° ëˆ„ë½ ë°©ì§€)
                    if meal_hours_from_patterns > meal_hours:
                        meal_hours = meal_hours_from_patterns
            
            # ë°ì´í„° ì‹ ë¢°ë„
            data_reliability = work_analysis.get('confidence_score', 0)
            if data_reliability == 0:
                # íƒœê·¸ ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
                total_tags = analysis_result.get('total_tags', 0)
                data_reliability = min(100, (total_tags / 80) * 100)
            
            # íš¨ìœ¨ì„± ê³„ì‚°
            work_efficiency = 0
            if attendance_hours > 0:
                work_efficiency = (actual_work_hours / attendance_hours) * 100
            
            return {
                'employee_id': employee_id,
                'analysis_date': work_date,
                'attendance_hours': attendance_hours,
                'actual_work_hours': actual_work_hours,
                'work_estimation_rate': work_efficiency,
                'meeting_time': meeting_hours,  # ì‹œê°„ ë‹¨ìœ„ë¡œ í†µì¼
                'meal_time': meal_hours,
                'movement_time': movement_hours,
                'rest_time': rest_hours,
                'breakfast_time': breakfast_hours,
                'lunch_time': lunch_hours,
                'dinner_time': dinner_hours,
                'midnight_meal_time': midnight_meal_hours,
                'shift_type': work_analysis.get('shift_type', 'ì£¼ê°„'),
                'cross_day_flag': work_analysis.get('cross_day', False),
                'data_reliability': data_reliability,
                'tag_count': analysis_result.get('total_tags', 0),
                'data_completeness': data_reliability,
                'work_efficiency': work_efficiency,
                'productivity_score': min(100, (actual_work_hours / 8) * 100) if actual_work_hours > 0 else 0
            }
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    # ê¸°ì¡´ ì½”ë“œëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - ì‚­ì œ ì˜ˆì •
    def _analyze_employee_old(self, employee_id: str, start_date, end_date):
        """ì´ì „ ë²„ì „ - ì‚­ì œ ì˜ˆì •"""
        # ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤
        # _analyze_employee í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
        pass
    
    def _calculate_daily_metrics(self, employee_id, work_date, tag_data, claim_data, meal_data, emp_info):
        """ì¼ì¼ ë©”íŠ¸ë¦­ ê³„ì‚° - individual_dashboardì˜ ë¡œì§ ì‚¬ìš©"""
        try:
            # ë””ë²„ê¹… ë¡œê·¸
            self.logger.debug(f"ë©”íŠ¸ë¦­ ê³„ì‚° ì‹œì‘: {employee_id} - {work_date}")
            self.logger.debug(f"  tag_data: {len(tag_data) if tag_data is not None else 0}ê°œ")
            self.logger.debug(f"  claim_data type: {type(claim_data)}")
            # ì¶œí‡´ê·¼ ì‹œê°„ ì°¾ê¸°
            first_in = None
            last_out = None
            
            if not tag_data.empty:
                sorted_tags = tag_data.sort_values('datetime')
                
                # ì¶œê·¼ ì‹œê°„ (ì²« ì…ë¬¸ ë˜ëŠ” ì²« íƒœê·¸)
                in_tags = sorted_tags[sorted_tags['INOUT_GB'] == 'ì…ë¬¸'] if 'INOUT_GB' in sorted_tags.columns else pd.DataFrame()
                if not in_tags.empty:
                    first_in = pd.to_datetime(in_tags.iloc[0]['datetime'])
                elif len(sorted_tags) > 0:
                    first_in = pd.to_datetime(sorted_tags.iloc[0]['datetime'])
                
                # í‡´ê·¼ ì‹œê°„ (ë§ˆì§€ë§‰ ì¶œë¬¸ ë˜ëŠ” ë§ˆì§€ë§‰ íƒœê·¸)
                out_tags = sorted_tags[sorted_tags['INOUT_GB'] == 'ì¶œë¬¸'] if 'INOUT_GB' in sorted_tags.columns else pd.DataFrame()
                if not out_tags.empty:
                    last_out = pd.to_datetime(out_tags.iloc[-1]['datetime'])
                elif len(sorted_tags) > 0:
                    last_out = pd.to_datetime(sorted_tags.iloc[-1]['datetime'])
            
            # ì²´ë¥˜ì‹œê°„ ê³„ì‚°
            total_hours = 0
            if first_in and last_out:
                total_hours = (last_out - first_in).total_seconds() / 3600
            
            # ê·¼íƒœê¸°ë¡ì‹œê°„ (claim ë°ì´í„°ì—ì„œ)
            attendance_hours = 0
            if claim_data is not None:
                # claim_dataê°€ Seriesì¸ ê²½ìš°
                if isinstance(claim_data, pd.Series):
                    # ê°€ëŠ¥í•œ ëª¨ë“  ì»¬ëŸ¼ëª… ì²´í¬
                    possible_columns = ['claimed_work_hours', 'ì‹¤ì œê·¼ë¬´ì‹œê°„', 'ê·¼ë¬´ì‹œê°„', 'ê·¼íƒœì‹œê°„', 
                                      'actual_work_hours', 'work_hours', 'ì´ê·¼ë¬´ì‹œê°„']
                    for col in possible_columns:
                        if col in claim_data and pd.notna(claim_data[col]):
                            try:
                                value = claim_data[col]
                                if isinstance(value, str):
                                    # '11.5h' ë˜ëŠ” '11.5ì‹œê°„' í˜•íƒœ ì²˜ë¦¬
                                    attendance_hours = float(value.replace('h', '').replace('ì‹œê°„', '').strip())
                                else:
                                    attendance_hours = float(value)
                                if attendance_hours > 0:
                                    self.logger.debug(f"    ê·¼íƒœì‹œê°„ ë°œê²¬ ({col}): {attendance_hours}h")
                                    break
                            except Exception as e:
                                self.logger.debug(f"    {col} íŒŒì‹± ì‹¤íŒ¨: {e}")
                                continue
                # DataFrameì¸ ê²½ìš°
                elif isinstance(claim_data, pd.DataFrame) and not claim_data.empty:
                    row = claim_data.iloc[0]
                    possible_columns = ['claimed_work_hours', 'ì‹¤ì œê·¼ë¬´ì‹œê°„', 'ê·¼ë¬´ì‹œê°„', 'ê·¼íƒœì‹œê°„', 
                                      'actual_work_hours', 'work_hours', 'ì´ê·¼ë¬´ì‹œê°„']
                    for col in possible_columns:
                        if col in row and pd.notna(row[col]):
                            try:
                                value = row[col]
                                if isinstance(value, str):
                                    attendance_hours = float(value.replace('h', '').replace('ì‹œê°„', '').strip())
                                else:
                                    attendance_hours = float(value)
                                if attendance_hours > 0:
                                    break
                            except:
                                continue
            
            # í™œë™ë³„ ì‹œê°„ ì§‘ê³„ (íƒœê·¸ ê¸°ë°˜)
            work_minutes = 0
            meal_minutes = 0
            rest_minutes = 0
            movement_minutes = 0
            meeting_minutes = 0
            
            if not tag_data.empty:
                # ì‹œê°„ ê°„ê²© ê³„ì‚°
                sorted_tags = tag_data.sort_values('datetime').copy()
                sorted_tags['datetime'] = pd.to_datetime(sorted_tags['datetime'])
                sorted_tags['next_datetime'] = sorted_tags['datetime'].shift(-1)
                sorted_tags['duration_minutes'] = (
                    (sorted_tags['next_datetime'] - sorted_tags['datetime']).dt.total_seconds() / 60
                ).fillna(0)
                
                # ìœ„ì¹˜ë³„ ì‹œê°„ ì§‘ê³„
                for idx, row in sorted_tags.iterrows():
                    duration = row['duration_minutes']
                    location = str(row.get('DR_NM', ''))
                    inout = str(row.get('INOUT_GB', ''))
                    
                    # ì‹ì‚¬ íŒë³„ (CAFETERIA ë˜ëŠ” ì‹ë‹¹)
                    if 'CAFETERIA' in location.upper() or 'ì‹ë‹¹' in location:
                        meal_minutes += duration
                    # íšŒì˜ì‹¤ íŒë³„
                    elif 'íšŒì˜' in location or 'MEETING' in location.upper():
                        meeting_minutes += duration
                    # íœ´ê²Œ íŒë³„
                    elif 'íœ´ê²Œ' in location or 'í™”ì¥ì‹¤' in location or 'REST' in location.upper():
                        rest_minutes += duration
                    # ì´ë™ íŒë³„ (ì§§ì€ ì¶œë¬¸)
                    elif inout == 'ì¶œë¬¸' and duration < 15:
                        movement_minutes += duration
                    # ë‚˜ë¨¸ì§€ëŠ” ì‘ì—…
                    else:
                        work_minutes += duration
                
                # ìµœëŒ€ê°’ ì œí•œ (ì²´ë¥˜ì‹œê°„ ê¸°ì¤€)
                total_minutes = total_hours * 60
                if total_minutes > 0:
                    # ê° í™œë™ ì‹œê°„ì´ ì²´ë¥˜ì‹œê°„ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì¡°ì •
                    work_minutes = min(work_minutes, total_minutes * 0.8)  # ìµœëŒ€ 80%
                    meal_minutes = min(meal_minutes, 120)  # ìµœëŒ€ 2ì‹œê°„
                    rest_minutes = min(rest_minutes, 60)  # ìµœëŒ€ 1ì‹œê°„
                    movement_minutes = min(movement_minutes, 60)  # ìµœëŒ€ 1ì‹œê°„
                    meeting_minutes = min(meeting_minutes, 240)  # ìµœëŒ€ 4ì‹œê°„
            
            # ì‹œê°„ì„ ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜
            actual_work_hours = work_minutes / 60
            meal_hours = meal_minutes / 60
            rest_hours = rest_minutes / 60
            movement_hours = movement_minutes / 60
            meeting_hours = meeting_minutes / 60
            
            # ì‹ì‚¬ ì„¸ë¶€ ì‹œê°„ (meal_dataì—ì„œ)
            breakfast_time = 0
            lunch_time = 0
            dinner_time = 0
            midnight_meal_time = 0
            
            if meal_data is not None and isinstance(meal_data, pd.DataFrame) and not meal_data.empty:
                for _, meal in meal_data.iterrows():
                    meal_type = meal.get('meal_category', meal.get('ì‹ì‚¬ëŒ€ë¶„ë¥˜', ''))
                    ë°°ì‹êµ¬ = meal.get('ë°°ì‹êµ¬', '')
                    is_takeout = 'takeout' in str(ë°°ì‹êµ¬).lower() or 'í…Œì´í¬ì•„ì›ƒ' in str(ë°°ì‹êµ¬)
                    
                    # í…Œì´í¬ì•„ì›ƒì€ 10ë¶„, ì¼ë°˜ì€ 30ë¶„
                    meal_duration = 10 if is_takeout else 30
                    
                    if 'ì¡°ì‹' in meal_type or 'breakfast' in meal_type.lower():
                        breakfast_time += meal_duration
                    elif 'ì¤‘ì‹' in meal_type or 'lunch' in meal_type.lower():
                        lunch_time += meal_duration
                    elif 'ì„ì‹' in meal_type or 'dinner' in meal_type.lower():
                        dinner_time += meal_duration
                    elif 'ì•¼ì‹' in meal_type or 'midnight' in meal_type.lower():
                        midnight_meal_time += meal_duration
                
                # ì‹¤ì œ ì‹ì‚¬ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
                if breakfast_time + lunch_time + dinner_time + midnight_meal_time > 0:
                    meal_hours = (breakfast_time + lunch_time + dinner_time + midnight_meal_time) / 60
            
            # ë¶„ì„ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            breakfast_hours = breakfast_time / 60
            lunch_hours = lunch_time / 60
            dinner_hours = dinner_time / 60
            midnight_meal_hours = midnight_meal_time / 60
            
            # ì‘ì—…ì‹œê°„ ì¶”ì •ìœ¨
            work_estimation_rate = 0
            if attendance_hours > 0:
                work_estimation_rate = (actual_work_hours / attendance_hours) * 100
            
            # ë°ì´í„° ì‹ ë¢°ë„ (íƒœê·¸ ìˆ˜ ê¸°ë°˜)
            tag_count = len(tag_data)
            # í•˜ë£¨ 8ì‹œê°„ ê·¼ë¬´ ê¸°ì¤€ìœ¼ë¡œ 5ë¶„ë§ˆë‹¤ íƒœê·¸ê°€ ìˆìœ¼ë©´ 96ê°œ
            # 80ê°œ ì´ìƒì´ë©´ 100%
            data_reliability = min(100, (tag_count / 80) * 100)
            
            # ë°ì´í„° ì™„ì „ì„±
            data_completeness = min(100, (tag_count / 50) * 100)  # 50ê°œ íƒœê·¸ë¥¼ 100%ë¡œ
            
            # ì—…ë¬´ íš¨ìœ¨ì„±
            work_efficiency = work_estimation_rate
            
            # ìƒì‚°ì„± ì ìˆ˜ (ì‹¤ì œ ì‘ì—…ì‹œê°„ ê¸°ì¤€)
            productivity_score = min(100, (actual_work_hours / 8) * 100) if actual_work_hours > 0 else 0
            
            # êµëŒ€ ê·¼ë¬´ ì •ë³´
            shift_type = 'ì£¼ê°„'  # ê¸°ë³¸ê°’
            cross_day_flag = False
            
            if first_in and last_out:
                # ì•¼ê°„ ê·¼ë¬´ íŒë³„ (20ì‹œ ì´í›„ ì¶œê·¼ ë˜ëŠ” 8ì‹œ ì´ì „ í‡´ê·¼)
                if first_in.hour >= 20 or last_out.hour <= 8:
                    shift_type = 'ì•¼ê°„'
                # ë‚ ì§œ êµì°¨ íŒë³„
                if first_in.date() != last_out.date():
                    cross_day_flag = True
            
            # ê²°ê³¼ ë°˜í™˜
            return {
                'employee_id': employee_id,
                'employee_name': emp_info.get('name', emp_info.get('ì„±ëª…', '')) if emp_info is not None else '',
                'department': emp_info.get('dept_name', emp_info.get('ë¶€ì„œëª…', '')) if emp_info is not None else '',
                'center': emp_info.get('center', emp_info.get('ì„¼í„°', '')) if emp_info is not None else '',
                'team': emp_info.get('team', emp_info.get('íŒ€', '')) if emp_info is not None else '',
                'analysis_date': work_date,
                'attendance_hours': attendance_hours,
                'actual_work_hours': actual_work_hours,
                'work_estimation_rate': work_estimation_rate,
                'meeting_hours': meeting_hours,
                'meal_hours': meal_hours,
                'movement_hours': movement_hours,
                'rest_hours': rest_hours,
                'breakfast_time': breakfast_hours,
                'lunch_time': lunch_hours,
                'dinner_time': dinner_hours,
                'midnight_meal_time': midnight_meal_hours,
                'shift_type': shift_type,
                'cross_day_flag': cross_day_flag,
                'data_reliability': data_reliability,
                'tag_count': tag_count,
                'data_completeness': data_completeness,
                'work_efficiency': work_efficiency,
                'productivity_score': productivity_score
            }
            
        except Exception as e:
            self.logger.error(f"ì¼ì¼ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None
    
    def _save_employee_analysis(self, analysis_results):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        session = None
        try:
            from ...database.schema import DailyWorkData
            
            # get_session()ì´ context managerë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ with ë¬¸ ì‚¬ìš©
            with self.db_manager.get_session() as session:
                saved_count = 0
                for result in analysis_results:
                    try:
                        # ê¸°ì¡´ ë°ì´í„° í™•ì¸ ë° ì—…ë°ì´íŠ¸/ì‚½ì…
                        existing = session.query(DailyWorkData).filter_by(
                            employee_id=result['employee_id'],
                            work_date=result['analysis_date']
                        ).first()
                        
                        if existing:
                            # ì—…ë°ì´íŠ¸
                            existing.shift_type = result.get('shift_type', 'ì£¼ê°„')
                            existing.actual_work_time = result.get('actual_work_hours', 0)
                            existing.work_time = result.get('attendance_hours', 0)
                            existing.rest_time = result.get('rest_hours', 0)
                            existing.non_work_time = result.get('rest_hours', 0) + result.get('meal_hours', 0)
                            existing.meal_time = result.get('meal_hours', 0)
                            existing.breakfast_time = result.get('breakfast_time', 0)
                            existing.lunch_time = result.get('lunch_time', 0)
                            existing.dinner_time = result.get('dinner_time', 0)
                            existing.midnight_meal_time = result.get('midnight_meal_time', 0)
                            existing.cross_day_flag = result.get('cross_day_flag', False)
                            existing.efficiency_ratio = result.get('work_efficiency', 0)
                            existing.data_quality_score = result.get('data_reliability', 0)
                            saved_count += 1
                        else:
                            # ìƒˆë¡œ ì‚½ì…
                            daily_data = DailyWorkData(
                                employee_id=result['employee_id'],
                                work_date=result['analysis_date'],
                                shift_type=result.get('shift_type', 'ì£¼ê°„'),
                                actual_work_time=result.get('actual_work_hours', 0),
                                work_time=result.get('attendance_hours', 0),
                                rest_time=result.get('rest_hours', 0),
                                non_work_time=result.get('rest_hours', 0) + result.get('meal_hours', 0),
                                meal_time=result.get('meal_hours', 0),
                                breakfast_time=result.get('breakfast_time', 0),
                                lunch_time=result.get('lunch_time', 0),
                                dinner_time=result.get('dinner_time', 0),
                                midnight_meal_time=result.get('midnight_meal_time', 0),
                                cross_day_flag=result.get('cross_day_flag', False),
                                efficiency_ratio=result.get('work_efficiency', 0),
                                data_quality_score=result.get('data_reliability', 0)
                            )
                            session.add(daily_data)
                            saved_count += 1
                    except Exception as e:
                        self.logger.error(f"ê°œë³„ ë ˆì½”ë“œ ì €ì¥ ì‹¤íŒ¨: {e}")
                        import traceback
                        self.logger.error(traceback.format_exc())
                        continue
                
                if saved_count > 0:
                    session.commit()
                    self.logger.info(f"{saved_count}ê°œ ë ˆì½”ë“œ ì €ì¥ ì™„ë£Œ")
                
                return True
                
        except Exception as e:
            self.logger.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False