"""
ë°ì´í„° ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸ - í…Œì´ë¸” í˜•íƒœë¡œ ì¬êµ¬ì„±
"""

import streamlit as st
import pandas as pd
from datetime import datetime
import logging
import time
import os
import json
from pathlib import Path
from typing import Dict, List, Optional

from ...database import DatabaseManager
from ...data_processing import PickleManager, DataTransformer, ExcelLoader

class DataUploadComponent:
    """ë°ì´í„° ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db_manager = db_manager
        self.logger = logging.getLogger(__name__)
        self.pickle_manager = PickleManager()
        self.data_transformer = DataTransformer()
        self.excel_loader = ExcelLoader()
        
        # ì„¤ì • íŒŒì¼ ê²½ë¡œ
        self.config_dir = Path("config")
        self.config_dir.mkdir(exist_ok=True)
        self.config_file = self.config_dir / "upload_config.json"
        
        # ë°ì´í„° ìœ í˜• ì •ì˜ ë¡œë“œ (ì €ì¥ëœ ì„¤ì •ì´ ìˆìœ¼ë©´ ì‚¬ìš©)
        self.data_types = self._load_data_types()
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'upload_config' not in st.session_state:
            st.session_state.upload_config = self._load_upload_config()
        
        # ìë™ìœ¼ë¡œ pickle íŒŒì¼ í™•ì¸ ë° ë¡œë“œ - ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰
        if 'pickles_auto_loaded' not in st.session_state:
            self._auto_load_pickles()
            st.session_state.pickles_auto_loaded = True
    
    def _load_data_types(self) -> Dict:
        """ë°ì´í„° ìœ í˜• ì •ì˜ ë¡œë“œ"""
        default_types = {
            "Tagging Data": {
                "table_name": "tag_data",
                "display_name": "íƒœê¹… ë°ì´í„°",
                "process_func_name": "process_tagging_data"
            },
            "íƒœê¹…ì§€ì ": {
                "table_name": "tag_location_master",
                "display_name": "íƒœê¹… ì§€ì  ë§ˆìŠ¤í„°",
                "process_func_name": None
            },
            "ê·¼ë¬´ì‹œê°„_Claim": {
                "table_name": "claim_data",
                "display_name": "ê·¼ë¬´ì‹œê°„ Claim ë°ì´í„°",
                "process_func_name": "process_claim_data"
            },
            "ê·¼íƒœì‚¬ìš©": {
                "table_name": "attendance_data",
                "display_name": "ê·¼íƒœ ì‚¬ìš© ë°ì´í„°",
                "process_func_name": None
            },
            "ë¹„ê·¼ë¬´ì‹œê°„": {
                "table_name": "non_work_time",
                "display_name": "ë¹„ê·¼ë¬´ì‹œê°„ ë°ì´í„°",
                "process_func_name": None
            },
            "ABCë°ì´í„°": {
                "table_name": "abc_data",
                "display_name": "ABC í™œë™ ë°ì´í„°",
                "process_func_name": "process_abc_data"
            },
            "ì‹ì‚¬ ë°ì´í„°": {
                "table_name": "meal_data",
                "display_name": "ì‹ì‚¬ íƒœê·¸ ë°ì´í„°",
                "process_func_name": "process_meal_data"
            }
        }
        
        # ì €ì¥ëœ ì„¤ì • íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    saved_config = json.load(f)
                    if 'data_types' in saved_config:
                        default_types.update(saved_config['data_types'])
            except Exception as e:
                self.logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # process_func ì„¤ì •
        for data_type, info in default_types.items():
            if info.get('process_func_name'):
                info['process_func'] = getattr(self.data_transformer, info['process_func_name'], None)
            else:
                info['process_func'] = None
        
        return default_types
    
    def _save_data_types(self):
        """ë°ì´í„° ìœ í˜• ì •ì˜ ì €ì¥"""
        # process_funcëŠ” ì €ì¥í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ í•¨ìˆ˜ ì´ë¦„ë§Œ ì €ì¥
        save_data = {'data_types': {}}
        for data_type, info in self.data_types.items():
            save_info = info.copy()
            # process_func ì œê±°í•˜ê³  í•¨ìˆ˜ ì´ë¦„ë§Œ ì €ì¥
            if 'process_func' in save_info:
                if save_info['process_func']:
                    save_info['process_func_name'] = save_info['process_func'].__name__
                del save_info['process_func']
            save_data['data_types'][data_type] = save_info
        
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _load_upload_config(self) -> Dict:
        """ì—…ë¡œë“œ ì„¤ì • ë¡œë“œ"""
        # ê¸°ë³¸ ì„¤ì • ì´ˆê¸°í™”
        config = {}
        for data_type, info in self.data_types.items():
            config[data_type] = {
                "files": [],
                "file_names": [],
                "pickle_exists": False,
                "dataframe_name": None,
                "last_modified": None,
                "row_count": 0
            }
        
        # ì €ì¥ëœ ì„¤ì •ì´ ìˆìœ¼ë©´ ë³‘í•©
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    saved_config = json.load(f)
                    if 'upload_config' in saved_config:
                        for data_type, saved_info in saved_config['upload_config'].items():
                            if data_type in config:
                                # filesëŠ” ë¡œë“œí•˜ì§€ ì•ŠìŒ (UploadedFile ê°ì²´ëŠ” ì €ì¥ ë¶ˆê°€)
                                saved_info['files'] = []
                                # file_names ì •ë³´ëŠ” ìœ ì§€
                                config[data_type].update(saved_info)
            except Exception as e:
                self.logger.warning(f"ì—…ë¡œë“œ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return config
    
    def _save_upload_config(self):
        """ì—…ë¡œë“œ ì„¤ì • ì €ì¥"""
        # UploadedFile ê°ì²´ëŠ” JSON ì§ë ¬í™” ë¶ˆê°€í•˜ë¯€ë¡œ íŒŒì¼ ì´ë¦„ë§Œ ì €ì¥
        save_config = {'upload_config': {}}
        for data_type, info in st.session_state.upload_config.items():
            save_info = info.copy()
            # íŒŒì¼ ì´ë¦„ ì €ì¥ - ì´ë¯¸ file_namesê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
            if 'file_names' in info and info['file_names']:
                save_info['file_names'] = info['file_names']
            else:
                # filesê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                save_info['file_names'] = [file_info['name'] for file_info in info.get('files', [])]
            save_info['files'] = []  # UploadedFile ê°ì²´ëŠ” ì œì™¸
            save_config['upload_config'][data_type] = save_info
        
        # ë°ì´í„° ìœ í˜• ì •ì˜ë„ í•¨ê»˜ ì €ì¥
        save_data = {'data_types': {}}
        for data_type, info in self.data_types.items():
            save_info = info.copy()
            if 'process_func' in save_info:
                if save_info['process_func']:
                    save_info['process_func_name'] = save_info['process_func'].__name__
                del save_info['process_func']
            save_data['data_types'][data_type] = save_info
        
        save_data.update(save_config)
        
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ì—…ë¡œë“œ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def render(self):
        """ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        st.markdown("### ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬")
        
        # ì´ˆê¸° ë¡œë“œ ì‹œ pickle íŒŒì¼ ì •ë³´ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
        if 'data_status_refreshed' not in st.session_state:
            self._refresh_data_status()
            st.session_state.data_status_refreshed = True
        
        # ë°ì´í„° ìƒíƒœ í…Œì´ë¸” í‘œì‹œ
        self._render_data_status_table()
        
        # êµ¬ë¶„ì„ 
        st.markdown("---")
        
        # íŒŒì¼ ì¶”ê°€ ì„¹ì…˜
        self._render_file_upload_section()
        
        # êµ¬ë¶„ì„ 
        st.markdown("---")
        
        # ì˜µì…˜ ì„¤ì •
        with st.expander("âš™ï¸ ë¡œë“œ ì˜µì…˜", expanded=False):
            save_to_db = st.checkbox("ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥", value=False, 
                                   help="ì²´í¬í•˜ë©´ Pickle íŒŒì¼ê³¼ í•¨ê»˜ SQLite ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥ë©ë‹ˆë‹¤.")
            st.session_state.save_to_db = save_to_db
            
            process_data = st.checkbox("ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰", value=False,
                                     help="ì²´í¬í•˜ë©´ ë°ì´í„° ë¡œë”© í›„ ì „ì²˜ë¦¬(ë¶„ì„)ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.session_state.process_data = process_data
        
        # ë°ì´í„° ë¡œë“œ ë²„íŠ¼
        col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
        with col1:
            if st.button("ğŸš€ ë°ì´í„° ë¡œë“œ", type="primary", use_container_width=True):
                self._load_all_data()
        
        with col2:
            if st.button("ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™”", use_container_width=True):
                self._clear_cache()
                
        with col3:
            if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
                self._refresh_data_status()
                st.rerun()
                
        with col4:
            if st.button("ğŸ’¾ ì„¤ì • ì €ì¥", use_container_width=True):
                self._save_upload_config()
                st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _render_data_status_table(self):
        """ë°ì´í„° ìƒíƒœ í…Œì´ë¸” ë Œë”ë§"""
        st.markdown("#### ğŸ“Š ë°ì´í„° ë¡œë”© ìƒíƒœ")
        
        # ìƒíƒœ ì •ë³´ ìˆ˜ì§‘
        status_data = []
        for data_type, info in self.data_types.items():
            # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„¤ì • ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            config = st.session_state.upload_config.get(data_type, {
                "files": [], 
                "file_names": [],
                "pickle_exists": False,
                "dataframe_name": None,
                "last_modified": None,
                "row_count": 0
            })
            
            # Pickle íŒŒì¼ ì¡´ì¬ í™•ì¸ (ì‹¤ì‹œê°„ ì²´í¬)
            pickle_files = self.pickle_manager.list_pickle_files(info['table_name'])
            pickle_exists = len(pickle_files) > 0
            
            # í˜„ì¬ ë“±ë¡ëœ íŒŒì¼ ìˆ˜ì™€ ì €ì¥ëœ íŒŒì¼ ì´ë¦„ ëª©ë¡
            current_files = len(config.get('files', []))
            saved_file_names = config.get('file_names', [])
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            if current_files > 0:
                # í˜„ì¬ ë“±ë¡ëœ íŒŒì¼ëª… í‘œì‹œ
                current_file_names = [f['name'] for f in config.get('files', [])]
                file_info = f"{current_files}ê°œ ë“±ë¡ ({', '.join(current_file_names[:2])}{'...' if len(current_file_names) > 2 else ''})"
            elif saved_file_names:
                # ì €ì¥ëœ íŒŒì¼ëª… í‘œì‹œ
                # ë¡œê¹… ì¶”ê°€
                self.logger.info(f"{data_type} saved_file_names: {saved_file_names}")
                file_info = f"{len(saved_file_names)}ê°œ ({', '.join(saved_file_names[:2])}{'...' if len(saved_file_names) > 2 else ''})"
            else:
                file_info = "0ê°œ"
            
            # ì„¤ì • íŒŒì¼ì˜ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
            row_count = config.get('row_count', 0)
            last_modified = config.get('last_modified', '-')
            dataframe_name = config.get('dataframe_name', '-')
            
            # ì„¤ì • íŒŒì¼ì— ì •ë³´ê°€ ì—†ìœ¼ë©´ pickle íŒŒì¼ ì •ë³´ ì‚¬ìš©
            if pickle_exists and pickle_files and row_count == 0:
                latest_pickle = pickle_files[0]
                row_count = latest_pickle.get('rows', 0)
                last_modified = latest_pickle.get('created_at', '-')
                dataframe_name = latest_pickle.get('name', '-')
            
            status_data.append({
                "ë°ì´í„° ìœ í˜•": info['display_name'],
                "ë“±ë¡ íŒŒì¼": file_info,
                "Pickle ìƒíƒœ": "âœ… ìˆìŒ" if (pickle_exists or config.get('pickle_exists', False)) else "âŒ ì—†ìŒ",
                "ë°ì´í„°í”„ë ˆì„": dataframe_name,
                "í–‰ ìˆ˜": f"{row_count:,}" if row_count > 0 else "-",
                "ìµœì¢… ìˆ˜ì •": last_modified if last_modified != '-' else "-"
            })
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
        df_status = pd.DataFrame(status_data)
        st.dataframe(df_status, use_container_width=True, height=250)
    
    def _render_file_upload_section(self):
        """íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ë Œë”ë§"""
        st.markdown("#### ğŸ“ íŒŒì¼ ë“±ë¡")
        
        # ë°ì´í„° ìœ í˜• ì„ íƒ
        col1, col2 = st.columns([1, 2])
        
        with col1:
            selected_type = st.selectbox(
                "ë°ì´í„° ìœ í˜•",
                list(self.data_types.keys()),
                key="upload_data_type"
            )
        
        with col2:
            uploaded_files = st.file_uploader(
                "ì—‘ì…€ íŒŒì¼ ì„ íƒ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
                type=['xlsx', 'xls'],
                accept_multiple_files=True,
                key=f"file_uploader_{selected_type}"
            )
        
        # íŒŒì¼ ì¶”ê°€ ë²„íŠ¼
        if uploaded_files:
            if st.button("â• íŒŒì¼ ì¶”ê°€", key="add_files"):
                for file in uploaded_files:
                    file_info = {
                        "name": file.name,
                        "size": file.size,
                        "file": file
                    }
                    if file_info not in st.session_state.upload_config[selected_type]["files"]:
                        st.session_state.upload_config[selected_type]["files"].append(file_info)
                st.success(f"{len(uploaded_files)}ê°œ íŒŒì¼ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ë“±ë¡ëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
        if st.session_state.upload_config[selected_type]["files"]:
            st.markdown(f"##### ğŸ“‹ {self.data_types[selected_type]['display_name']} ë“±ë¡ íŒŒì¼")
            
            for idx, file_info in enumerate(st.session_state.upload_config[selected_type]["files"]):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.text(file_info["name"])
                with col2:
                    st.text(f"{file_info['size'] / (1024*1024):.2f} MB")
                with col3:
                    if st.button("âŒ", key=f"remove_{selected_type}_{idx}"):
                        st.session_state.upload_config[selected_type]["files"].pop(idx)
        
        # ì‹ ê·œ ë°ì´í„° ìœ í˜• ì¶”ê°€
        with st.expander("â• ì‹ ê·œ ë°ì´í„° ìœ í˜• ì¶”ê°€"):
            new_type_name = st.text_input("ë°ì´í„° ìœ í˜• ì´ë¦„")
            new_table_name = st.text_input("í…Œì´ë¸” ì´ë¦„")
            new_display_name = st.text_input("í‘œì‹œ ì´ë¦„")
            
            if st.button("ì¶”ê°€") and all([new_type_name, new_table_name, new_display_name]):
                self.data_types[new_type_name] = {
                    "table_name": new_table_name,
                    "display_name": new_display_name,
                    "process_func": None
                }
                st.session_state.upload_config[new_type_name] = {
                    "files": [],
                    "pickle_exists": False,
                    "dataframe_name": None,
                    "last_modified": None,
                    "row_count": 0
                }
                # ì„¤ì • ì €ì¥
                self._save_data_types()
                self._save_upload_config()
                st.success(f"'{new_type_name}' ë°ì´í„° ìœ í˜•ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _load_all_data(self):
        """ëª¨ë“  ë°ì´í„° ë¡œë“œ"""
        progress_bar = st.progress(0)
        status_text = st.empty()
        detail_text = st.empty()  # ìƒì„¸ ì§„í–‰ìƒí™© í‘œì‹œìš©
        
        total_types = len(self.data_types)
        
        for idx, (data_type, info) in enumerate(self.data_types.items()):
            config = st.session_state.upload_config[data_type]
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = (idx) / total_types
            progress_bar.progress(progress)
            status_text.text(f"ì²˜ë¦¬ ì¤‘: {info['display_name']} ({idx + 1}/{total_types})")
            
            # íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            pickle_files = self.pickle_manager.list_pickle_files(info['table_name'])
            needs_reload = (
                len(config['files']) > 0 or  # ìƒˆ íŒŒì¼ì´ ì¶”ê°€ë¨
                (len(pickle_files) == 0 and len(config['files']) == 0)  # pickleë„ ì—†ê³  íŒŒì¼ë„ ì—†ìŒ
            )
            
            if needs_reload and len(config['files']) > 0:
                # ì—‘ì…€ íŒŒì¼ì—ì„œ ë¡œë“œ
                detail_text.text(f"ğŸ“‚ {info['display_name']} íŒŒì¼ ë¡œë”© ì¤‘...")
                self._load_from_excel(data_type, info, config, detail_text)
            elif len(pickle_files) > 0 and len(config['files']) == 0:
                # Pickle íŒŒì¼ì—ì„œ ë¡œë“œ
                detail_text.text(f"ğŸ’¾ {info['display_name']} ìºì‹œì—ì„œ ë¡œë”© ì¤‘...")
                self._load_from_pickle(data_type, info)
            
            time.sleep(0.1)  # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
        
        progress_bar.empty()
        status_text.empty()
        detail_text.empty()
        
        # ì„¤ì • ì €ì¥ - ì„¸ì…˜ ìƒíƒœê°€ ì´ë¯¸ ì—…ë°ì´íŠ¸ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë°”ë¡œ ì €ì¥
        self._save_upload_config()
        self.logger.info("ë°ì´í„° ë¡œë“œ ì™„ë£Œ - ì„¤ì • ì €ì¥ë¨")
        
        st.success("âœ… ëª¨ë“  ë°ì´í„° ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.info("ğŸ”„ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ì„ ëˆŒëŸ¬ í…Œì´ë¸”ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
        
        # ë²„íŠ¼ í´ë¦­ í›„ì—ë§Œ rerun
        time.sleep(2)  # ì„±ê³µ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ëŒ€ê¸°
    
    def _load_from_excel(self, data_type: str, info: Dict, config: Dict, detail_text=None):
        """ì—‘ì…€ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            all_dfs = []
            
            # íŒŒì¼ ì´ë¦„ ëª©ë¡ ìˆ˜ì§‘
            file_names = []
            
            # ëª¨ë“  íŒŒì¼ ì½ê¸°
            for idx, file_info in enumerate(config['files']):
                self.logger.info(f"[{idx+1}/{len(config['files'])}] {file_info['name']} ë¡œë”© ì‹œì‘...")
                
                # íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥ (UploadedFile ê°ì²´ëŠ” ì§ì ‘ ê²½ë¡œë¡œ ì ‘ê·¼ ë¶ˆê°€)
                import tempfile
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                    tmp_file.write(file_info['file'].getbuffer())
                    tmp_path = tmp_file.name
                
                try:
                    # ExcelLoader ì‚¬ìš©í•˜ì—¬ ë¡œë“œ (ì—¬ëŸ¬ ì‹œíŠ¸ ìë™ ë³‘í•©)
                    if detail_text:
                        detail_text.text(f"ğŸ“‚ {file_info['name']} íŒŒì¼ ë¶„ì„ ì¤‘...")
                    df = self.excel_loader.load_excel_file(tmp_path, auto_merge_sheets=True)
                    all_dfs.append(df)
                    file_names.append(file_info['name'])
                    self.logger.info(f"{file_info['name']} ë¡œë“œ ì™„ë£Œ: {len(df):,}í–‰")
                    if detail_text:
                        detail_text.text(f"âœ… {file_info['name']} ë¡œë“œ ì™„ë£Œ: {len(df):,}í–‰")
                finally:
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    import os
                    if os.path.exists(tmp_path):
                        os.unlink(tmp_path)
            
            # ë°ì´í„°í”„ë ˆì„ ë³‘í•©
            if all_dfs:
                combined_df = pd.concat(all_dfs, ignore_index=True)
                
                # ë°ì´í„° ë³€í™˜ (ì˜µì…˜ì´ ì¼œì ¸ìˆì„ ë•Œë§Œ)
                if info['process_func'] and st.session_state.get('process_data', False):
                    self.logger.info(f"{data_type} ì „ì²˜ë¦¬ ì‹œì‘...")
                    processed_df = info['process_func'](combined_df)
                else:
                    processed_df = combined_df
                    if info['process_func']:
                        self.logger.info(f"{data_type} ë¡œë”©ë§Œ ìˆ˜í–‰ (ì „ì²˜ë¦¬ ê±´ë„ˆëœ€)")
                
                # Pickleë¡œ ì €ì¥
                version = datetime.now().strftime('%Y%m%d_%H%M%S')
                self.pickle_manager.save_dataframe(
                    processed_df,
                    name=info['table_name'],
                    version=version,
                    description=f"Combined from {len(config['files'])} files"
                )
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì˜µì…˜ì´ ì¼œì ¸ìˆì„ ë•Œë§Œ)
                if self.db_manager and st.session_state.get('save_to_db', False):
                    try:
                        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
                        table_class = self.db_manager.get_table_class(info['table_name'])
                        if table_class:
                            with self.db_manager.get_session() as session:
                                session.query(table_class).delete()
                                session.commit()
                        
                        # ìƒˆ ë°ì´í„° ì‚½ì…
                        self.db_manager.dataframe_to_table(
                            processed_df, 
                            info['table_name'], 
                            if_exists='append'
                        )
                        self.logger.info(f"{info['display_name']} ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")
                    except Exception as db_error:
                        self.logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨ (Pickleì€ ì„±ê³µ): {db_error}")
                
                # ì„¤ì • ì—…ë°ì´íŠ¸
                config['file_names'] = file_names  # ìœ„ì—ì„œ ìˆ˜ì§‘í•œ íŒŒì¼ ì´ë¦„ ëª©ë¡ ì‚¬ìš©
                config['files'] = []  # ë¡œë“œ ì™„ë£Œ í›„ íŒŒì¼ ëª©ë¡ ì´ˆê¸°í™”
                config['pickle_exists'] = True
                config['dataframe_name'] = info['table_name']
                config['row_count'] = len(processed_df)
                config['last_modified'] = datetime.now().isoformat()
                
                # ë””ë²„ê¹…ìš© ë¡œê·¸
                self.logger.info(f"{data_type} íŒŒì¼ëª… ìˆ˜ì§‘ ê²°ê³¼: {file_names}")
                
                # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.upload_config[data_type] = config
                self.logger.info(f"{data_type} ì„¤ì • ì—…ë°ì´íŠ¸: {config}")
                
                st.success(f"âœ… {info['display_name']} ë¡œë“œ ì™„ë£Œ: {len(processed_df):,}í–‰")
                
        except Exception as e:
            st.error(f"âŒ {info['display_name']} ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.logger.error(f"{data_type} ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    def _load_from_pickle(self, data_type: str, info: Dict):
        """Pickle íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            # ê°€ì¥ ìµœì‹  pickle íŒŒì¼ ë¡œë“œ
            pickle_files = self.pickle_manager.list_pickle_files(info['table_name'])
            if pickle_files:
                latest_file = pickle_files[0]
                df = self.pickle_manager.load_dataframe(
                    name=info['table_name'],
                    version=latest_file['version']
                )
                
                if df is not None:
                    # ì„¤ì • ì—…ë°ì´íŠ¸
                    config = st.session_state.upload_config[data_type]
                    config['pickle_exists'] = True
                    config['dataframe_name'] = info['table_name']
                    config['row_count'] = len(df)
                    config['last_modified'] = latest_file.get('created_at', datetime.now().isoformat())
                    
                    # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                    st.session_state.upload_config[data_type] = config
                    
                    st.info(f"â„¹ï¸ {info['display_name']} Pickle ìºì‹œì—ì„œ ë¡œë“œ: {len(df):,}í–‰")
                else:
                    st.warning(f"âš ï¸ {info['display_name']} Pickle íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
                    
        except Exception as e:
            st.error(f"âŒ {info['display_name']} Pickle ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.logger.error(f"{data_type} pickle ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    def _refresh_data_status(self):
        """ë°ì´í„° ìƒíƒœ ì •ë³´ë¥¼ pickle íŒŒì¼ì—ì„œ ë‹¤ì‹œ ì½ì–´ì„œ ì—…ë°ì´íŠ¸"""
        self.logger.info("ë°ì´í„° ìƒíƒœ ìƒˆë¡œê³ ì¹¨ ì‹œì‘...")
        
        for data_type, info in self.data_types.items():
            # ìµœì‹  pickle íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            pickle_files = self.pickle_manager.list_pickle_files(info['table_name'])
            
            if pickle_files:
                latest_pickle = pickle_files[0]  # ê°€ì¥ ìµœì‹  íŒŒì¼
                
                # ì„¤ì • ì—…ë°ì´íŠ¸
                config = st.session_state.upload_config.get(data_type, {})
                config['pickle_exists'] = True
                config['dataframe_name'] = info['table_name']
                config['row_count'] = latest_pickle.get('rows', 0)
                config['last_modified'] = latest_pickle.get('created_at', datetime.now().isoformat())
                
                # íŒŒì¼ëª… ì •ë³´ê°€ ì—†ìœ¼ë©´ descriptionì—ì„œ ì¶”ì¶œ ì‹œë„
                if not config.get('file_names'):
                    description = latest_pickle.get('description', '')
                    if 'Combined from' in description:
                        # "Combined from X files" í˜•íƒœì—ì„œ íŒŒì¼ ìˆ˜ë§Œ í‘œì‹œ
                        config['file_names'] = [f"Pickle íŒŒì¼ ({latest_pickle.get('rows', 0):,}í–‰)"]
                
                # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.upload_config[data_type] = config
                self.logger.info(f"{data_type} ìƒíƒœ ì—…ë°ì´íŠ¸: {latest_pickle.get('rows', 0):,}í–‰")
            else:
                # pickle íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ì´ˆê¸°í™”
                config = st.session_state.upload_config.get(data_type, {})
                config['pickle_exists'] = False
                config['row_count'] = 0
                config['last_modified'] = '-'
                st.session_state.upload_config[data_type] = config
        
        # ì—…ë°ì´íŠ¸ëœ ì„¤ì • ì €ì¥
        self._save_upload_config()
        self.logger.info("ë°ì´í„° ìƒíƒœ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ")
    
    def _clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        # í™•ì¸ ë‹¤ì´ì–¼ë¡œê·¸ í‘œì‹œ
        with st.expander("âš ï¸ ìºì‹œ ì´ˆê¸°í™” í™•ì¸", expanded=True):
            st.warning("ëª¨ë“  Pickle ìºì‹œê°€ ì‚­ì œë©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            col1, col2 = st.columns([1, 3])
            with col1:
                if st.button("í™•ì¸", type="primary", key="confirm_clear_cache"):
                    try:
                        # ëª¨ë“  pickle íŒŒì¼ ì‚­ì œ
                        pickle_dir = Path("data/pickles")
                        if pickle_dir.exists():
                            for file in pickle_dir.glob("*.pkl.gz"):
                                file.unlink()
                        
                        st.success("âœ… ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        time.sleep(1)
                        
                    except Exception as e:
                        st.error(f"ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            with col2:
                st.info("í™•ì¸ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ëª¨ë“  ìºì‹œê°€ ì‚­ì œë©ë‹ˆë‹¤.")
    
    def _auto_load_pickles(self):
        """ìë™ìœ¼ë¡œ pickle íŒŒì¼ì„ í™•ì¸í•˜ê³  ë¡œë“œ"""
        self.logger.info("Pickle íŒŒì¼ ìë™ ë¡œë“œ ì‹œì‘...")
        
        try:
            # ê° ë°ì´í„° íƒ€ì…ë³„ë¡œ pickle íŒŒì¼ í™•ì¸
            for data_type, info in self.data_types.items():
                pickle_files = self.pickle_manager.list_pickle_files(info['table_name'])
                
                if pickle_files:
                    # ê°€ì¥ ìµœì‹  pickle íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    latest_pickle = pickle_files[0]
                    
                    # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰ (ì‹¤ì œ ë°ì´í„° ë¡œë“œëŠ” í•˜ì§€ ì•ŠìŒ)
                    config = st.session_state.upload_config.get(data_type, {})
                    config['pickle_exists'] = True
                    config['dataframe_name'] = info['table_name']
                    config['row_count'] = latest_pickle.get('rows', 0)
                    config['last_modified'] = latest_pickle.get('created_at', datetime.now().isoformat())
                    
                    # íŒŒì¼ëª… ì •ë³´ ì—…ë°ì´íŠ¸
                    if not config.get('file_names'):
                        config['file_names'] = [f"Pickle íŒŒì¼ ({latest_pickle.get('rows', 0):,}í–‰)"]
                    
                    st.session_state.upload_config[data_type] = config
                    
                    self.logger.info(f"{data_type} ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {latest_pickle.get('rows', 0):,}í–‰")
                else:
                    self.logger.info(f"{data_type}ì— ëŒ€í•œ pickle íŒŒì¼ ì—†ìŒ")
            
            # ì„¤ì • ì €ì¥
            self._save_upload_config()
            
        except Exception as e:
            self.logger.error(f"Pickle íŒŒì¼ ìë™ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")